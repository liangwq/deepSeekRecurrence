{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec11ed5-16fe-4629-8c33-c89f14ebaf38",
   "metadata": {},
   "source": [
    "# 时间旅行（Time Travel\n",
    "LangGraph 中的 **时间旅行（Time Travel）** 功能，这是一种高级状态管理机制，允许用户回溯到工作流的历史状态并重新执行后续步骤。以下是核心概念的中文解析：\n",
    "\n",
    "---\n",
    "\n",
    "### ⏳ **时间旅行功能的核心价值**\n",
    "1. **问题场景**：\n",
    "   - 传统聊天机器人是**线性对话**：用户输入 → AI 响应 → 结束\n",
    "   - **实际需求**：\n",
    "     - 用户想从**历史节点重新探索**不同结果（如：\"回到第三步尝试其他方案\"）\n",
    "     - 修复错误后**重新执行后续流程**（如：修改参数后重试计算）\n",
    "     - 类似 Git 的版本回退（常见于自主编程 Agent）\n",
    "\n",
    "2. **技术基础**：\n",
    "   - **检查点（Checkpoints）**：LangGraph 自动保存每个步骤的完整状态\n",
    "   - **持久化层**：所有历史状态存储在数据库（如 Redis/PostgreSQL）\n",
    "   - **状态标识**：每个状态有唯一 ID（如 `thread_id + step_id`）\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 **时间旅行工作原理**\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant User\n",
    "    participant LangGraph\n",
    "    participant DB\n",
    "\n",
    "    User->>LangGraph: 发起任务\n",
    "    LangGraph->>DB: 保存状态(step1)\n",
    "    LangGraph->>User: 响应A\n",
    "    User->>LangGraph: 继续任务\n",
    "    LangGraph->>DB: 保存状态(step2)\n",
    "    LangGraph->>User: 响应B\n",
    "\n",
    "    Note over User: 用户选择\"回到step1\"\n",
    "    User->>LangGraph: 提交历史状态ID\n",
    "    LangGraph->>DB: 加载step1状态\n",
    "    LangGraph->>LangGraph: 从step1重新执行\n",
    "    LangGraph->>User: 新响应A'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 **关键实现要素**\n",
    "1. **状态加载 API**：\n",
    "   ```python\n",
    "   # 加载历史状态\n",
    "   old_state = checkpoint.get(thread_id=\"123\", step_id=2)\n",
    "   \n",
    "   # 从该状态重新执行\n",
    "   new_state = graph.invoke(\n",
    "       input={\"new_input\": \"修正后的参数\"},\n",
    "       config={\"configurable\": {\"thread_id\": \"123\", \"step_id\": 2}}  # 指定起点\n",
    "   )\n",
    "   ```\n",
    "\n",
    "2. **分支探索**：\n",
    "   - 同一历史状态可衍生**多个执行分支**\n",
    "   - 每个分支独立存储（类似代码仓库的 Git branch）\n",
    "\n",
    "3. **状态完整性**：\n",
    "   - 回退时自动隔离原始状态（避免污染历史数据）\n",
    "   - 新分支继承原状态的**工具调用历史/消息记忆**\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 **典型应用场景**\n",
    "1. **决策回溯**  \n",
    "   - *场景*：金融分析 Agent 推荐股票A，用户想验证股票B  \n",
    "   - *操作*：回退到分析节点，修改股票代码重新执行\n",
    "\n",
    "2. **错误修复**  \n",
    "   - *场景*：编程 Agent 第5步代码报错  \n",
    "   - *操作*：回退到第4步，修改代码后继续执行\n",
    "\n",
    "3. **策略对比**  \n",
    "   - *场景*：实验设计 Agent 生成方案A，用户想比较方案B  \n",
    "   - *操作*：从方案生成节点创建两个分支并行执行\n",
    "\n",
    "4. **教育场景**  \n",
    "   - *场景*：数学辅导 Agent 解题到第3步，学生想尝试不同解法  \n",
    "   - *操作*：回溯到第2步重新推导\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ **实现注意事项**\n",
    "1. **工具副作用**：\n",
    "   - 避免重复执行有副作用的工具（如支付/写数据库）\n",
    "   - 方案：标记工具为 `idempotent`（幂等）或添加回滚逻辑\n",
    "   ```python\n",
    "   @tool(idempotent=True)  # 声明幂等工具\n",
    "   def get_stock_price(symbol: str):\n",
    "       # 可安全重复执行\n",
    "   ```\n",
    "\n",
    "2. **状态存储优化**：\n",
    "   - 大尺寸状态（如图像生成）需压缩或外部存储\n",
    "   - 设置自动清理策略（保留最近 N 个版本）\n",
    "\n",
    "3. **分支管理**：\n",
    "   - 为分支添加语义标签（如 `branch: \"alternative_solution\"`）\n",
    "   - 可视化工具展示状态树（类似 Git Graph）\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **总结**\n",
    "LangGraph 的时间旅行功能通过：\n",
    "1. **状态快照**：自动保存每一步的完整上下文  \n",
    "2. **精确回溯**：通过 `thread_id + step_id` 定位历史状态  \n",
    "3. **分支执行**：从任意节点衍生新路径  \n",
    "\n",
    "实现了 **\"可逆计算\"** 能力，解决了 AI Agent 工作流的**关键痛点**：\n",
    "- 探索不确定性时的试错成本  \n",
    "- 错误传导导致的推倒重来  \n",
    "- 多方案对比的重复执行  \n",
    "\n",
    "> 开发者建议：在涉及**复杂决策链**（如科研分析、代码生成）的场景中优先集成此功能，为用户提供 **\"撤销/重试/分支探索\"** 的核心交互体验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed671b-8bf5-431f-8dee-6a4c61595b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 设置自定义API配置\n",
    "os.environ[\"QWEN_API_KEY\"] = \"You API Key\"\n",
    "os.environ[\"QWEN_API_BASE\"] = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "# 使用自定义配置\n",
    "llm = init_chat_model(\n",
    "    model=\"qwen-plus-latest\",\n",
    "    model_provider=\"openai\",\n",
    "    api_key=os.environ[\"QWEN_API_KEY\"],\n",
    "    base_url=os.environ[\"QWEN_API_BASE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2878c7-793e-4128-8258-be4907134d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2649c908-3ef8-45fb-a6fb-26f08d0a8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "@tool\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc9bb7a-9cd7-4113-9bd0-191c4f355512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help you with that. Could you provide me with more details on what specific aspects of LangGraph you're interested in? For example, are you looking for an overview of its features, tutorials on how to use it, or something else?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4ba39b-4f35-4c2c-a3cb-e8675789699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great plan! LangGraph is well-suited for building agents as it allows you to define complex workflows with ease. Here are some key points and steps that can help guide your project of building an autonomous agent:\n",
      "\n",
      "### **Key Concepts in LangGraph**\n",
      "1. **Graph-Based Workflows**: LangGraph lets you model workflows as graphs, making it easier to visualize and manage the flow of data and execution.\n",
      "2. **Modular Components**: You can create modular components (nodes) representing specific tasks or functions, which can be reused across different workflows.\n",
      "3. **State Management**: It provides tools to manage state effectively, allowing agents to remember previous interactions and make decisions based on historical data.\n",
      "4. **Integration with LLMs**: LangGraph integrates seamlessly with large language models (LLMs), enabling you to build intelligent agents capable of reasoning and decision-making.\n",
      "\n",
      "### **Steps to Build an Autonomous Agent Using LangGraph**\n",
      "1. **Define the Goal**:\n",
      "   - Clearly outline what your agent should achieve. For example, is it a customer service chatbot, a personal assistant, or something else?\n",
      "\n",
      "2. **Design the Workflow**:\n",
      "   - Use LangGraph's graph-based approach to design how your agent will process inputs, make decisions, and generate outputs. Identify nodes for each task (e.g., input parsing, decision-making, response generation).\n",
      "\n",
      "3. **Implement Nodes**:\n",
      "   - Develop individual components (nodes) for each step in the workflow. These could include prompt templates, LLM calls, external API integrations, or custom logic.\n",
      "\n",
      "4. **Integrate State Management**:\n",
      "   - Implement mechanisms for your agent to store and retrieve context from past interactions. This helps in providing personalized and coherent responses.\n",
      "\n",
      "5. **Test and Iterate**:\n",
      "   - Test your agent thoroughly to ensure it behaves as expected under various scenarios. Refine the workflow and node implementations based on feedback.\n",
      "\n",
      "6. **Deploy and Monitor**:\n",
      "   - Deploy your agent to the desired environment and monitor its performance. Make improvements based on real-world usage and user feedback.\n",
      "\n",
      "If you're looking for tutorials or examples to get started, I can guide you to resources or provide sample code snippets tailored to your use case. Let me know if you'd like to dive deeper into any of these areas!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d914d7-dc4d-4f80-950f-5713d6dcba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ac13b9-966f-4b77-b3c2-8294147c684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f061241-0473-6e16-8006-fd937852f970'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c10458b-4b0c-4d39-94c7-c2b81f9bf0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help you with that. Could you provide me with more details on what specific aspects of LangGraph you're interested in? For example, are you looking for an overview of its features, tutorials on how to use it, or something else?\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383a924-4f80-4620-8e18-8eb4a6a29efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
