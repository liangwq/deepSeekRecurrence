{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906daecd-5f47-4d9c-b8cd-56d71c78a950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca9f69-79e9-4d67-b12d-5747e3f541a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 设置自定义API配置\n",
    "os.environ[\"QWEN_API_KEY\"] = \"You API Key\"\n",
    "os.environ[\"QWEN_API_BASE\"] = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "# 使用自定义配置\n",
    "llm = init_chat_model(\n",
    "    model=\"qwen-plus-latest\",\n",
    "    model_provider=\"openai\",\n",
    "    api_key=os.environ[\"QWEN_API_KEY\"],\n",
    "    base_url=os.environ[\"QWEN_API_BASE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39958d1-5a73-4880-8e28-90abc5a1290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07bc487e-86a0-4ec3-a129-2bccbed7e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 开始生成报告...\n",
      "📋 规划完成，共 10 个章节\n",
      "🔄 处理章节: 引言：AI 技术的发展与教育变革\n",
      "🔄 处理章节: 个性化学习的实现路径\n",
      "🔄 处理章节: 生成式 AI 的基本原理与功能\n",
      "🔄 处理章节: 教学内容的自动化生成与优化\n",
      "🔄 处理章节: 智能辅导与学习评估系统\n",
      "🔄 处理章节: 教师角色的转变与能力提升\n",
      "🔄 处理章节: 教育公平与技术普及的挑战\n",
      "🔄 处理章节: 伦理与隐私保护问题探讨\n",
      "🔄 处理章节: 未来教育生态的重构与展望\n",
      "🔄 处理章节: 政策支持与教育 AI 的健康发展\n",
      "✅ 完成章节: 伦理与隐私保护问题探讨\n",
      "✅ 完成章节: 引言：AI 技术的发展与教育变革\n",
      "✅ 完成章节: 教学内容的自动化生成与优化\n",
      "✅ 完成章节: 未来教育生态的重构与展望\n",
      "✅ 完成章节: 个性化学习的实现路径\n",
      "✅ 完成章节: 教师角色的转变与能力提升\n",
      "✅ 完成章节: 智能辅导与学习评估系统\n",
      "✅ 完成章节: 生成式 AI 的基本原理与功能\n",
      "✅ 完成章节: 教育公平与技术普及的挑战\n",
      "✅ 完成章节: 政策支持与教育 AI 的健康发展\n",
      "📝 合并 10 个章节\n",
      "\n",
      "==================================================\n",
      "📊 最终报告:\n",
      "==================================================\n",
      "# 生成式 AI 如何重塑教育\n",
      "\n",
      "根据您的修改意见，我对原文进行了优化，增强了段落间的逻辑衔接、提升了语言的精准度，并补充了具体案例以增强说服力。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## AI 技术的发展与教育变革  \n",
      "\n",
      "人工智能技术的飞速发展正在深刻影响教育的各个方面。从智能辅导系统到个性化学习路径，AI 不仅改变了传统教学模式，还为学生提供更具针对性的学习体验。通过分析学习数据，AI 能够识别个体差异，自动调整教学内容和节奏，从而提升学习效率，弥补传统课堂中“一刀切”教学方式的不足。例如，某些智能辅导平台已能够根据学生的答题记录实时调整题目难度与讲解策略，实现真正意义上的因材施教。\n",
      "\n",
      "尽管 AI 在教学中展现出巨大潜力，其广泛应用仍面临一系列现实挑战。在技术层面，当前的 AI 系统在面对复杂的教育场景时，仍存在适应性不足的问题。学习数据的稀疏性和算法模型的局限性，可能导致个性化推荐出现偏差，从而影响教学效果。此外，随着 AI 在教学中的深入应用，教师的角色也发生了变化。教育者不再只是知识的传授者，而需转变为学习的引导者和情感的支持者。如何在技术辅助下保持人文关怀，是教育工作者必须思考的重要课题。\n",
      "\n",
      "在此基础上，AI 也在推动教学方法的革新。它促进了协作式学习、项目式学习等新型教学模式的发展，使课堂更加互动和高效。未来，随着 AI 技术的不断成熟，其与教育的深度融合将持续推进教学理念、方法与评价体系的革新，为构建更加公平、高效的教育体系提供可能。\n",
      "\n",
      "---\n",
      "\n",
      "如您所见，修改后的内容在逻辑结构上更清晰，语言表达更为准确，同时加入了实际案例来支撑观点，整体更具条理性和说服力。欢迎继续提出宝贵意见！\n",
      "\n",
      "---\n",
      "\n",
      "根据您的意见，我对原文进行了全面改写和润色，重点提升语言的专业性、逻辑性和表达的准确性。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI 的基本原理与功能  \n",
      "\n",
      "生成式 AI（Generative AI）是一种基于深度学习的模型技术，区别于主要用于分类或预测任务的判别式模型（Discriminative Model），它能够从大量数据中学习潜在的数据分布，并据此生成此前不存在的内容。这些内容可以是文本、图像、音频、视频等多种形式，具有高度的真实感和多样性。其核心技术通常依赖于大型语言模型（LLM）或多模态模型，通过捕捉数据中的复杂模式来实现高质量输出。\n",
      "\n",
      "生成式 AI 的工作流程主要包括四个关键阶段，每个阶段均涉及具体的技术手段和优化方法：\n",
      "\n",
      "1. **数据收集**：构建生成式 AI 模型的第一步是获取高质量且多样化的训练数据集。数据来源广泛，可能包括公开文本、图像库、音视频资料等。数据的广度与代表性直接影响模型的泛化能力。\n",
      "\n",
      "2. **模型训练**：在该阶段，模型通常采用如 Transformer 架构或扩散模型（Diffusion Model）等主流结构，利用大规模数据进行参数优化。训练过程中，反向传播算法被用于不断调整神经网络权重，以最小化生成误差。\n",
      "\n",
      "3. **内容生成**：一旦模型训练完成，用户可通过输入提示（prompt）引导模型生成所需内容。此过程常使用诸如 top-k 采样、温度调节（temperature scaling）等策略，以平衡生成结果的创造性与稳定性。\n",
      "\n",
      "4. **微调与优化**：为了提升特定场景下的性能，模型可进一步通过指令微调（Instruction Tuning）、人类反馈强化学习（RLHF）等方式进行迭代优化，从而增强其对特定任务的理解与响应能力。\n",
      "\n",
      "Google 推出的 Gemini 系列模型便是生成式 AI 技术的典型代表，具备强大的多模态处理能力，能够同时理解并生成文字、图像、视频等内容。这些模型已被广泛应用于智能客服、自动写作、数据分析、创意辅助等多个领域，为个人用户与企业组织带来了显著的效率提升。\n",
      "\n",
      "然而，随着技术的快速发展，生成式 AI 也面临一系列现实挑战。例如，模型可能因知识边界不清而产生“幻觉”现象，即输出看似合理但实际错误的信息；训练数据中若包含敏感个人信息，可能导致隐私泄露风险；此外，AI 所生成内容的版权归属问题尚无明确法律界定，这在一定程度上影响了其在商业场景中的合规应用。\n",
      "\n",
      "因此，在充分利用生成式 AI 所带来创新价值的同时，也需要加强对技术伦理、数据安全及法律规范的重视，推动人工智能技术的可持续、负责任发展。\n",
      "\n",
      "--- \n",
      "\n",
      "如果您需要将这段内容用于特定场合（如学术论文、产品介绍、行业报告等），我也可以根据用途进一步调整语气与风格。\n",
      "\n",
      "---\n",
      "\n",
      "以下是根据您提供的三条具体改进意见，对原文进行的重写版本。修改内容包括术语定义、段落衔接优化和语言精准化，以提升文章的**准确性、逻辑性和可读性**。\n",
      "\n",
      "---\n",
      "\n",
      "### 二、生成式 AI：个性化学习的新引擎  \n",
      "\n",
      "生成式人工智能（Generative AI），尤其是基于深度学习的大语言模型（如 GPT、BERT 等），具备根据输入内容生成高质量文本的能力，为个性化学习提供了前所未有的技术支持。这类技术不仅能够理解自然语言，还能根据不同场景生成具有逻辑性和连贯性的回应，使其在教育领域展现出巨大潜力。\n",
      "\n",
      "与传统教学系统相比，生成式 AI 能够根据学生的学习风格、知识掌握情况和兴趣偏好，实时生成个性化的教学内容和互动反馈，真正实现“千人千面”的学习体验。这种高度定制化的学习方式，有助于提高学生的接受度和学习成效。\n",
      "\n",
      "在智能辅导系统中，生成式 AI 可以模拟教师的角色，通过自然语言处理技术与学生进行深度对话，理解其认知水平并提供针对性指导。以一个实际应用为例，“苏格拉底游乐园”是一款基于大语言模型构建的智能辅导系统，采用苏格拉底式提问法引导学生思考。它通过层层递进的问题，激发学生主动探索答案的兴趣，进而促进其批判性思维和问题解决能力的发展。这一案例展示了生成式 AI 在促进深度学习方面的独特优势。\n",
      "\n",
      "此外，生成式 AI 还能辅助教师设计个性化作业、生成多样化练习题，并根据学生的作答情况动态调整难度，形成闭环反馈机制。例如，系统可根据学生错误类型自动推送解析、补充知识点讲解或推荐相关练习，从而帮助学生查漏补缺，提高学习效率的同时增强其学习主动性与参与感。\n",
      "\n",
      "当然，生成式 AI 在教育中的应用仍面临挑战，如内容准确性、伦理风险和技术依赖等问题。因此，在推进个性化学习的过程中，必须建立科学的技术应用框架，确保 AI 辅助教育的质量与安全，推动人机协同教学向更高效、更公平的方向发展。\n",
      "\n",
      "---\n",
      "\n",
      "如需进一步调整文风、扩展某部分内容或适配特定受众（如学术研究者、教育从业者或普通读者），欢迎继续提出需求，我将为您进一步润色与优化。\n",
      "\n",
      "---\n",
      "\n",
      "根据您提供的修改意见，我对原文进行了系统性的优化，增强了段落间的逻辑衔接、补充了数据来源以提升可信度，并精炼了语言表达。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## 教学内容的智能化生成与优化\n",
      "\n",
      "人工智能的迅猛发展正在深刻改变教育领域，尤其是在教学内容的智能化生成与优化方面展现出巨大潜力。AI技术能够根据教材内容自动拆解知识点，生成结构化的教学要点，为教师提供科学、系统的教学参考。例如，一些数学在线教育平台已实现通过AI分析教材章节，自动生成知识点图谱，从而显著提升备课效率与教学质量。\n",
      "\n",
      "除了在知识组织方面的优势，AI在教学形式的多样化呈现上也发挥着重要作用。它可以根据教学内容智能生成配图，增强学生的理解力。在几何教学中，AI可根据知识点自动生成图形演示，使抽象概念变得直观易懂。此外，AI还能生成多种风格的授课逐字稿与视频，满足不同学习风格的学生需求。多样的风格提升教学吸引力，使课堂更具互动性与趣味性。\n",
      "\n",
      "在知识输出与巩固环节，AI技术同样展现出显著优势。AI可自动生成练习题与详细解题步骤，实现个性化练习与即时反馈，帮助学生高效掌握所学内容。根据英国教育部2023年发布的《AI在教育中的应用报告》，45%的英国教师表示使用AI工具后每周节省两小时备课时间，而超过40%的美国教师也实现了类似的时间节约效果。更重要的是，AI的应用不仅提升了教学效率，还增强了教师的教学热情与职业认同感，推动了教育创新的持续发展。\n",
      "\n",
      "总体来看，借助AI技术，教学内容正朝着更智能、更精准、更个性化的方向演进，为教育质量的提升注入强大动力。\n",
      "\n",
      "---\n",
      "\n",
      "如需进一步调整语气或风格以适应特定用途（如学术论文、宣传文案等），可继续细化润色。\n",
      "\n",
      "---\n",
      "\n",
      "根据您的意见，我对原文进行了针对性修改，重点增强了论据支撑、优化了逻辑衔接，并提升了语言的可读性。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## 智能辅导与学习评估系统：生成式 AI 的革新力量  \n",
      "\n",
      "随着人工智能技术的飞速发展，生成式 AI 在教育领域的应用正逐步深化，尤其在作业批改、学习分析和智能辅导等方面展现出巨大潜力。例如，《教育技术研究》期刊曾发表一项对比研究指出，在数学等结构化较强的学科中，使用智能辅导系统的学生平均成绩提升幅度与接受一对一人类教师辅导的学生相当，甚至在某些认知推理任务上表现更优。这一发现表明，智能辅导系统在提升学习成果方面已具备与人类导师相媲美的能力，为个性化学习提供了坚实的技术支持。\n",
      "\n",
      "当前，智能辅导系统的实现方式主要分为两类：基于传统计算机交互和基于自然语言的对话交互。前者通过点击、拖拽等操作引导学生完成学习任务，后者则借助自然语言处理技术，模拟教师与学生进行一对一交流，增强学习的沉浸感和灵活性。这些交互方式不仅提升了学习体验，也为后续的学习评估提供了丰富的行为数据基础。\n",
      "\n",
      "在此基础上，生成式 AI 能够利用智能分析工具，对学生的作业和考试进行自动批改，并提供精准且个性化的反馈。AI 可依据学生的答题记录、学习路径等行为数据构建“学习者画像”——即对学生知识掌握情况、学习习惯和认知风格的综合分析。基于这些信息，系统能够实施自适应评估，动态调整题目难度，并给出符合个体需求的学习建议。此外，情感计算技术的应用也使 AI 的反馈更具人性化，能够在识别学生情绪状态的基础上给予鼓励或安抚，从而降低焦虑情绪，提升学习积极性。\n",
      "\n",
      "未来，随着算法模型的不断优化和技术能力的持续提升，生成式 AI 将在教育领域发挥更大作用，推动教学模式向智能化、个性化方向演进，真正实现“因材施教”的教育理想。\n",
      "\n",
      "---\n",
      "\n",
      "如需进一步润色或针对特定受众（如学术论文、科普文章等）调整语气，请随时告知。\n",
      "\n",
      "---\n",
      "\n",
      "根据您的意见，我对原文进行了修改与优化，重点提升了语言表达的准确性与多样性、段落之间的逻辑衔接性，并增强了引用内容的论证力度。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "在人工智能迅速渗透教育领域的背景下，教师的角色正经历着深刻的变革。传统以知识传授为核心的教学职责，正在逐步转向以学习引导、思维启发与创造力培养为核心的新定位。教师不再仅仅是课程的执行者，而应成为学生个性化学习路径的设计者和终身学习的积极促进者。\n",
      "\n",
      "这一角色转型对教师提出了更高的素养要求。面对人工智能生成的海量信息，教师需要具备信息甄别能力，能够判断其教育价值，并引导学生进行深度学习与复杂问题的解决。与此同时，教师还需掌握智能技术的基本原理与教学应用方法，理解人工智能的工作机制，并能在教学实践中灵活运用，例如通过AI工具实现差异化教学、精准化评价等目标。\n",
      "\n",
      "然而，当前许多教师对人工智能的认知仍停留在工具层面，缺乏对其伦理影响与教育融合路径的深入理解。冯剑峰等（2024）通过对全国多所中小学教师的调研发现，超过六成受访教师对人工智能的理解局限于技术操作层面，忽视了其在教学重构、师生关系调整及伦理责任等方面的重要意义。这种认知局限在一定程度上削弱了教师在AI环境下的教学判断力与决策能力。\n",
      "\n",
      "在此背景下，构建系统化的教师人工智能素养框架显得尤为迫切。联合国教科文组织提出的能力模型涵盖“以人为中心的理念”、“AI伦理意识”、“基础技术理解与实践应用”等多个维度，强调教师不仅应具备技术操作能力，更需拥有教育使命感与人文关怀。唯有如此，教师才能在人工智能时代真正实现育人价值的升华，推动教育向更高层次发展。\n",
      "\n",
      "---\n",
      "\n",
      "如您所见，修改后的内容在语言表达上更具多样性和学术性，段落之间增加了过渡语句，使逻辑推进更加自然顺畅，同时补充了引用研究的具体背景与数据支持，增强了论证的说服力。希望这个版本符合您的预期。\n",
      "\n",
      "---\n",
      "\n",
      "以下是根据您的意见对原文进行的**全面修改与优化版本**，重点加强了论据的具体性、深化了教师角色的分析，并提升了语言表达的逻辑性与流畅度：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI：教育公平的“双刃剑”？\n",
      "\n",
      "生成式 AI 在推动教育公平方面展现出前所未有的潜力。它可以根据不同学生的学习特点和进度，动态生成个性化教学内容，为资源匮乏地区的学生提供更优质的学习机会。同时，AI 技术还能有效降低教育资源获取成本，通过国家智慧教育平台等公共渠道实现资源共享，让更多学生受益。\n",
      "\n",
      "尽管潜力巨大，AI 在推动教育公平的过程中仍面临多重挑战。其中最显著的问题便是日益加剧的数字鸿沟。根据联合国儿童基金会2023年的报告，全球仍有超过三分之一的学龄儿童无法稳定接入互联网，这直接限制了他们在 AI 教育环境下的学习机会。此外，AI 教育产品的质量参差不齐，也影响了其在实际教学中的应用效果。例如，在印度农村地区，由于网络基础设施薄弱，许多学校难以有效部署 AI 教学工具，导致技术红利难以惠及全体学生。\n",
      "\n",
      "与此同时，算法偏见也可能带来新的不公平现象。某些 AI 教育系统在训练数据中存在性别或地域偏差，可能导致对特定群体的误判或忽视，从而加剧教育资源分配的不平衡。\n",
      "\n",
      "在此背景下，教师的角色显得尤为关键。教师不仅是知识的传递者，更是 AI 技术的监督者与引导者。他们可以通过智能批改系统提升作业反馈效率，利用数据分析识别学生的薄弱环节，进而实施更具针对性的教学干预。更重要的是，教师应具备识别和纠正算法偏见的能力，引导学生批判性地使用 AI 生成的内容，培养其信息鉴别力和技术伦理意识。\n",
      "\n",
      "为此，教师培训体系亟需做出相应调整。未来的教师发展项目应纳入数据素养、人工智能基础以及技术伦理等内容，帮助教师更好地适应 AI 赋能的教学环境。芬兰在推进 AI 教育普及过程中，就特别强调了教师数字能力的系统化提升，这一经验值得借鉴。\n",
      "\n",
      "英国教育部的实践表明，虽然大多数教育工作者认可 AI 的教学价值，但也对其潜在风险表示担忧，包括学术诚信问题、技术依赖带来的教学异化，以及可能扩大的教育差距。因此，政府需要加强政策引导，完善数字基础设施建设，开展面向师生的 AI 素养培训，并建立相应的伦理规范与监管机制，确保 AI 技术真正服务于教育公平的目标。\n",
      "\n",
      "总而言之，生成式 AI 是一把“双刃剑”。它既有可能成为缩小教育差距的利器，也有可能因使用不当而加剧教育不平等。关键在于我们如何制定合理的制度框架、提升教育主体的技术素养，并以人文关怀为出发点，引导这项技术朝着促进公平、包容与可持续的方向发展。\n",
      "\n",
      "---\n",
      "\n",
      "### 修改亮点总结：\n",
      "\n",
      "| 改进方向 | 具体体现 |\n",
      "|----------|-----------|\n",
      "| 增强论据具体性 | 引用联合国儿童基金会报告、提及印度农村和芬兰的案例 |\n",
      "| 深化教师角色分析 | 明确教师作为 AI 使用者、监督者和引导者的三重角色，提出培训体系建设建议 |\n",
      "| 优化语言表达 | 使用更精准的术语，增加过渡句，强化段落之间的逻辑衔接 |\n",
      "\n",
      "如需进一步扩展某一部分（如教师培训体系、国际比较研究等），欢迎继续提出！\n",
      "\n",
      "---\n",
      "\n",
      "根据您的意见，我对原文《人工智能在教育中的伦理风险》进行了全面修改与优化，重点增强了论据支撑、逻辑深度和结论的实践指导性。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## 人工智能在教育中的伦理风险\n",
      "\n",
      "人工智能技术的迅猛发展正在深刻改变教育领域，但其应用也带来了诸多伦理挑战。在享受技术红利的同时，我们更应警惕其背后潜藏的风险，确保教育公平与学生权益不被技术逻辑所侵蚀。\n",
      "\n",
      "首先，**数据隐私泄露**是AI教育应用中最突出的伦理问题之一。AI系统依赖大量学生数据进行训练和优化，这些数据通常包括学习记录、行为模式、甚至面部识别等生物特征信息。然而，当前许多教育平台在数据采集、存储与使用过程中缺乏透明度和安全保障。例如，2021年某知名在线教育平台因数据库未加密，导致超过百万名学生的姓名、住址和学习记录被非法访问，暴露了AI教育系统在数据管理方面的脆弱性。此类事件不仅侵犯了学生的基本隐私权，也可能被用于商业操控甚至身份盗用，后果严重。\n",
      "\n",
      "其次，**算法偏见与决策歧视**问题同样不容忽视。AI模型的训练数据若存在偏差，可能在成绩评估、升学推荐、个性化学习路径规划等关键环节中加剧教育不公。例如，若某AI成绩评估系统主要基于城市学生的答题数据训练，可能无法准确评估农村学生的实际能力，从而在升学推荐中产生系统性歧视。这种偏见往往源于训练数据的历史局限、样本代表性不足或算法设计中的隐性假设，最终导致某些群体在教育资源分配中处于不利地位。此外，AI系统的“黑箱”特性使得其决策过程缺乏透明度，教师和学生难以理解或质疑其判断，从而削弱了教育的公平性和可问责性。\n",
      "\n",
      "最后，**人机交互的普及可能弱化师生之间的情感联结**。尽管AI教学工具在提升教学效率方面具有显著优势，但过度依赖智能系统会减少真实互动的机会，导致教育过程中的情感温度下降。教育不仅是知识传递的过程，更是情感交流与价值观塑造的过程。缺乏人际互动的教育环境可能影响学生的社交能力、情绪调节能力以及心理健康成长。\n",
      "\n",
      "因此，在推动AI教育应用的同时，必须建立完善的伦理规范与法律保障体系，以确保技术服务于教育本质。具体而言，**政府应制定AI教育数据使用的法律框架，明确数据采集、存储与使用的边界；学校需设立伦理审查委员会，对AI教学工具进行合规性评估；技术公司则应增强算法透明度与可解释性，推动公平性测试与偏见修正机制**。只有多方协作、责任共担，才能构建一个安全、公正、以人为本的智能教育生态，真正实现公平、安全与人性化的教育愿景。\n",
      "\n",
      "---\n",
      "\n",
      "通过上述修改，文章在以下方面得到了显著提升：\n",
      "\n",
      "- **增强说服力**：引入了真实案例（如2021年教育平台数据泄露事件），使论据更具现实基础；\n",
      "- **深化逻辑链条**：明确了算法偏见的形成机制，并结合教育场景说明其影响；\n",
      "- **提升实践指导意义**：在结论部分提出了可操作的政策建议与责任主体，增强了文章的现实针对性和可行性。\n",
      "\n",
      "如需进一步优化语言风格或调整结构，欢迎继续提出建议。\n",
      "\n",
      "---\n",
      "\n",
      "根据您的意见，我对原文进行了系统性优化，重点提升了论证逻辑的严密性、教师转型路径的深度阐释以及语言表达的专业性和可读性。以下是修改后的文章：\n",
      "\n",
      "---\n",
      "\n",
      "## 教师转型与AI共融：构建未来教育生态的核心驱动力\n",
      "\n",
      "生成式人工智能（AI）正以前所未有的速度重塑全球教育格局，教师的角色也因此面临深刻变革。面对技术浪潮，与其担忧被取代，不如主动拥抱转型。未来的教师将不再仅仅是知识的传授者，而应成为学习的引导者、数据的分析者以及教育AI的协同共创者。在此背景下，教师具备基本的数据素养，能够理解并解读AI生成的学习报告，并据此动态调整教学策略，将成为其专业能力的重要组成部分。\n",
      "\n",
      "生成式AI不仅提升了教学效率，更为实现联合国可持续发展目标四（SDG4）——“确保包容和公平的优质教育”提供了现实路径。例如，AI驱动的智能辅导系统可根据学生的学习行为提供个性化反馈，有效弥补传统课堂中因资源不均导致的教学质量差异。据联合国教科文组织2023年发布的报告，AI辅助教学已在非洲部分地区显著提升了基础教育阶段的学习成效，尤其在识字率和数学能力方面表现突出。这些案例充分说明，AI技术正在为弥合教育资源鸿沟提供切实可行的解决方案。\n",
      "\n",
      "然而，要实现教师角色的成功转型，仅提出愿景远远不够。当前教师普遍缺乏与AI协同教学所需的专业支持体系。为此，亟需从多个层面推动教师发展路径的重构：一是建立系统的教师AI素养培训课程，涵盖数据分析、人机协作教学设计等核心技能；二是推动政策层面的支持机制，如将AI素养纳入教师资格认证标准；三是鼓励学校开展校本实践，探索适应不同教学场景的人机协同模式，并制定相应的教学评估标准。唯有如此，教师才能真正胜任新时代教育生态系统中的关键角色。\n",
      "\n",
      "当然，AI在教育中的应用也伴随着伦理与治理挑战。隐私保护、算法偏见和技术依赖等问题需要引起高度重视。正如澳大利亚教育专家Andrew Smith所指出的：“只有在安全与道德的基础上，AI才能真正促进教育公平，而非加剧已有不平等。”因此，建立健全的教育AI伦理规范和制度保障体系，是实现技术赋能教育的前提条件。\n",
      "\n",
      "展望未来，教育生态将逐步演变为人机协同的新范式。教师与AI将在持续互动中共同构建灵活、高效的教学互动结构，推动教学创新不断深化。将AI素养纳入教师专业发展的核心标准，不仅是应对技术变革的必然选择，更是建设一个更具包容性、适应性和发展性学习社会的关键一步。\n",
      "\n",
      "--- \n",
      "\n",
      "通过上述修改，文章在逻辑结构上更加严谨，内容更具实证支撑和现实指导意义，同时语言表达更趋专业化与清晰化，有助于提升整体学术价值与传播效果。\n",
      "\n",
      "---\n",
      "\n",
      "根据您的意见，我对原文进行了系统性修改与优化，重点在增强论据支撑、提升结构条理、强化语言专业性等方面作出调整。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "### 政策法规与伦理建设护航 AI 教育健康发展\n",
      "\n",
      "人工智能技术的迅猛发展正在深刻重塑教育生态，其在教学内容、学习方式、评价机制等方面的广泛应用，亟需健全的政策法规体系与伦理规范框架提供制度保障。AI教育涉及大规模数据采集、算法决策支持和个性化学习路径设计等关键环节，若缺乏有效监管，极易引发隐私泄露、算法歧视、教育不公等风险。近年来，国内外已有多个案例表明，AI在教育领域的不当应用可能对师生权益造成实质性损害。\n",
      "\n",
      "例如，2023年某地试点AI作文评分系统时，因训练数据存在地域与文化偏见，导致部分少数民族地区学生的作文得分明显偏低，暴露出算法偏差带来的评估不公问题。此外，2022年某在线教育平台发生学生个人信息泄露事件，影响数万名用户，凸显出数据安全立法与执行层面的短板。这些现实问题警示我们：必须加快完善相关法律法规，明确AI在教育场景中的权责边界，确保其应用符合法律规范和程序正义要求。\n",
      "\n",
      "---\n",
      "\n",
      "#### 一、加强法律制度建设，夯实治理基础\n",
      "\n",
      "当前，应加快推进人工智能领域专门立法进程，修订《教育法》《个人信息保护法》《数据安全法》等相关条款，构建覆盖数据采集、处理、共享全过程的法律框架。尤其要针对教育场景中敏感信息的使用范围、存储期限与访问权限进行细化规定，切实保障师生的数据权利与信息安全。\n",
      "\n",
      "同时，可探索制定《AI教育应用伦理法》，从法律层面确立AI教育产品开发、部署、评估各阶段的伦理审查机制，明确开发者、运营方与使用者的责任归属，推动形成权责清晰、监管有力的治理体系。\n",
      "\n",
      "---\n",
      "\n",
      "#### 二、推进伦理教育体系建设，培育科技素养\n",
      "\n",
      "除了制度约束，教育本身也应成为引导AI向善的重要途径。应在各级教育体系中系统性融入人工智能伦理课程内容，从小培养学生对技术的理性认知与道德判断能力。例如，在中小学开设“人工智能伦理导论”选修课，引导学生思考技术背后的公平、透明与责任问题；在高校设立AI伦理研究方向，培养具备跨学科视野的专业人才。\n",
      "\n",
      "此外，可通过举办“青少年AI伦理论坛”等活动，汇聚学生、家长、教师与专家学者多方力量，共同探讨AI教育的伦理边界与实践路径，形成社会共识与价值导向。\n",
      "\n",
      "---\n",
      "\n",
      "#### 三、构建多元共治机制，推动协同治理\n",
      "\n",
      "AI教育治理不能仅依赖政府主导，还需建立由企业、学校、科研机构、社会组织等多方参与的协同治理机制。应鼓励行业组织制定自律公约，推动形成透明、公正、可追溯的AI治理标准。同时，建立健全第三方评估机制，定期对AI教育产品的伦理合规性、算法公平性进行独立审核。\n",
      "\n",
      "在此基础上，还应加强国际交流与合作，借鉴欧盟《人工智能法案》、联合国教科文组织《人工智能伦理建议书》等国际经验，提升我国AI教育治理的全球适应力与话语权。\n",
      "\n",
      "---\n",
      "\n",
      "正如习近平总书记所强调：“要把握人工智能发展趋势，完善法律法规与伦理准则，构建风险预警与治理体系。”唯有将法治思维与伦理意识深度融合于AI教育发展的全过程，才能真正实现技术服务于教育公平与个性化成长的目标，推动社会可持续发展。未来，随着政策法规的不断完善与伦理机制的持续优化，人工智能将在教育领域释放更大潜能，助力构建更加智能、公平、包容的教育新生态。\n",
      "\n",
      "--- \n",
      "\n",
      "如您所见，本次改写在保留原意的基础上，增强了实证材料支撑、优化了论述结构，并提升了语言的专业性与准确性，整体更具说服力与学术规范性。是否还需要进一步细化某一部分？\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ---------- 1. 全局 LLM & 工具 ----------\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)  # 修复：取消注释\n",
    "search = TavilySearchResults(max_results=3)\n",
    "\n",
    "# ---------- 2. 数据结构 ----------\n",
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"Section title\")\n",
    "    description: str = Field(description=\"Section description\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"List of report sections\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    plan: List[Section]\n",
    "    drafts: Annotated[List[str], operator.add]\n",
    "    final_report: str\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    drafts: Annotated[List[str], operator.add]  # 修复：匹配状态键\n",
    "\n",
    "# ---------- 3. Plan-and-Solve：生成大纲 ----------\n",
    "planner = llm.with_structured_output(Plan)\n",
    "\n",
    "def plan_node(state: State):\n",
    "    # 修复：添加 JSON 关键词\n",
    "    prompt = f\"\"\"为\"{state['topic']}\"写一份详细的大纲，每节含标题和 20 字描述。\n",
    "    \n",
    "    请以 JSON 格式返回，包含以下结构：\n",
    "    {{\n",
    "        \"sections\": [\n",
    "            {{\"title\": \"章节标题\", \"description\": \"章节描述\"}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    plan = planner.invoke([\n",
    "        SystemMessage(content=\"你是一个专业的报告规划师，请按照 JSON 格式返回报告大纲。\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    return {\"plan\": plan.sections}\n",
    "\n",
    "# ---------- 4. ReAct：联网搜集 ----------\n",
    "def research(section: Section) -> str:\n",
    "    try:\n",
    "        query = f\"{section.title} {section.description}\"\n",
    "        docs = search.invoke(query)\n",
    "        return \"\\n\".join([d[\"content\"][:500] for d in docs])\n",
    "    except Exception as e:\n",
    "        print(f\"搜索错误: {e}\")\n",
    "        return f\"无法获取 {section.title} 的相关信息\"\n",
    "\n",
    "# ---------- 5. Worker：写作 + Reflection ----------\n",
    "writer_prompt = \"\"\"你是一名专栏作家。\n",
    "标题：{title}\n",
    "描述：{desc}\n",
    "素材：{material}\n",
    "请用 Markdown 写一篇 400 字左右的正文，不要前言。\n",
    "\"\"\"\n",
    "\n",
    "critic_prompt = \"\"\"请对以下文字提出 3 条具体改进意见：\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "def worker_node(state: WorkerState):\n",
    "    print(f\"🔄 处理章节: {state['section'].title}\")\n",
    "    \n",
    "    material = research(state['section'])\n",
    "    \n",
    "    # 初稿\n",
    "    draft1 = llm.invoke(writer_prompt.format(\n",
    "        title=state['section'].title,\n",
    "        desc=state['section'].description,\n",
    "        material=material\n",
    "    )).content\n",
    "    \n",
    "    # 反思\n",
    "    critique = llm.invoke(critic_prompt.format(text=draft1)).content\n",
    "    \n",
    "    # 重写\n",
    "    draft2 = llm.invoke(\n",
    "        f\"根据意见重写：\\n意见：{critique}\\n原文：{draft1}\"\n",
    "    ).content\n",
    "    \n",
    "    print(f\"✅ 完成章节: {state['section'].title}\")\n",
    "    return {\"drafts\": [draft2]}  # 修复：返回 drafts 而不是 draft\n",
    "\n",
    "# ---------- 6. Map-Reduce：并行分发 ----------\n",
    "def dispatch(state: State):\n",
    "    print(f\"📋 规划完成，共 {len(state['plan'])} 个章节\")\n",
    "    return [Send(\"worker\", {\"section\": s}) for s in state[\"plan\"]]\n",
    "\n",
    "# ---------- 7. 合并节点 ----------\n",
    "def merge(state: State):\n",
    "    print(f\"📝 合并 {len(state['drafts'])} 个章节\")\n",
    "    full = f\"# {state['topic']}\\n\\n\"\n",
    "    full += \"\\n\\n---\\n\\n\".join(state[\"drafts\"])\n",
    "    return {\"final_report\": full}\n",
    "\n",
    "# ---------- 8. 构建图 ----------\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"plan\", plan_node)\n",
    "graph_builder.add_node(\"worker\", worker_node)\n",
    "graph_builder.add_node(\"merge\", merge)\n",
    "\n",
    "graph_builder.add_edge(START, \"plan\")\n",
    "graph_builder.add_conditional_edges(\"plan\", dispatch, [\"worker\"])\n",
    "graph_builder.add_edge(\"worker\", \"merge\")\n",
    "graph_builder.add_edge(\"merge\", END)\n",
    "\n",
    "app = graph_builder.compile()\n",
    "\n",
    "# ---------- 9. 运行 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 开始生成报告...\")\n",
    "    topic = \"生成式 AI 如何重塑教育\"\n",
    "    result = app.invoke({\"topic\": topic})\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📊 最终报告:\")\n",
    "    print(\"=\"*50)\n",
    "    print(result[\"final_report\"])  # 修复：去掉多余的冒号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75722ee5-4c12-4808-9a1a-fa9b37910c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 开始生成报告...\n",
      "📋 规划完成，共 10 个章节\n",
      "🔄 处理章节 2: 生成式 AI 在教育中的应用\n",
      "🔄 处理章节 1: 引言：生成式 AI 的兴起\n",
      "🔄 处理章节 3: 个性化学习的实现\n",
      "🔄 处理章节 5: 教师角色的转变\n",
      "🔄 处理章节 6: 学生能力的培养\n",
      "🔄 处理章节 4: 教育资源的普及与公平\n",
      "🔄 处理章节 7: 数据隐私与伦理问题\n",
      "🔄 处理章节 8: 技术局限与挑战\n",
      "🔄 处理章节 9: 未来教育模式的展望\n",
      "🔄 处理章节 10: 结论与建议\n",
      "✅ 完成章节 9: 未来教育模式的展望\n",
      "✅ 完成章节 2: 生成式 AI 在教育中的应用\n",
      "✅ 完成章节 3: 个性化学习的实现\n",
      "✅ 完成章节 5: 教师角色的转变\n",
      "✅ 完成章节 10: 结论与建议\n",
      "✅ 完成章节 7: 数据隐私与伦理问题\n",
      "✅ 完成章节 1: 引言：生成式 AI 的兴起\n",
      "✅ 完成章节 4: 教育资源的普及与公平\n",
      "✅ 完成章节 6: 学生能力的培养\n",
      "✅ 完成章节 8: 技术局限与挑战\n",
      "📝 合并 10 个章节\n",
      "\n",
      "==================================================\n",
      "📊 最终报告:\n",
      "==================================================\n",
      "# 生成式 AI 如何重塑教育\n",
      "\n",
      "## 引言：生成式 AI 的兴起\n",
      "\n",
      "以下是根据您的意见对原文进行修改后的版本，重点优化了段落间的逻辑衔接、语言表达的精炼性以及术语解释的可读性：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI 的源起与发展\n",
      "\n",
      "生成式人工智能是一类能够主动创造内容的人工智能技术，涵盖文本、图像、音频、视频等多种形式。它通过学习已有数据的模式与结构，生成全新的内容，展现出强大的创造力。其核心价值在于“生成”——不仅限于识别或分类，而是具备创新的能力，为人类社会带来前所未有的可能性。\n",
      "\n",
      "生成式 AI 的历史可以追溯到 1966 年，由 MIT 教授 Joseph Weizenbaum 开发的聊天机器人 Eliza 是早期探索之一。尽管受限于当时的计算能力和数据规模，Eliza 的表现较为有限，但它为后来的对话系统奠定了基础。真正推动这一领域发展的，是深度学习技术的兴起。1986 年，Geoffrey Hinton 提出反向传播算法，这是一种让神经网络通过误差反馈不断调整参数、提升性能的方法，为后续生成模型的发展提供了关键技术支撑。\n",
      "\n",
      "随着深度学习的不断演进，2014 年生成对抗网络（GAN）的提出成为生成式 AI 发展的重要里程碑。GAN 通过两个神经网络相互博弈的方式，使 AI 能够生成高度逼真的图像，标志着生成能力的重大突破。此后，基于 Transformer 架构的 GPT 系列模型在自然语言处理领域掀起变革。Transformer 是一种新型神经网络架构，极大提升了模型理解和生成长文本的能力。特别是 2022 年 ChatGPT 的问世，让公众首次广泛体验到 AI 在内容生成方面的强大潜力。\n",
      "\n",
      "如今，DALL-E、GPT-4 等先进模型不断拓展 AI 创造力的边界，应用已覆盖创意艺术、内容创作、科学研究等多个领域。生成式 AI 的发展不仅是技术创新的体现，更是人类探索智能本质的重要一步。随着其影响力日益扩大，如何在激发创造力的同时确保伦理规范与可控性，将成为未来发展的关键课题。\n",
      "\n",
      "---\n",
      "\n",
      "如您所见，本文在以下几个方面进行了优化：\n",
      "\n",
      "- **增强了段落之间的逻辑衔接**：例如在从 Eliza 过渡到深度学习时添加了承上启下的语句，使时间线和技术演进更连贯。\n",
      "- **避免了重复表达，提升了语言精炼度**：合并了“自主生成新内容”和“创造出全新且独特的数据实例”等相似表述，使语言更为简洁有力。\n",
      "- **提升了术语解释的易懂性**：对“反向传播算法”、“Transformer 架构”等专业术语进行了简明解释或类比说明，增强文章的可读性和普及性。\n",
      "\n",
      "如有需要，还可进一步根据目标读者群体调整语言风格或术语深度。\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI 在教育中的应用\n",
      "\n",
      "根据您的意见，我对原文进行了有针对性的润色与优化，重点加强了段落之间的过渡、语言表达的多样性以及结尾的总结力度。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI：重塑大学教育的新力量  \n",
      "\n",
      "生成式 AI 正以前所未有的速度渗透进大学校园，深刻改变着学生的学习方式与教师的教学模式。从文本写作、问题解答到图像生成、创意设计，人工智能工具的应用已覆盖多个学习与生活场景。大学生借助这些智能系统，不仅提高了学习效率，也在潜移默化中推动着教育形态的变革。\n",
      "\n",
      "在学生积极运用 AI 提升学习效果的同时，教师也在积极探索其在教学中的应用潜力。在学习过程中，学生利用智能技术快速获取知识启发、优化作业质量，并尝试将其应用于研究与创作之中。他们期望这类技术不仅能提供信息支持，更能成为思维的引导者，帮助其深入理解复杂概念并解决实际问题。与此同时，教师则开始尝试借助 AI 辅助课程设计、制作教学视频、生成个性化反馈等，从而释放更多精力用于因材施教和教学创新。\n",
      "\n",
      "然而，AI 在教育中的广泛应用也带来了诸多挑战：学生如何学会有效提问？教师又该如何提升数字素养，以驾驭这一新兴教学辅助工具？评估机制应如何调整，以适应 AI 参与的学习过程？这些问题提醒我们，在拥抱技术进步的同时，更需构建合理的规范体系，使智能系统真正服务于教育的本质——激发思考、促进成长。\n",
      "\n",
      "**唯有在规范引导下合理利用生成式 AI，才能真正实现教育质量的全面提升与人才培养模式的持续创新。**\n",
      "\n",
      "---\n",
      "\n",
      "如您所见，本次修改围绕逻辑衔接、语言多样性和主旨强化三个方面展开，整体结构更加清晰，语言更具表现力，结尾也更有说服力。希望这个版本符合您的预期！\n",
      "\n",
      "---\n",
      "\n",
      "## 个性化学习的实现\n",
      "\n",
      "根据您提供的修改意见，我对原文进行了优化，提升了逻辑连贯性、数据支撑力以及语言的专业性和准确性。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI：重塑个性化学习的新引擎  \n",
      "\n",
      "传统教育模式通常采用统一标准开展教学，难以兼顾每位学生的个体差异。而生成式 AI 的崛起，为实现真正意义上的个性化学习提供了可能。通过深度分析学生的学习数据与行为模式，生成式 AI 能够动态调整教学内容的难度与呈现方式，为不同水平的学生提供量身定制的学习路径。\n",
      "\n",
      "在课堂中，生成式 AI 可扮演虚拟助教角色，实时解答学生疑问，提供一对一辅导，增强互动体验并提升学习效率。除此之外，AI 还具备强大的内容生成能力，能够根据教学需求定制多样化学习资源，甚至模拟真实实验环境，让学生在沉浸式场景中动手实践，从而有效提升理解力与创造力。研究表明（如 2023 年某教育科技期刊发表的研究），使用 AI 辅助学习的学生在学习成绩和作业质量方面，相较传统教学组平均提升了约 15%，体现出明显的学习成效优势。\n",
      "\n",
      "此外，生成式 AI 还能推动教学评价从“结果导向”转向“过程驱动”。通过持续追踪学生的学习轨迹，教师可获得精准的学情反馈，并基于详细的学习轨迹分析，及时识别学生的认知盲区并实施差异化干预，从而实现精细化教学。随着 AI 技术的不断演进，教育正逐步从“千人一面”的标准化模式转向“千人千面”的个性化发展路径，助力每位学习者构建契合自身特点的成长体系。\n",
      "\n",
      "---\n",
      "\n",
      "**说明：**\n",
      "\n",
      "- **段落逻辑更清晰**：在“虚拟助教”之后加入过渡句，自然引出“内容生成”功能，使段落结构更流畅。\n",
      "- **增强说服力**：对研究结论补充了来源假设和具体数据，提升可信度。\n",
      "- **语言更具专业性**：将部分口语化表述替换为更具学术色彩的语言，增强了表达的精准度和专业感。\n",
      "\n",
      "此版本更适合用于学术论文、政策建议或高质量科普文章等正式写作场景。\n",
      "\n",
      "---\n",
      "\n",
      "## 教育资源的普及与公平\n",
      "\n",
      "以下是根据您提供的三条具体改进意见，对原文进行的全面修改与润色版本。文章在**逻辑性、表达准确性与论证深度**方面均有显著提升：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI：教育公平的新引擎？\n",
      "\n",
      "生成式 AI 正在重塑教育资源的分配方式，为实现教育公平提供前所未有的新路径。传统教育中，优质资源往往集中于发达地区，而边远和农村地区则长期面临师资匮乏、教学内容滞后等问题。生成式 AI 的兴起，正在打破这一壁垒——通过智能生成个性化学习内容，它能让不同地区的学生共享高质量教育资源，缩小地域间的教育差距。\n",
      "\n",
      "以国家智慧教育平台为例，AI 技术接入后，不仅提升了资源获取效率，也大幅降低了教育成本。例如，2023 年数据显示，在云南某边远县区推广 AI 辅助教学后，学生英语平均分提高了 15%，教师备课时间减少了 30%。这类实证数据表明，AI 不仅改变了资源供给的方式，更在实际教学中产生了可衡量的积极影响，成为推动教育公平的重要工具。\n",
      "\n",
      "然而，技术革新带来的不仅是机遇，也有不容忽视的挑战。生成式 AI 教育产品的开发与部署往往需要大量资金支持，而经济欠发达地区的学校难以承担这些初期投入。若缺乏政府补贴与统一规划，这种技术将优先服务于城市富裕家庭，反而使弱势群体进一步边缘化，从而加剧教育资源的两极分化。此外，政策引导不足可能导致市场主导下的技术应用偏离公共教育目标，使得“数字鸿沟”非但未被弥合，反而被进一步扩大。\n",
      "\n",
      "与此同时，教师角色也在经历深刻转型。他们不再只是知识的传授者，而需转变为学习的设计者与引导者，具备课程设计、数据分析与个性化指导的能力。然而，这一转变并非一蹴而就。许多乡村教师仍面临信息技术素养不足、培训机会有限、工作负担加重等现实困境。教师转型不仅是技能更新，更是系统性教育改革的重要一环，必须辅以制度保障、专业培训与心理支持，才能真正实现从“教书”到“育人”的跨越。\n",
      "\n",
      "因此，在推动生成式 AI 应用的同时，政府与社会应加强基础设施建设，补贴弱势地区，并开展多层次、差异化的教师培训计划，确保技术红利惠及所有人。唯有在技术发展与制度保障并重的前提下，AI 才能真正成为教育公平的助推器，而非新的分化工具。\n",
      "\n",
      "---\n",
      "\n",
      "### 总结\n",
      "\n",
      "本改写版本在以下三方面进行了强化：\n",
      "\n",
      "1. **增强论据支撑**：补充了具体案例与数据（如云南某地的英语成绩提升），增强了论证的说服力；\n",
      "2. **明确因果关系**：清晰梳理了“高投入—资源分配不均—数字鸿沟扩大”的逻辑链条，突出了政策干预的必要性；\n",
      "3. **深化现实洞察**：拓展了教师角色转变的讨论维度，涵盖能力要求、现实困难与支持体系，提升了文章的思想深度与现实针对性。\n",
      "\n",
      "通过以上调整，文章整体更具逻辑性、实证性和批判性，能够更好地服务于学术或政策讨论场景。\n",
      "\n",
      "---\n",
      "\n",
      "## 教师角色的转变\n",
      "\n",
      "以下是根据您提供的修改意见对原文进行的重写，重点提升了语言表达的精准性、段落结构的逻辑性，并增强了内容的思想深度与说服力：\n",
      "\n",
      "---\n",
      "\n",
      "## 教师角色的重塑：从知识传授者到育人枢纽  \n",
      "\n",
      "生成式人工智能的迅猛发展，正以前所未有的速度重构教育生态。教师的角色也正在发生深刻转变——由传统的“教学权威”逐步演进为连接技术、学生与社会的“育人枢纽”。在传统课堂中，教师作为知识的主要来源，主导着学习节奏与内容传递；而在AI赋能的教育环境中，知识获取变得更加多元和即时。教师的核心价值不再局限于知识传授，而应转向引导学生形成正确的价值观、培养批判性思维能力与社会情感技能。\n",
      "\n",
      "### 一、从“教材搬运工”到“资源库建构者”  \n",
      "\n",
      "面对AI生成的海量信息与多模态资源，教师的任务已不再是简单地照本宣科，而是需要成为信息的筛选者、整合者与重构者。他们需围绕核心概念构建弹性化的教学体系，将外部资源与课程目标有机融合，打造以知识点为锚、拓展资源为云支持的教学生态系统。例如，一些学校已经开始引入AI辅助平台，教师通过设定个性化学习路径，结合学生的兴趣与认知水平，设计出“一生一案”的教学方案，从而实现真正意义上的因材施教。\n",
      "\n",
      "此外，除了教学内容的重构，教师在AI时代还肩负着更重要的育人使命。\n",
      "\n",
      "### 二、从“讲台上的权威”到“成长中的陪伴者”  \n",
      "\n",
      "在人机协同的教育新图景中，教师的角色不再只是知识的传递者，更应是学生成长过程中的情感陪伴者与价值引领者。尽管AI可以提供精准的数据反馈和学习建议，但它无法替代教师对学生心理状态的敏锐洞察与人文关怀。研究表明，在情感支持充足的课堂环境中，学生的学习动机与自我效能感显著提升。因此，教师需要具备更强的沟通能力和共情意识，帮助学生在面对复杂信息与快速变化的社会时，建立稳定的价值观与积极的人生态度。\n",
      "\n",
      "### 三、从“被动适应者”到“教育创新的推动者”  \n",
      "\n",
      "未来教师不仅是课堂教学的设计者，更是教育变革的积极参与者。面对技术的冲击，教师需要主动探索新的教学模式与评估方式，推动教育理念的更新与实践的突破。例如，北京某中学率先尝试“双师课堂”模式，将AI智能助手与教师协同授课相结合，不仅提高了教学效率，也促使教师不断反思与优化教学策略。这类实践表明，教师只有不断提升自身的数字素养与创新能力，才能在教育现代化进程中发挥关键作用。\n",
      "\n",
      "---\n",
      "\n",
      "**结语：**  \n",
      "在人工智能日益渗透教育领域的当下，教师的角色虽面临挑战，但也蕴含前所未有的机遇。唯有从知识传授者转型为育人枢纽，教师才能在新时代的教育格局中站稳脚跟，真正成为学生成长道路上不可或缺的引路人与守护者。\n",
      "\n",
      "---\n",
      "\n",
      "## 学生能力的培养\n",
      "\n",
      "以下是根据您提供的具体意见对原文进行的重写版本。新版在**逻辑衔接、论证具体性与语言表达**三个方面进行了优化，使文章更具条理性、说服力和可读性：\n",
      "\n",
      "---\n",
      "\n",
      "## 生成式 AI 重塑学生能力发展的挑战与机遇  \n",
      "\n",
      "生成式人工智能正在深刻影响教育领域，尤其在学生技能培养方面展现出巨大潜力。通过个性化学习内容的生成和即时反馈机制，AI 能够根据学生的兴趣、节奏和能力调整教学方式，从而提升学习效率。然而，这一技术的应用也伴随着多重挑战。\n",
      "\n",
      "除了对学生思维能力的影响，生成式 AI 的广泛应用也对教育体系本身提出了新的挑战。一方面，它可能削弱学生的独立思考能力和问题解决能力。若学生习惯于依赖 AI 解决问题，而缺乏自主探索的过程，将可能导致批判性思维和创造力的下降。此外，AI 生成内容的质量尚不稳定。例如，在历史或科学等学科中，AI 可能会生成不准确的时间线或错误的因果推断，进而误导学生的知识构建过程。这种信息的不确定性和相关性不足，使得学生容易陷入知识掌握的表面化陷阱。\n",
      "\n",
      "另一方面，现有教育制度和政策尚未完全适应 AI 技术的发展。例如，部分高校已对毕业论文中 AI 使用的比例作出限制，以防止学术不端行为的发生。同时，AI 的广泛应用也对教师角色提出了新要求——教师不仅需要掌握生成式 AI 等技术工具的使用方法，还应注重培养学生提出问题、评估信息来源、进行跨学科思考以及创造新知识的能力。\n",
      "\n",
      "未来，学校应注重构建人机协同的教学模式，引导学生在利用 AI 提升效率的同时，保持独立判断和深度思考的能力。只有在技术与人文教育之间找到平衡，才能真正实现生成式 AI 对学生技能发展的积极促进作用。\n",
      "\n",
      "---\n",
      "\n",
      "如需进一步扩展为完整论文、添加参考文献或细化某一部分内容，欢迎继续提供需求，我可以协助您完善。\n",
      "\n",
      "---\n",
      "\n",
      "## 数据隐私与伦理问题\n",
      "\n",
      "根据您的原文以及提出的三条改进建议，我对文章进行了全面重写与优化，重点增强段落之间的逻辑衔接、补充具体案例以提升说服力，并细化结论中的建议内容。以下是修改后的版本：\n",
      "\n",
      "---\n",
      "\n",
      "### 数据隐私与伦理问题：生成式 AI 在教育中的挑战\n",
      "\n",
      "随着生成式人工智能（AI）在教育领域的广泛应用，其在提升教学效率和个性化学习方面的潜力日益显现。然而，技术的迅猛发展也带来了诸多挑战，尤其是在数据隐私和伦理规范方面，亟需引起重视。\n",
      "\n",
      "**首先，数据隐私管理构成了生成式 AI 教育应用的核心难题。**  \n",
      "教育大数据不仅涵盖学生的基本信息和学习行为，还可能涉及家庭背景等敏感内容。一旦这些数据被不当采集、存储或泄露，可能对学生及其家庭造成严重后果。例如，某在线学习平台因系统漏洞导致数万名学生的个人信息外泄，引发公众对数据安全的广泛担忧。因此，如何在提供个性化服务的同时，确保数据的合法合规使用，成为当前亟待解决的关键议题。\n",
      "\n",
      "**除了数据隐私问题，生成式 AI 的使用还可能带来一系列更深层次的负面影响。**  \n",
      "学生若长期依赖 AI 提供的答案，可能会削弱其自主思考能力和创造力。此外，AI 生成内容中也可能潜藏偏见。例如，在某些历史课程辅助系统中，AI 因训练数据偏向西方视角，而忽视或误读亚洲国家的历史经验；又如，据一项研究指出，AI 教育工具在处理性别相关问题时，倾向于强化传统性别角色认知。这些问题不仅影响教育公平，也可能加剧社会偏见，值得警惕。\n",
      "\n",
      "**上述问题背后，反映出一个更为根本的挑战——即当前 AI 教育应用在伦理规范方面的缺失。**  \n",
      "目前，AI 教育产品的开发者、使用者和监管者之间责任界限模糊，缺乏统一的行业标准和伦理准则。这导致“算法歧视”频发，且出现问题后难以追责。例如，当 AI 推荐的学习资源存在偏见时，究竟是开发者、平台运营方还是教师应承担责任？这种权责不清的局面阻碍了 AI 在教育中的健康发展。\n",
      "\n",
      "面对以上挑战，我们应从技术、制度和教学实践三个层面构建更具操作性的治理框架：\n",
      "\n",
      "- **在技术层面**，应推动开源 AI 教育模型的发展，便于审查算法透明性，同时加强数据加密、访问权限控制等手段，保障数据全生命周期的安全。\n",
      "- **在制度层面**，建议由教育部牵头设立 AI 教育伦理委员会，制定统一的数据采集、使用和共享标准，明确各方权责，建立问责机制。\n",
      "- **在教学实践层面**，应将“AI 批判素养”纳入课程体系，鼓励教师引导学生审慎评估 AI 输出内容，培养其独立思考与技术反思能力。\n",
      "\n",
      "唯有通过多方协同努力，才能真正实现生成式 AI 与教育的深度融合，让技术服务于人的全面发展，而非带来新的风险与不公。\n",
      "\n",
      "--- \n",
      "\n",
      "如您希望进一步调整语气风格、压缩字数或适配特定用途（如学术论文、报告或演讲稿），也可以继续告诉我，我会为您进一步优化。\n",
      "\n",
      "---\n",
      "\n",
      "## 技术局限与挑战\n",
      "\n",
      "以下是根据您提供的三条具体改进意见，对原文进行重写后的版本。新版本在逻辑结构、论证深度和实践指导性方面均有明显提升：\n",
      "\n",
      "---\n",
      "\n",
      "### 生成式AI在教育中的技术局限与挑战\n",
      "\n",
      "随着生成式人工智能（AI）逐渐渗透到教育领域，其潜力与问题并存。本文将从**技术能力限制**与**算法偏见影响**两个层面，探讨该技术在教育应用中所面临的现实挑战。这两方面不仅反映了AI当前发展阶段的局限，也揭示了其在社会伦理层面可能引发的深层问题。\n",
      "\n",
      "首先，大型语言模型（LLMs）在教育环境中存在显著的技术局限。它们依赖于已有数据进行内容生成，因此在处理开放性或需要创造性思维的问题时，往往难以提供准确或富有洞见的答案。例如，2023年一项关于GPT-4在教育场景下的评估发现，其在开放性写作任务中出现事实性错误的比例高达15%。此外，学生若过度依赖这些工具，可能会削弱独立思考与问题解决能力，从而影响学习效果。\n",
      "\n",
      "除了技术本身的能力限制，生成式AI在训练数据上的依赖性还带来了更深层次的社会伦理问题。LLMs通过吸收大量互联网文本进行学习，而这些数据中常常包含性别、种族和社会阶层等方面的偏见。有研究表明，某些语言模型在处理“职业”相关问题时，更倾向于将男性与“工程师”关联，女性与“护士”关联。这种隐性偏见可能在教学材料生成、作业评估等环节中被放大，进而加剧教育中的不平等问题。同时，不同国家和人群在使用LLMs时的体验差异，也反映出技术普及过程中的不平衡现象。\n",
      "\n",
      "上述两方面的挑战并非孤立存在，而是相互交织、共同作用。技术局限可能导致AI输出质量不稳定，而算法偏见则进一步放大了教育中的结构性不平等。要有效应对这些问题，必须采取系统性策略。\n",
      "\n",
      "一方面，应开展系统的人工智能教学工作坊，帮助教师识别AI生成内容的潜在错误，并学会引导学生进行交叉验证，从而提升其信息辨别能力。另一方面，学校应在课程中引入“AI素养”模块，教导学生质疑AI输出的合理性，培养批判性思维。此外，政府也应推动建立AI教育产品的透明审查机制，确保其算法公正性与文化包容性。\n",
      "\n",
      "只有通过技术、教育与政策多维度协同推进，才能真正实现生成式AI在教育领域的可持续发展，使其成为促进公平与质量提升的有力工具，而非新的不平等来源。\n",
      "\n",
      "--- \n",
      "\n",
      "如需进一步优化为学术论文段落或用于特定出版物格式，可继续调整语言风格与引用规范。\n",
      "\n",
      "---\n",
      "\n",
      "## 未来教育模式的展望\n",
      "\n",
      "以下是根据您提供的三条具体改进意见，对原文进行修改后的版本。调整重点在于增强逻辑衔接、避免语言重复，并提升论证深度和说服力：\n",
      "\n",
      "---\n",
      "\n",
      "## 未来教育模式的展望：生成式 AI 的机遇与挑战\n",
      "\n",
      "生成式人工智能正以前所未有的速度重塑教育模式。它不仅能够根据教学需求自动生成跨模态、个性化的教学资源，还能作为教师的智能助手，完成作业批改、错题分析、诊断反馈等任务，从而有效减轻教师的重复性工作负担，优化教学资源配置。\n",
      "\n",
      "除了在教学效率方面的显著提升，生成式 AI 还在教学方式和学习体验方面带来了深远变革。通过与虚拟现实（VR）、增强现实（AR）技术融合，AI 正在催生虚拟实验室、沉浸式历史课堂等新型教学场景。这种高度互动和沉浸的学习方式，有助于激发学生兴趣，提升实践能力。同时，在语言学习、科学实验、艺术创作等多个领域的广泛应用，也进一步推动了教育内容的多样化与个性化发展。\n",
      "\n",
      "然而，在拥抱技术红利的同时，我们也必须认清其局限。AI 生成内容的质量高度依赖于训练数据本身，存在偏见、错误甚至误导信息的风险。此外，有研究表明，过度依赖 AI 辅助写作的学生在独立完成复杂思维任务时表现较弱，说明长期使用可能削弱学生的批判性思维与自主学习能力。因此，教育者应引导学生学会提问、验证与反思，培养其判断力与创造力，而非简单复制 AI 提供的答案。\n",
      "\n",
      "面向未来，高校需加快构建人机协同的教学新范式，既要善用生成式 AI 提升教育效率，也要建立相应的伦理规范与使用边界。唯有如此，才能真正实现以学习者为中心的教育变革。\n",
      "\n",
      "---\n",
      "\n",
      "如您所见，修改后的内容在段落间增加了过渡语句，使整体结构更连贯；替换了部分重复表达，增强了语言的准确性和多样性；并引入了研究案例，提升了观点的可信度与说服力。希望这一版本能更好地满足您的要求。\n",
      "\n",
      "---\n",
      "\n",
      "## 结论与建议\n",
      "\n",
      "根据您提供的**三条具体改进意见**，我对原文进行了针对性修改与优化，强化了数据支撑、逻辑衔接和建议的可行性。以下是**修订后的版本**：\n",
      "\n",
      "---\n",
      "\n",
      "## 结论与建议\n",
      "\n",
      "生成式人工智能正以前所未有的速度重塑教育生态，在个性化教学、智能辅导、内容生成等方面展现出巨大潜力。据2024年联合国教科文组织发布的报告，全球已有超过60%的高等教育机构试点引入生成式AI进行个性化学习支持。以印度为例，该国已在全国范围内推广基于AI的编程课程，覆盖超过500万中小学生；加拿大则聚焦于企业培训领域，通过AI平台提升职业技能培训效率；我国也在加速推进教育类AI产品的落地进程。依托星火大模型、通义千问等通用大模型，以及各类教育垂类大模型的发展，生成式AI已在各级各类教育中广泛应用，推动教学形态向多元化、智能化方向演进。\n",
      "\n",
      "尽管生成式AI为教育带来了前所未有的机遇，但其快速渗透也引发了一系列值得警惕的问题。技术的快速发展可能导致学生对AI的认知依赖，影响其独立思考能力的培养；同时，评价体系尚未同步更新，AI辅助写作可能造成学术成果的真实性难以判断，进而带来评价失衡与学术诚信危机。因此，教育应用的设计与推广应以“增强人类能动性”为核心原则，鼓励AI作为学习工具辅助而非替代人的思维过程。\n",
      "\n",
      "为此，建议多方协同推进生成式AI在教育中的规范发展与合理应用：\n",
      "\n",
      "一是由**教育部牵头**，联合高校与科研机构开展跨学科研究，系统评估生成式AI对学生核心素养、课程体系、教学目标及评价方式的深层影响，形成科学决策依据；\n",
      "\n",
      "二是由**行业协会主导制定AI教育产品伦理标准与使用指南**，明确企业在开发与推广过程中的责任边界，确保技术应用符合教育伦理与公平原则；\n",
      "\n",
      "三是通过**国家级教师培训计划**，全面提升教师的AI素养与技术整合能力，使其能够有效引导学生合理使用智能工具，在激发创造力的同时规避技术依赖风险。\n",
      "\n",
      "唯有审慎应对、积极引导，并在政策、标准与师资建设方面协同发力，才能让生成式人工智能真正服务于高质量教育体系建设，实现技术赋能与育人本质的有机统一。\n",
      "\n",
      "---\n",
      "\n",
      "如需进一步细化某一建议措施、补充国际案例或增强语言风格的专业性，欢迎继续提出需求，我可以为您做进一步润色或扩展。\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ---------- 1. 全局 LLM & 工具 ----------\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "search = TavilySearchResults(max_results=3)\n",
    "\n",
    "# ---------- 2. 数据结构 ----------\n",
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"Section title\")\n",
    "    description: str = Field(description=\"Section description\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"List of report sections\")\n",
    "\n",
    "# 修改：添加带索引的章节结果\n",
    "class IndexedDraft(BaseModel):\n",
    "    index: int\n",
    "    content: str\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    plan: List[Section]\n",
    "    drafts: Annotated[List[IndexedDraft], operator.add]  # 修改：使用带索引的结果\n",
    "    final_report: str\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    index: int  # 修改：添加索引\n",
    "    drafts: Annotated[List[IndexedDraft], operator.add]\n",
    "\n",
    "# ---------- 3. Plan-and-Solve：生成大纲 ----------\n",
    "planner = llm.with_structured_output(Plan)\n",
    "\n",
    "def plan_node(state: State):\n",
    "    prompt = f\"\"\"为\"{state['topic']}\"写一份详细的大纲，每节含标题和 20 字描述。\n",
    "    \n",
    "    请以 JSON 格式返回，包含以下结构：\n",
    "    {{\n",
    "        \"sections\": [\n",
    "            {{\"title\": \"章节标题\", \"description\": \"章节描述\"}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    plan = planner.invoke([\n",
    "        SystemMessage(content=\"你是一个专业的报告规划师，请按照 JSON 格式返回报告大纲。\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    return {\"plan\": plan.sections}\n",
    "\n",
    "# ---------- 4. ReAct：联网搜集 ----------\n",
    "def research(section: Section) -> str:\n",
    "    try:\n",
    "        query = f\"{section.title} {section.description}\"\n",
    "        docs = search.invoke(query)\n",
    "        return \"\\n\".join([d[\"content\"][:500] for d in docs])\n",
    "    except Exception as e:\n",
    "        print(f\"搜索错误: {e}\")\n",
    "        return f\"无法获取 {section.title} 的相关信息\"\n",
    "\n",
    "# ---------- 5. Worker：写作 + Reflection ----------\n",
    "writer_prompt = \"\"\"你是一名专栏作家。\n",
    "标题：{title}\n",
    "描述：{desc}\n",
    "素材：{material}\n",
    "请用 Markdown 写一篇 400 字左右的正文，不要前言。\n",
    "\"\"\"\n",
    "\n",
    "critic_prompt = \"\"\"请对以下文字提出 3 条具体改进意见：\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "def worker_node(state: WorkerState):\n",
    "    print(f\"🔄 处理章节 {state['index'] + 1}: {state['section'].title}\")\n",
    "    \n",
    "    material = research(state['section'])\n",
    "    \n",
    "    # 初稿\n",
    "    draft1 = llm.invoke(writer_prompt.format(\n",
    "        title=state['section'].title,\n",
    "        desc=state['section'].description,\n",
    "        material=material\n",
    "    )).content\n",
    "    \n",
    "    # 反思\n",
    "    critique = llm.invoke(critic_prompt.format(text=draft1)).content\n",
    "    \n",
    "    # 重写\n",
    "    draft2 = llm.invoke(\n",
    "        f\"根据意见重写：\\n意见：{critique}\\n原文：{draft1}\"\n",
    "    ).content\n",
    "    \n",
    "    print(f\"✅ 完成章节 {state['index'] + 1}: {state['section'].title}\")\n",
    "    \n",
    "    # 修改：返回带索引的结果\n",
    "    indexed_draft = IndexedDraft(index=state['index'], content=draft2)\n",
    "    return {\"drafts\": [indexed_draft]}\n",
    "\n",
    "# ---------- 6. Map-Reduce：并行分发 ----------\n",
    "def dispatch(state: State):\n",
    "    print(f\"📋 规划完成，共 {len(state['plan'])} 个章节\")\n",
    "    # 修改：传递索引信息\n",
    "    return [Send(\"worker\", {\"section\": s, \"index\": i}) for i, s in enumerate(state[\"plan\"])]\n",
    "\n",
    "# ---------- 7. 合并节点 ----------\n",
    "def merge(state: State):\n",
    "    print(f\"📝 合并 {len(state['drafts'])} 个章节\")\n",
    "    \n",
    "    # 修改：按索引排序\n",
    "    sorted_drafts = sorted(state[\"drafts\"], key=lambda x: x.index)\n",
    "    \n",
    "    full = f\"# {state['topic']}\\n\\n\"\n",
    "    \n",
    "    # 按顺序组装内容\n",
    "    for i, draft in enumerate(sorted_drafts):\n",
    "        full += f\"## {state['plan'][draft.index].title}\\n\\n\"\n",
    "        full += draft.content\n",
    "        if i < len(sorted_drafts) - 1:\n",
    "            full += \"\\n\\n---\\n\\n\"\n",
    "    \n",
    "    return {\"final_report\": full}\n",
    "\n",
    "# ---------- 8. 构建图 ----------\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"plan\", plan_node)\n",
    "graph_builder.add_node(\"worker\", worker_node)\n",
    "graph_builder.add_node(\"merge\", merge)\n",
    "\n",
    "graph_builder.add_edge(START, \"plan\")\n",
    "graph_builder.add_conditional_edges(\"plan\", dispatch, [\"worker\"])\n",
    "graph_builder.add_edge(\"worker\", \"merge\")\n",
    "graph_builder.add_edge(\"merge\", END)\n",
    "\n",
    "app = graph_builder.compile()\n",
    "\n",
    "# ---------- 9. 运行 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 开始生成报告...\")\n",
    "    topic = \"生成式 AI 如何重塑教育\"\n",
    "    result = app.invoke({\"topic\": topic})\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📊 最终报告:\")\n",
    "    print(\"=\"*50)\n",
    "    print(result[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda3c07-6f64-47d8-a35b-49c0a70913a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10235ec9-4e93-4d7c-bc59-0de041fc5acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 启动增强版报告生成系统...\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 10 个章节\n",
      "🔄 处理章节 1: 引言：生成式 AI 的兴起\n",
      "🔄 处理章节 2: 教育领域的传统挑战\n",
      "🔄 处理章节 3: 生成式 AI 在教学中的应用\n",
      "🔄 处理章节 5: 教师角色的转变与支持\n",
      "🔄 处理章节 4: 个性化学习的实现\n",
      "🔄 处理章节 6: 评估与反馈机制革新\n",
      "🔄 处理章节 7: 教育资源公平性的影响\n",
      "🔄 处理章节 8: 伦理与隐私问题探讨\n",
      "🔄 处理章节 9: 未来教育模式的展望\n",
      "🔄 处理章节 10: 结论与行动建议\n",
      "🔍 搜索查询优化: 引言：生成式 AI 的兴起 介绍生成式 AI 技术的发展背景及其潜力。 -> \"生成式 AI 教育应用\" AND (\"技术发展\" OR \"潜力\") AND (2023 OR 2024) AND (权威研究 OR 学术报告)\n",
      "🔍 搜索查询优化: 教育资源公平性的影响 研究生成式 AI 在缩小教育鸿沟方面的潜在价值。 -> \"生成式 AI\" AND (\"教育资源公平\" OR \"教育鸿沟\") AND (impact OR effect) AND 2023..2024 AND (review OR study)\n",
      "🔍 搜索查询优化: 评估与反馈机制革新 分析 AI 在作业批改、学习效果评估中的作用。 -> \"生成式AI 作业批改 学习评估\" AND (\"教育技术\" OR \"智能教学\") AND (2020..2024) site:edu OR site:gov\n",
      "🔍 搜索查询优化: 教师角色的转变与支持 讨论 AI 技术如何改变教师职责并为其提供新工具。 -> \"生成式 AI 教育应用\" AND \"教师角色转变\" AND \"AI教学工具\" AND (2020..2024) AND (权威 OR 研究)\n",
      "🔍 搜索查询优化: 结论与行动建议 总结影响，并提出政策制定者和教育者的应对策略。 -> \"生成式 AI 教育影响\" AND (\"政策建议\" OR \"教学策略\") AND 2023..2024 AND (政府报告 OR 教育研究)\n",
      "🔍 搜索查询优化: 个性化学习的实现 展示生成式 AI 如何为不同学生提供定制化学习体验。 -> \"生成式AI\" AND \"个性化学习\" AND (\"教育应用\" OR \"教学创新\") AND (2020..2024) AND (权威性 site:edu OR site:org)\n",
      "🔍 搜索查询优化: 未来教育模式的展望 预测生成式 AI 推动下教育系统可能发生的变化趋势。 -> \"生成式AI 教育模式变革\" AND (\"未来教育趋势\" OR \"教育系统转型\") AND (2023 OR 2024) AND (权威报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 伦理与隐私问题探讨 审视 AI 教育应用中可能引发的数据安全和道德问题。 -> \"生成式 AI 教育应用\" AND (\"伦理\" OR \"隐私\") AND (\"数据安全\" OR \"道德问题\") AND (2020..2024) AND (权威来源)\n",
      "🔍 搜索查询优化: 教育领域的传统挑战 分析当前教育体系中存在的资源不均、个性化不足等问题。 -> \"教育公平性问题\" AND (\"资源分配不均\" OR \"个性化教育不足\") AND (生成式AI OR 教育技术) AND 出版年份:2020-2024\n",
      "🔍 搜索查询优化: 生成式 AI 在教学中的应用 探讨 AI 如何辅助课程设计与内容生成，提升教学效率。 -> \"生成式 AI 教学应用\" AND (\"课程设计\" OR \"内容生成\") AND (教育效率提升) AND (2023 OR 2024) AND (权威研究 OR 教育技术)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成章节 2: 教育领域的传统挑战\n",
      "✅ 完成章节 3: 生成式 AI 在教学中的应用\n",
      "✅ 完成章节 6: 评估与反馈机制革新\n",
      "✅ 完成章节 4: 个性化学习的实现\n",
      "✅ 完成章节 10: 结论与行动建议\n",
      "✅ 完成章节 1: 引言：生成式 AI 的兴起\n",
      "✅ 完成章节 7: 教育资源公平性的影响\n",
      "✅ 完成章节 5: 教师角色的转变与支持\n",
      "✅ 完成章节 9: 未来教育模式的展望\n",
      "✅ 完成章节 8: 伦理与隐私问题探讨\n",
      "📝 合并 10 个章节\n",
      "🔍 开始验证最终报告...\n",
      "📊 验证结果: 需要改进\n",
      "❌ 发现问题:\n",
      "  - 内容完整性部分缺失：引言部分改写内容仅覆盖了部分内容，未见后续章节如‘个性化学习的实现’、‘教师角色的转变’等的实际撰写内容。\n",
      "  - 逻辑性不足：由于仅提供引言部分详细内容，其他章节标题存在但无正文，无法判断整体报告逻辑是否自洽。\n",
      "  - 事实准确性存疑：部分数据来源标注模糊，如‘中国人工智能产业发展联盟’2028年预测值缺乏具体引用方式或原始链接支持；GPT-4o发布时间为2024年属于未来事件（当前时间为2025年7月）。\n",
      "  - 语言质量不一致：说明部分提到‘优化逻辑衔接：每段...’但后文被截断，影响理解优化程度。\n",
      "  - 结构合理性问题：目录与实际内容严重不匹配，仅提供引言内容，其余章节为空，结构失衡。\n",
      "💡 改进建议:\n",
      "  - 补充完整各章节正文内容，确保与目录对应，保障报告的整体性和系统性。\n",
      "  - 核实未来时间点的技术发布时间和数据预测来源，确保所有引用可查证并具有权威出处。\n",
      "  - 统一语言风格，在技术描述与政策分析之间保持专业性与通俗性的平衡。\n",
      "  - 增强章节间的过渡语句，提升段落之间的逻辑连贯性与阅读流畅度。\n",
      "  - 建议在图表或数据引用处添加脚注或尾注，便于读者追溯原始资料。\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 10 个章节\n",
      "🔄 处理章节 1: 引言：AI 技术的崛起\n",
      "🔄 处理章节 3: 生成式 AI 在教学中的应用\n",
      "🔄 处理章节 2: 教育现状与挑战\n",
      "🔄 处理章节 4: 个性化学习体验\n",
      "🔄 处理章节 5: 学生创新能力培养\n",
      "🔄 处理章节 7: 数据隐私与伦理问题\n",
      "🔄 处理章节 8: 教师角色的转变\n",
      "🔄 处理章节 9: 未来教育模式展望\n",
      "🔄 处理章节 10: 结论与建议\n",
      "🔄 处理章节 6: 教育资源公平分配\n",
      "🔍 搜索查询优化: 学生创新能力培养 分析 AI 工具如何激发学生的创造力和批判思维。 -> \"生成式AI AND (创新思维 OR 批判性思维) AND 教育应用 AND 2023..2024\"\n",
      "🔍 搜索查询优化: 教育现状与挑战 分析当前教育体系面临的主要问题和痛点。 -> \"教育现状\" AND (\"生成式AI\" OR \"人工智能教育\") AND (挑战 OR 问题) AND 时效性 2020-2024 AND 权威来源\n",
      "🔍 搜索查询优化: 结论与建议 总结 AI 对教育的影响并提出实施建议。 -> \"生成式 AI 教育影响\" AND (\"实施建议\" OR \"策略\") AND 2023..2024 AND (教育技术 OR 教学创新)\n",
      "🔍 搜索查询优化: 教师角色的转变 阐述在 AI 普及下教师职能的变化与适应。 -> \"生成式 AI 教育应用\" AND \"教师角色转变\" AND (\"2023\" OR \"2024\") AND (研究 OR 报告)\n",
      "🔍 搜索查询优化: 教育资源公平分配 讨论 AI 在弥合教育资源差距方面的潜力。 -> \"生成式AI 教育资源公平分配\" AND (\"教育技术\" OR \"AI教育\") AND 2023..2024 AND (政府报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 个性化学习体验 说明生成式 AI 如何实现因材施教的个性化学习。 -> \"生成式AI\" AND \"个性化学习\" AND (\"因材施教\" OR \"自适应学习\") AND 2023..2024 AND (\"教育技术\" OR \"智能教育\")\n",
      "🔍 搜索查询优化: 数据隐私与伦理问题 审视使用 AI 过程中涉及的学生隐私和伦理风险。 -> \"生成式 AI\" AND (\"数据隐私\" OR \"伦理问题\") AND 教育 AND 学生隐私 AND 2020..2024 AND (权威 OR 学术)\n",
      "🔍 搜索查询优化: 生成式 AI 在教学中的应用 探讨 AI 如何辅助教师提升教学质量与效率。 -> \"生成式 AI 教学应用\" AND (\"教育质量\" OR \"教学效率\") AND (2023 OR 2024) AND (教师 OR 教育者)\n",
      "🔍 搜索查询优化: 未来教育模式展望 预测生成式 AI 推动下的新型教育生态系统。 -> \"生成式AI 教育应用\" AND (\"未来教育模式\" OR \"教育生态系统\") AND 2023..2024 AND (研究 OR 报告)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 搜索查询优化: 引言：AI 技术的崛起 介绍生成式 AI 的发展及其技术潜力。 -> \"生成式 AI\" AND (\"教育应用\" OR \"教学创新\") AND (\"技术发展\" OR \"潜力\") AND (\"2023\" OR \"2024\") AND (site:edu OR site:gov)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成章节 7: 数据隐私与伦理问题\n",
      "✅ 完成章节 6: 教育资源公平分配\n",
      "✅ 完成章节 10: 结论与建议\n",
      "✅ 完成章节 3: 生成式 AI 在教学中的应用\n",
      "✅ 完成章节 8: 教师角色的转变\n",
      "✅ 完成章节 2: 教育现状与挑战\n",
      "✅ 完成章节 5: 学生创新能力培养\n",
      "✅ 完成章节 9: 未来教育模式展望\n",
      "✅ 完成章节 1: 引言：AI 技术的崛起\n",
      "搜索错误: 1 validation error for SearchResult\n",
      "results\n",
      "  Input should be a valid list [type=list_type, input_value=\"ConnectionError(Protocol...on without response')))\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/list_type\n",
      "✅ 完成章节 4: 个性化学习体验\n",
      "📝 合并 20 个章节\n",
      "🔍 开始验证最终报告...\n",
      "📊 验证结果: 需要改进\n",
      "❌ 发现问题:\n",
      "  - 目录中存在重复章节（如第2、16、18节等），导致结构混乱，影响内容完整性和逻辑性。\n",
      "  - 正文内容仅提供‘引言：生成式 AI 的兴起’部分，其余章节内容缺失，无法验证整体逻辑连贯性。\n",
      "  - 部分内容片段化严重（如“在中国，政府已将发展生成式AI作为...”被截断），信息不完整，影响事实准确性判断。\n",
      "  - 目录中某些章节标题高度相似（如第7与第8节、第13与第14节、第19与第20节），容易造成读者困惑。\n",
      "  - 语言表达上存在部分语义不清或冗余现象（如“改进后的版本”出现在引言开始前，缺乏上下文说明）。\n",
      "  - 未提供足够的数据来源和引用支持，如“据中国信息通信研究院数据”未注明具体年份或报告名称，影响可信度。\n",
      "💡 改进建议:\n",
      "  - 重新梳理目录结构，合并或重命名重复章节，确保章节编号与标题唯一对应。\n",
      "  - 补充完整的各章节内容以评估整体逻辑连贯性及章节间衔接。\n",
      "  - 对截断内容进行补全，确保每个段落表达完整，增强可读性与专业性。\n",
      "  - 明确标注数据来源、引用文献或调查方法，提升报告的权威性与可信度。\n",
      "  - 统一语言风格，去除冗余表述，优化段落过渡，提升整体语言质量。\n",
      "  - 建议在引言部分说明报告撰写目的、目标读者及结构安排，帮助读者理解框架。\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 10 个章节\n",
      "🔄 处理章节 2: 教育的现状与挑战\n",
      "🔄 处理章节 1: 引言：生成式 AI 的崛起\n",
      "🔄 处理章节 3: 生成式 AI 在教学中的应用\n",
      "🔄 处理章节 4: 个性化学习的实现\n",
      "🔄 处理章节 5: 内容创作与资源生成\n",
      "🔄 处理章节 6: 评估与反馈机制优化\n",
      "🔄 处理章节 8: 学生技能发展的新需求\n",
      "🔄 处理章节 7: 教师角色的转变\n",
      "🔄 处理章节 9: 伦理与隐私问题\n",
      "🔄 处理章节 10: 未来展望与发展趋势\n",
      "🔍 搜索查询优化: 教育的现状与挑战 分析当前教育体系中的主要问题与面临的挑战。 -> \"教育现状 挑战\" AND (\"生成式AI\" OR \"人工智能\") AND (2023 OR 2024) AND (权威报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 伦理与隐私问题 分析生成式 AI 在教育领域应用中的伦理与数据安全问题。 -> \"生成式 AI 伦理\" AND \"教育数据安全\" AND (\"隐私保护\" OR \"学生信息\") AND 2020..2024 AND (权威机构 OR 学术研究)\n",
      "🔍 搜索查询优化: 未来展望与发展趋势 预测生成式 AI 对教育行业的长期影响及可能的发展方向。 -> \"生成式AI 教育 长期影响 发展趋势\" AND (\"未来教育技术\" OR \"AI驱动教学\") AND 2023..2025 AND (来源:政府报告 OR 权威期刊)\n",
      "🔍 搜索查询优化: 学生技能发展的新需求 探索生成式 AI 环境中学生需要培养的关键能力。 -> \"生成式AI 教育 学生技能发展\" AND (\"关键能力\" OR \"核心素养\") AND (2020..2024) site:edu OR site:gov\n",
      "🔍 搜索查询优化: 生成式 AI 在教学中的应用 探讨生成式 AI 如何辅助教师进行课程设计和教学优化。 -> \"生成式 AI AND 教学应用 AND 课程设计 AND 教学优化\" site:.edu OR site:.gov AND \"2020..2024\"\n",
      "🔍 搜索查询优化: 个性化学习的实现 分析生成式 AI 如何为学生提供个性化的学习体验。 -> \"生成式 AI\" AND \"个性化学习\" AND (\"教育应用\" OR \"教学创新\") AND (2021..2025) AND (权威 OR 学术)\n",
      "🔍 搜索查询优化: 教师角色的转变 讨论在生成式 AI 影响下，教师职责的变化与提升方向。 -> \"生成式 AI 教育应用\" AND (\"教师角色转变\" OR \"教师职责变化\") AND (\"教育技术\" OR \"教学创新\") AND (\"2020..2024\" OR 最近五年)\n",
      "🔍 搜索查询优化: 评估与反馈机制优化 研究生成式 AI 在学生表现评估和反馈中的作用。 -> \"生成式AI 评估 学生表现 反馈机制\" AND (\"教育技术\" OR \"智能评估\") AND (\"2020..2024\" OR recent) AND (site:edu OR site:org)\n",
      "🔍 搜索查询优化: 内容创作与资源生成 展示生成式 AI 在教材编写、测试题生成等方面的应用。 -> 生成式AI 教材编写 测试题生成 教育应用 \"内容创作\"  AND (\"2023\" OR \"2024\") AND (site:edu OR site:org)\n",
      "🔍 搜索查询优化: 引言：生成式 AI 的崛起 介绍生成式 AI 技术的基本概念与发展背景。 -> \"生成式 AI\" AND (\"教育应用\" OR \"教学创新\") AND (\"技术发展\" OR \"背景\") AND (2020..2024) AND site:edu OR site:gov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成章节 9: 伦理与隐私问题\n",
      "✅ 完成章节 4: 个性化学习的实现\n",
      "✅ 完成章节 10: 未来展望与发展趋势\n",
      "✅ 完成章节 8: 学生技能发展的新需求\n",
      "✅ 完成章节 2: 教育的现状与挑战\n",
      "✅ 完成章节 6: 评估与反馈机制优化\n",
      "✅ 完成章节 3: 生成式 AI 在教学中的应用\n",
      "✅ 完成章节 7: 教师角色的转变\n",
      "✅ 完成章节 5: 内容创作与资源生成\n",
      "✅ 完成章节 1: 引言：生成式 AI 的崛起\n",
      "📝 合并 30 个章节\n",
      "🔍 开始验证最终报告...\n",
      "📊 验证结果: 需要改进\n",
      "❌ 发现问题:\n",
      "  - 目录部分存在大量重复章节标题，例如'引言：生成式 AI 的兴起'、'教育的现状与挑战'、'个性化学习的实现'、'教师角色的转变'等多次重复出现，严重影响结构清晰度和阅读逻辑。\n",
      "  - 报告内容仅展示了一个改进后的'引言：生成式 AI 的兴起'部分，其余章节内容缺失或未完整呈现（如在'尽管生成式AI...'处截断），导致无法全面验证内容完整性和逻辑性。\n",
      "  - 目录列出30个章节，但实际正文仅提供一个章节的部分内容，缺乏对应主体内容，无法判断章节间的连贯性和整体结构合理性。\n",
      "  - 引用数据较为具体（如中国79个大模型、清华试点课程等），但因内容不完整，无法核实所有事实准确性。\n",
      "  - 语言质量方面，引言部分内容表达清晰、专业性强，但由于内容截断，难以评估整体语言风格一致性。\n",
      "💡 改进建议:\n",
      "  - 删除目录中重复的章节标题，确保每个章节标题唯一且有实际对应内容。\n",
      "  - 补充完整的报告正文内容，尤其是核心章节如‘生成式 AI 在教学中的应用’、‘个性化学习’、‘教师角色变化’、‘伦理问题’等部分，以保证内容完整性。\n",
      "  - 明确各章节之间的逻辑关系，建议使用过渡句或段落增强章节间的连贯性。\n",
      "  - 对所引用的数据、政策文件及案例进行来源标注，并在完整内容基础上核查其准确性和时效性。\n",
      "  - 统一语言风格，避免术语混用或表述不一致；同时检查全文语法、标点和格式规范，提升可读性。\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 10 个章节\n",
      "🔄 处理章节 2: 传统教育的挑战与痛点\n",
      "🔄 处理章节 3: 生成式 AI 在教育中的角色\n",
      "🔄 处理章节 1: 引言：生成式 AI 的兴起\n",
      "🔄 处理章节 4: 个性化学习的新时代\n",
      "🔄 处理章节 5: 教师的角色转变与支持\n",
      "🔄 处理章节 6: 内容生成与课程开发创新\n",
      "🔄 处理章节 7: 智能评估与反馈机制\n",
      "🔄 处理章节 8: 教育公平与可及性的提升\n",
      "🔄 处理章节 9: 伦理与隐私问题的考量\n",
      "🔄 处理章节 10: 未来趋势与展望\n",
      "🔍 搜索查询优化: 个性化学习的新时代 展示生成式 AI 如何为每位学生提供定制化的学习体验。 -> \"生成式AI 个性化学习 教育应用\" AND (\"自适应学习系统\" OR \"智能教学助手\") site:.edu OR site:.gov AND 年份:2020-2024\n",
      "🔍 搜索查询优化: 未来趋势与展望 预测生成式 AI 在教育领域的发展方向及可能带来的变革。 -> \"生成式 AI 教育应用\" AND (\"未来趋势\" OR \"教育变革\") AND (2023 OR 2024) AND (权威报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 内容生成与课程开发创新 介绍生成式 AI 在课程设计、教材生成方面的创新应用。 -> \"生成式AI 课程设计 教材开发\" AND (\"教育创新\" OR \"教学改革\") AND (2020..2025) AND (权威期刊 OR 研究报告)\n",
      "🔍 搜索查询优化: 生成式 AI 在教育中的角色 探讨生成式 AI 如何辅助教学、评估和学习过程。 -> \"生成式 AI 教育应用\" AND (\"教学评估\" OR \"个性化学习\") AND 2023..2024 AND (site:edu OR site:gov)\n",
      "🔍 搜索查询优化: 传统教育的挑战与痛点 分析当前教育体系中存在的资源不均、个性化不足等问题。 -> \"生成式AI 教育应用\" AND (\"资源不均\" OR \"个性化不足\") AND 2023..2024 AND (教育研究 | 权威报告)\n",
      "🔍 搜索查询优化: 智能评估与反馈机制 说明 AI 如何实现自动评估并提供即时、精准的学习反馈。 -> \"生成式AI 教育评估\" AND (\"智能反馈\" OR \"即时评价\") site:edu OR site:gov 2020..2024\n",
      "🔍 搜索查询优化: 伦理与隐私问题的考量 探讨在教育中使用 AI 所涉及的伦理、隐私和数据安全问题。 -> \"生成式 AI 教育应用\" AND (\"伦理\" OR \"隐私保护\") AND (\"数据安全\" site:edu OR site:gov) 2020-2024\n",
      "🔍 搜索查询优化: 教育公平与可及性的提升 讨论生成式 AI 如何降低教育门槛，促进全球教育资源共享。 -> \"生成式 AI\" AND (\"教育公平\" OR \"教育资源共享\") AND (2020..2024) AND (开放获取 OR 开放教育资源)\n",
      "🔍 搜索查询优化: 教师的角色转变与支持 分析 AI 时代中教师职责的变化及如何借助 AI 提升效率。 -> \"生成式 AI 教育应用\" AND \"教师角色转变\" AND \"AI 辅助教学效率\" AND (2020..2024) AND (权威 OR 期刊 OR 研究)\n",
      "🔍 搜索查询优化: 引言：生成式 AI 的兴起 介绍生成式 AI 技术的发展及其在各行业的应用潜力。 -> \"生成式 AI\" AND (\"教育应用\" OR \"教学创新\") AND (\"2023\" OR \"2024\") site:edu OR site:gov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成章节 2: 传统教育的挑战与痛点\n",
      "✅ 完成章节 4: 个性化学习的新时代\n",
      "✅ 完成章节 1: 引言：生成式 AI 的兴起\n",
      "✅ 完成章节 8: 教育公平与可及性的提升\n",
      "✅ 完成章节 10: 未来趋势与展望\n",
      "✅ 完成章节 7: 智能评估与反馈机制\n",
      "✅ 完成章节 6: 内容生成与课程开发创新\n",
      "✅ 完成章节 9: 伦理与隐私问题的考量\n",
      "✅ 完成章节 5: 教师的角色转变与支持\n",
      "✅ 完成章节 3: 生成式 AI 在教育中的角色\n",
      "📝 合并 40 个章节\n",
      "🔍 开始验证最终报告...\n",
      "📊 验证结果: 需要改进\n",
      "❌ 发现问题:\n",
      "  - 目录部分存在大量重复章节标题，例如'引言：生成式 AI 的兴起'、'个性化学习的实现'、'教师角色的转变'等多次重复，影响结构清晰度和逻辑性。\n",
      "  - 多个章节标题语义相近但表述不同（如'教育领域的传统挑战'与'教育现状与挑战'），未体现内容递进或差异化，造成理解混乱。\n",
      "  - 部分内容不完整，如引言中提到'据中国信息通信研究院数据……'后文本被截断（'近...'结束），导致事实依据缺失。\n",
      "  - 语言表达在某些地方不够正式或学术化，如'推动生成式AI向多模态方向演进'可优化为更规范的表达。\n",
      "  - 整体结构缺乏明确的主题划分，未能体现出从问题分析、技术应用、影响评估到未来展望的逻辑演进路径。\n",
      "💡 改进建议:\n",
      "  - 对目录进行精简和整合，去除重复章节，确保每个章节标题具有唯一性和明确的内容指向。\n",
      "  - 明确各章节之间的逻辑关系，建议按照'背景与挑战→技术应用→影响分析→伦理与风险→未来展望'的逻辑顺序组织内容。\n",
      "  - 补充完整被截断的数据引用部分，确保统计数据来源清晰、准确，并标明具体时间范围和参考文献。\n",
      "  - 提升语言表达的规范性和专业性，避免口语化表达，增强报告的学术严谨性。\n",
      "  - 增加章节间的过渡段落，提升整体连贯性，使读者能清晰把握文章脉络和核心论点。\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 15 个章节\n",
      "🔄 处理章节 3: 教育领域的传统模式分析\n",
      "🔄 处理章节 2: 生成式 AI 的基本概念\n",
      "🔄 处理章节 4: 生成式 AI 在教学中的应用\n",
      "🔄 处理章节 1: 引言：AI 技术的快速发展\n",
      "🔄 处理章节 5: 个性化学习的实现路径\n",
      "🔄 处理章节 6: 学生创造力与 AI 的结合\n",
      "🔄 处理章节 7: 评估与反馈机制的革新\n",
      "🔄 处理章节 8: 教育资源的公平分配问题\n",
      "🔄 处理章节 9: 伦理与隐私保护的挑战\n",
      "🔄 处理章节 10: 未来教育生态系统的变化\n",
      "🔄 处理章节 12: 教师角色的转型与适应\n",
      "🔄 处理章节 13: 技术局限性与潜在风险\n",
      "🔄 处理章节 11: 政策制定与监管框架需求\n",
      "🔄 处理章节 15: 结语：迈向 AI 赋能的教育时代\n",
      "🔄 处理章节 14: 全球范围内的实践案例分享\n",
      "🔍 搜索查询优化: 政策制定与监管框架需求 提出针对 AI 在教育领域应用的政策建议。 -> \"生成式 AI 教育应用\" AND (\"政策制定\" OR \"监管框架\") AND 2023..2024 AND (政府报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 生成式 AI 在教学中的应用 探讨生成式 AI 如何辅助教师进行教学和课程设计。 -> \"生成式AI 教学应用\" AND (\"课程设计\" OR \"教师辅助\") AND (2023 OR 2024) AND (教育技术 OR 权威研究)\n",
      "🔍 搜索查询优化: 全球范围内的实践案例分享 展示不同国家和地区利用生成式 AI 教育的成功案例。 -> \"生成式 AI 教育应用\" AND (\"全球案例\" OR \"国际实践\") AND 2023..2024 AND (UNESCO OR \"教育部门\")\n",
      "🔍 搜索查询优化: 教育资源的公平分配问题 探讨 AI 技术是否能够缩小教育资源差距。 -> \"生成式AI 教育公平\" AND (\"资源分配\" OR \"教育差距\") AND (2020..2024) AND (来源:edu OR 权威机构)\n",
      "🔍 搜索查询优化: 引言：AI 技术的快速发展 介绍 AI 技术的发展背景及其对社会的影响。 -> \"生成式 AI 教育应用\" AND (\"技术发展\" OR \"社会影响\") AND (2020..2024) AND (权威 OR 学术)\n",
      "🔍 搜索查询优化: 技术局限性与潜在风险 分析当前生成式 AI 在教育中的技术瓶颈与风险。 -> \"生成式 AI 教育 技术局限性 风险\" AND (\"2023\" OR \"2024\") AND (学术研究 OR 权威报告)\n",
      "🔍 搜索查询优化: 教育领域的传统模式分析 回顾传统教育模式的特点与面临的挑战。 -> \"传统教育模式\" AND (\"特点\" OR \"挑战\") AND (教育改革 OR 教学方法) AND 2020..2024 AND (权威机构 OR 教育部 OR 学术期刊)\n",
      "🔍 搜索查询优化: 未来教育生态系统的变化 预测生成式 AI 将如何塑造未来的教育生态系统。 -> \"生成式 AI 教育生态系统变化\" AND (\"未来教育技术\" OR \"AI驱动学习\") AND (2023 OR 2024) AND (权威报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 教师角色的转型与适应 讨论教师在未来 AI 驱动的教育环境中的新定位。 -> \"生成式 AI 教育应用\" AND \"教师角色转型\" AND (\"未来教育\" OR \"AI驱动教学\") AND (2020..2025)\n",
      "🔍 搜索查询优化: 评估与反馈机制的革新 研究生成式 AI 在学业评估与实时反馈中的作用。 -> \"生成式AI 评估 教育\" AND (\"实时反馈\" OR \"学业评价\") AND (2020..2024) AND (权威 OR 学术)\n",
      "🔍 搜索查询优化: 生成式 AI 的基本概念 解释生成式 AI 是什么及其核心技术原理。 -> \"生成式 AI\" AND (\"定义\" OR \"核心技术\") AND (\"教育应用\" OR \"原理\") AND (\"2023\" OR \"2024\") site:.edu OR site:.org\n",
      "🔍 搜索查询优化: 学生创造力与 AI 的结合 讨论 AI 工具如何激发学生的创造力与解决问题能力。 -> \"生成式AI AND 学生创造力\" AND \"解决问题能力\" AND (教育应用 OR 教学创新) AND 出版年份:2020-2024 AND (权威期刊 OR 教育技术报告)\n",
      "🔍 搜索查询优化: 个性化学习的实现路径 分析生成式 AI 如何推动个性化学习体验的发展。 -> \"生成式 AI\" AND \"个性化学习\" AND (\"教育技术\" OR \"自适应学习\") AND (\"2023\" OR \"2024\") AND (site:edu OR site:gov)\n",
      "🔍 搜索查询优化: 结语：迈向 AI 赋能的教育时代 总结生成式 AI 对教育变革的深远影响与未来展望。 -> \"生成式 AI 教育变革\" AND (\"未来教育\" OR \"教学创新\") AND (2023 OR 2024) AND (权威报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 伦理与隐私保护的挑战 分析在教育中使用生成式 AI 所涉及的伦理问题。 -> \"生成式AI 伦理 隐私 教育\" AND (\"学术诚信\" OR \"数据安全\") AND (2020..2024) site:edu OR site:gov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成章节 6: 学生创造力与 AI 的结合\n",
      "✅ 完成章节 8: 教育资源的公平分配问题\n",
      "✅ 完成章节 3: 教育领域的传统模式分析\n",
      "✅ 完成章节 2: 生成式 AI 的基本概念\n",
      "✅ 完成章节 4: 生成式 AI 在教学中的应用\n",
      "✅ 完成章节 10: 未来教育生态系统的变化\n",
      "✅ 完成章节 7: 评估与反馈机制的革新\n",
      "✅ 完成章节 13: 技术局限性与潜在风险\n",
      "✅ 完成章节 14: 全球范围内的实践案例分享\n",
      "✅ 完成章节 9: 伦理与隐私保护的挑战\n",
      "✅ 完成章节 5: 个性化学习的实现路径\n",
      "✅ 完成章节 11: 政策制定与监管框架需求\n",
      "✅ 完成章节 1: 引言：AI 技术的快速发展\n",
      "✅ 完成章节 15: 结语：迈向 AI 赋能的教育时代\n",
      "✅ 完成章节 12: 教师角色的转型与适应\n",
      "📝 合并 55 个章节\n",
      "🔍 开始验证最终报告...\n",
      "📊 验证结果: 需要改进\n",
      "❌ 发现问题:\n",
      "  - 内容完整性不足：目录重复项过多，例如‘引言’、‘生成式 AI 在教学中的应用’、‘个性化学习的实现’、‘教师角色的转变’、‘评估与反馈机制’、‘伦理与隐私问题’等多次重复出现，缺乏实质性内容支撑。\n",
      "  - 逻辑性混乱：多个章节标题重复且未见具体展开内容，导致整体结构逻辑不清晰，读者难以理解报告的核心论点和推导过程。\n",
      "  - 章节间连贯性差：从目录来看，章节命名相似但无明确递进或区分，未能体现各部分之间的逻辑衔接关系。\n",
      "  - 事实准确性无法判断：由于仅提供了目录而无正文内容，无法验证所涉及观点或数据的真实性。\n",
      "  - 语言质量较低：章节标题中存在格式错误（如空格插入）、用词重复、语义模糊等问题，影响阅读体验。\n",
      "  - 结构不合理：目录层级混乱，缺少必要的章节分类与组织结构，如‘基本概念’、‘应用场景’、‘挑战与问题’、‘未来展望’等模块未形成清晰体系。\n",
      "💡 改进建议:\n",
      "  - 精简目录结构，去除重复章节并明确每个章节的独特主题和内容定位。\n",
      "  - 补充完整正文内容，确保每一章节有实质性论述以支撑整体论点。\n",
      "  - 优化章节命名，使用更具描述性和差异性的标题以增强可读性和逻辑性。\n",
      "  - 建立清晰的内容框架，如分为背景介绍、技术基础、教育应用、挑战分析、伦理考量、未来展望等模块。\n",
      "  - 校对语言表达，修正格式错误，提升标题的准确性和专业性。\n",
      "  - 增加过渡段落或小结部分，增强章节间的连贯性和整体逻辑性。\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 10 个章节\n",
      "🔄 处理章节 1: 引言：生成式 AI 的兴起\n",
      "🔄 处理章节 2: 生成式 AI 的工作原理\n",
      "🔄 处理章节 4: 生成式 AI 在教学中的应用\n",
      "🔄 处理章节 3: 传统教育模式的挑战\n",
      "🔄 处理章节 5: 学生学习体验的变革\n",
      "🔄 处理章节 7: 评估与反馈机制的优化\n",
      "🔄 处理章节 6: 教育资源的普及与公平\n",
      "🔄 处理章节 8: 教师角色的转变与支持\n",
      "🔄 处理章节 9: 伦理与隐私问题\n",
      "🔄 处理章节 10: 未来教育生态的展望\n",
      "🔍 搜索查询优化: 教育资源的普及与公平 探索生成式 AI 在缩小教育差距中的潜力。 -> \"生成式 AI\" AND (\"教育资源公平\" OR \"教育差距\") AND (2020..2024) site:.edu OR site:org\n",
      "🔍 搜索查询优化: 学生学习体验的变革 讨论生成式 AI 如何实现个性化学习路径。 -> \"生成式AI AND 个性化学习路径\" AND (\"教育技术\" OR \"自适应学习\") AND 时效性:2020-2024 AND 权威来源\n",
      "🔍 搜索查询优化: 生成式 AI 在教学中的应用 分析生成式 AI 如何辅助教师和提升教学质量。 -> \"生成式 AI 教学应用\" AND (\"教育创新\" OR \"教学质量提升\") AND (2023 OR 2024) AND (教师 OR 教育机构)\n",
      "🔍 搜索查询优化: 生成式 AI 的工作原理 解释生成式 AI 如何通过算法和数据生成内容。 -> \"生成式AI 工作原理\" AND (\"算法\" OR \"数据生成\") AND (\"教育应用\" OR \"内容生成\") AND (2020..2024) site:edu OR site:gov\n",
      "🔍 搜索查询优化: 教师角色的转变与支持 分析教师如何利用 AI 工具提高工作效率。 -> \"生成式AI 教育应用\" AND \"教师角色转变\" AND \"AI工具提升教学效率\" AND (2020..2024) AND (来源:edu OR 权威教育机构)\n",
      "🔍 搜索查询优化: 未来教育生态的展望 预测生成式 AI 将如何长期影响教育生态系统。 -> \"生成式 AI 教育影响\" AND (\"未来教育生态\" OR \"长期教育变革\") AND (2023 OR 2024) AND (研究 OR 报告)\n",
      "🔍 搜索查询优化: 引言：生成式 AI 的兴起 介绍生成式 AI 技术的发展及其潜在影响。 -> \"生成式 AI 教育应用\" AND (\"技术发展\" OR \"影响\") AND (2023 OR 2024) AND (权威报告 OR 学术研究)\n",
      "🔍 搜索查询优化: 伦理与隐私问题 探讨生成式 AI 应用中可能涉及的伦理风险。 -> \"生成式AI 伦理问题\" AND (\"隐私保护\" OR \"数据安全\") AND (教育应用) AND (2020..2024) AND (权威来源)\n",
      "🔍 搜索查询优化: 评估与反馈机制的优化 展示生成式 AI 在作业批改和实时反馈中的作用。 -> \"生成式AI 作业批改 实时反馈 教育应用\" AND (\"评估机制\" OR \"教学优化\") AND (2020..2024) site:edu OR site:gov\n",
      "🔍 搜索查询优化: 传统教育模式的挑战 探讨当前教育体系面临的效率与个性化问题。 -> \"生成式 AI 教育应用\" AND (\"传统教育模式\" OR \"教育体系效率\") AND (\"个性化学习挑战\" OR \"教育技术革新\") AND (2020..2024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py:154: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成章节 9: 伦理与隐私问题\n",
      "✅ 完成章节 6: 教育资源的普及与公平\n",
      "✅ 完成章节 2: 生成式 AI 的工作原理\n",
      "✅ 完成章节 3: 传统教育模式的挑战\n",
      "✅ 完成章节 7: 评估与反馈机制的优化\n",
      "✅ 完成章节 8: 教师角色的转变与支持\n",
      "✅ 完成章节 1: 引言：生成式 AI 的兴起\n",
      "✅ 完成章节 10: 未来教育生态的展望\n",
      "✅ 完成章节 4: 生成式 AI 在教学中的应用\n",
      "✅ 完成章节 5: 学生学习体验的变革\n",
      "📝 合并 65 个章节\n",
      "🔍 开始验证最终报告...\n",
      "📊 验证结果: 需要改进\n",
      "❌ 发现问题:\n",
      "  - 目录中存在大量重复的章节标题，如多个‘引言：生成式 AI 的兴起’、‘生成式 AI 在教学中的应用’、‘评估与反馈机制优化’等，导致内容结构混乱。\n",
      "  - 章节标题缺乏明确的逻辑递进关系，整体结构不清晰，无法体现报告的分析框架。\n",
      "  - 部分章节标题过于相似（如‘教育领域的传统挑战’、‘教育现状与挑战’、‘教育的现状与挑战’），难以区分其具体内容差异，影响可读性。\n",
      "  - 部分内容截断（如第47条未完整显示），可能影响信息完整性。\n",
      "  - 语言表达不够专业，部分标题用词重复、冗余，缺乏学术报告应有的严谨性和规范性。\n",
      "💡 改进建议:\n",
      "  - 合并重复章节，并重新命名以反映不同角度或深度的内容，确保每个章节具有唯一性和独立性。\n",
      "  - 制定清晰的逻辑结构，例如按照‘背景介绍 → 问题分析 → 技术原理 → 应用场景 → 影响与挑战 → 未来展望’的顺序组织内容。\n",
      "  - 统一术语和表述方式，避免如‘教育现状与挑战’与‘教育的现状与挑战’这样仅微小差别的标题。\n",
      "  - 补充完整缺失的部分（如第47节），并确保整篇报告内容完整无误。\n",
      "  - 提升语言质量，使用更专业的术语和更规范的表达方式，增强报告的学术性和可读性。\n",
      "📋 开始制定计划...\n",
      "📋 开始并行处理 12 个章节\n",
      "❌ 生成过程出错: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/3768850566.py\", line 487, in <module>\n",
      "    result = app.invoke(config)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2844, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/langgraph/pregel/__init__.py\", line 2559, in stream\n",
      "    raise GraphRecursionError(msg)\n",
      "langgraph.errors.GraphRecursionError: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from typing import Annotated, List, TypedDict, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ---------- 1. 全局 LLM & 工具 ----------\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "search = TavilySearchResults(max_results=3)\n",
    "\n",
    "# ---------- 2. 创建工作目录 ----------\n",
    "def setup_directories():\n",
    "    \"\"\"创建必要的工作目录\"\"\"\n",
    "    dirs = [\"search_results\", \"drafts\", \"reports\"]\n",
    "    for dir_name in dirs:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "# ---------- 3. 数据结构 ----------\n",
    "class Section(BaseModel):\n",
    "    title: str = Field(description=\"Section title\")\n",
    "    description: str = Field(description=\"Section description\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"List of report sections\")\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    section_index: int\n",
    "    original_query: str\n",
    "    optimized_query: str\n",
    "    results: List[Dict]\n",
    "    processed_content: str\n",
    "\n",
    "class IndexedDraft(BaseModel):\n",
    "    index: int\n",
    "    title: str\n",
    "    content: str\n",
    "    search_used: bool = False\n",
    "\n",
    "class ValidationResult(BaseModel):\n",
    "    is_valid: bool\n",
    "    issues: List[str]\n",
    "    suggestions: List[str]\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    plan: List[Section]\n",
    "    todo_list: List[str]\n",
    "    completed_tasks: List[str]\n",
    "    search_results: Annotated[List[SearchResult], operator.add]\n",
    "    drafts: Annotated[List[IndexedDraft], operator.add]\n",
    "    final_report: str\n",
    "    validation_result: Optional[ValidationResult]\n",
    "    output_format: str  # \"markdown\", \"html\", \"pdf\"\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    index: int\n",
    "    drafts: Annotated[List[IndexedDraft], operator.add]\n",
    "    search_results: Annotated[List[SearchResult], operator.add]\n",
    "\n",
    "# ---------- 4. 任务管理 ----------\n",
    "def update_todo_list(todo_list: List[str], completed_tasks: List[str]):\n",
    "    \"\"\"更新TODO列表\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    with open(\"todo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"=== 报告生成任务列表 ({timestamp}) ===\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 已完成任务:\\n\")\n",
    "        for task in completed_tasks:\n",
    "            f.write(f\"✅ {task}\\n\")\n",
    "        \n",
    "        f.write(\"\\n## 待完成任务:\\n\")\n",
    "        for task in todo_list:\n",
    "            f.write(f\"🔘 {task}\\n\")\n",
    "        \n",
    "        f.write(f\"\\n## 进度: {len(completed_tasks)}/{len(completed_tasks) + len(todo_list)}\\n\")\n",
    "\n",
    "# ---------- 5. 搜索优化 ----------\n",
    "def optimize_search_query(section: Section, topic: str) -> str:\n",
    "    \"\"\"优化搜索查询\"\"\"\n",
    "    optimization_prompt = f\"\"\"\n",
    "    主题: {topic}\n",
    "    章节标题: {section.title}\n",
    "    章节描述: {section.description}\n",
    "    \n",
    "    请为这个章节生成一个优化的搜索查询，要求：\n",
    "    1. 包含关键词和相关术语\n",
    "    2. 使用布尔运算符或引号提高精确度\n",
    "    3. 考虑时效性和权威性\n",
    "    4. 限制在50字以内\n",
    "    \n",
    "    直接返回优化后的搜索查询，不要其他解释。\n",
    "    \"\"\"\n",
    "    \n",
    "    optimized_query = llm.invoke([\n",
    "        SystemMessage(content=\"你是搜索专家，专门优化搜索查询以获得最佳结果。\"),\n",
    "        HumanMessage(content=optimization_prompt)\n",
    "    ]).content.strip()\n",
    "    \n",
    "    return optimized_query\n",
    "\n",
    "# ---------- 6. 搜索和内容处理 ----------\n",
    "def enhanced_research(section: Section, index: int, topic: str) -> SearchResult:\n",
    "    \"\"\"增强的搜索和内容处理\"\"\"\n",
    "    try:\n",
    "        # 优化搜索查询\n",
    "        original_query = f\"{section.title} {section.description}\"\n",
    "        optimized_query = optimize_search_query(section, topic)\n",
    "        \n",
    "        print(f\"🔍 搜索查询优化: {original_query} -> {optimized_query}\")\n",
    "        \n",
    "        # 执行搜索\n",
    "        docs = search.invoke(optimized_query)\n",
    "        \n",
    "        # 处理搜索结果\n",
    "        processing_prompt = f\"\"\"\n",
    "        章节: {section.title}\n",
    "        搜索结果: {json.dumps(docs, ensure_ascii=False, indent=2)}\n",
    "        \n",
    "        请整合这些搜索结果，要求：\n",
    "        1. 提取关键信息和数据\n",
    "        2. 去除重复内容\n",
    "        3. 按重要性排序\n",
    "        4. 保持事实准确性\n",
    "        5. 整合成连贯的素材\n",
    "        \n",
    "        返回整合后的内容，用于章节写作。\n",
    "        \"\"\"\n",
    "        \n",
    "        processed_content = llm.invoke([\n",
    "            SystemMessage(content=\"你是信息整合专家，擅长从多个来源提取和整合关键信息。\"),\n",
    "            HumanMessage(content=processing_prompt)\n",
    "        ]).content\n",
    "        \n",
    "        # 保存搜索结果\n",
    "        search_result = SearchResult(\n",
    "            section_index=index,\n",
    "            original_query=original_query,\n",
    "            optimized_query=optimized_query,\n",
    "            results=docs,\n",
    "            processed_content=processed_content\n",
    "        )\n",
    "        \n",
    "        # 保存到文件\n",
    "        filename = f\"search_results/section_{index:02d}_{section.title.replace(' ', '_')}.json\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(search_result.dict(), f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return search_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"搜索错误: {e}\")\n",
    "        return SearchResult(\n",
    "            section_index=index,\n",
    "            original_query=original_query,\n",
    "            optimized_query=optimized_query,\n",
    "            results=[],\n",
    "            processed_content=f\"无法获取 {section.title} 的相关信息\"\n",
    "        )\n",
    "\n",
    "# ---------- 7. 计划节点 ----------\n",
    "planner = llm.with_structured_output(Plan)\n",
    "\n",
    "def plan_node(state: State):\n",
    "    print(\"📋 开始制定计划...\")\n",
    "    \n",
    "    prompt = f\"\"\"为\"{state['topic']}\"写一份详细的大纲，每节含标题和 20 字描述。\n",
    "    \n",
    "    请以 JSON 格式返回，包含以下结构：\n",
    "    {{\n",
    "        \"sections\": [\n",
    "            {{\"title\": \"章节标题\", \"description\": \"章节描述\"}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    plan = planner.invoke([\n",
    "        SystemMessage(content=\"你是一个专业的报告规划师，请按照 JSON 格式返回报告大纲。\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    \n",
    "    # 创建TODO列表\n",
    "    todo_list = [f\"生成章节: {section.title}\" for section in plan.sections]\n",
    "    todo_list.append(\"合并所有章节\")\n",
    "    todo_list.append(\"验证最终报告\")\n",
    "    \n",
    "    update_todo_list(todo_list, [])\n",
    "    \n",
    "    return {\n",
    "        \"plan\": plan.sections,\n",
    "        \"todo_list\": todo_list,\n",
    "        \"completed_tasks\": [\"制定报告大纲\"]\n",
    "    }\n",
    "\n",
    "# ---------- 8. Worker节点 ----------\n",
    "def worker_node(state: WorkerState):\n",
    "    section = state['section']\n",
    "    index = state['index']\n",
    "    \n",
    "    print(f\"🔄 处理章节 {index + 1}: {section.title}\")\n",
    "    \n",
    "    # 搜索和处理信息\n",
    "    search_result = enhanced_research(section, index, state.get('topic', ''))\n",
    "    \n",
    "    # 写作提示\n",
    "    writer_prompt = f\"\"\"\n",
    "    你是一名专业的报告写作专家。\n",
    "    \n",
    "    章节标题: {section.title}\n",
    "    章节描述: {section.description}\n",
    "    \n",
    "    处理后的素材:\n",
    "    {search_result.processed_content}\n",
    "    \n",
    "    请写一篇高质量的章节内容，要求：\n",
    "    1. 使用 Markdown 格式\n",
    "    2. 长度约 400-600 字\n",
    "    3. 结构清晰，逻辑严谨\n",
    "    4. 包含具体例子和数据\n",
    "    5. 语言专业且易懂\n",
    "    6. 为后续章节做好过渡\n",
    "    \n",
    "    直接返回章节内容，不要标题。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 生成初稿\n",
    "    draft1 = llm.invoke([\n",
    "        SystemMessage(content=\"你是专业的报告写作专家，擅长创作高质量的技术报告。\"),\n",
    "        HumanMessage(content=writer_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    # 反思和改进\n",
    "    critique_prompt = f\"\"\"\n",
    "    请对以下章节内容进行专业评估并提出改进建议：\n",
    "    \n",
    "    {draft1}\n",
    "    \n",
    "    请从以下方面评估：\n",
    "    1. 内容准确性和深度\n",
    "    2. 逻辑结构和流畅性\n",
    "    3. 语言表达和专业性\n",
    "    4. 与主题的相关性\n",
    "    5. 过渡和衔接性\n",
    "    \n",
    "    提供3-5条具体的改进建议。\n",
    "    \"\"\"\n",
    "    \n",
    "    critique = llm.invoke([\n",
    "        SystemMessage(content=\"你是专业的内容评估专家，擅长提供建设性的改进建议。\"),\n",
    "        HumanMessage(content=critique_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    # 重写改进\n",
    "    rewrite_prompt = f\"\"\"\n",
    "    根据以下改进建议，重写章节内容：\n",
    "    \n",
    "    原文：\n",
    "    {draft1}\n",
    "    \n",
    "    改进建议：\n",
    "    {critique}\n",
    "    \n",
    "    请重写出改进后的版本，保持原有结构但提升质量。\n",
    "    \"\"\"\n",
    "    \n",
    "    final_draft = llm.invoke([\n",
    "        SystemMessage(content=\"你是专业的内容编辑，擅长根据反馈改进文章质量。\"),\n",
    "        HumanMessage(content=rewrite_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    # 保存草稿\n",
    "    draft_filename = f\"drafts/section_{index:02d}_{section.title.replace(' ', '_')}.md\"\n",
    "    with open(draft_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# {section.title}\\n\\n{final_draft}\")\n",
    "    \n",
    "    print(f\"✅ 完成章节 {index + 1}: {section.title}\")\n",
    "    \n",
    "    # 创建索引草稿\n",
    "    indexed_draft = IndexedDraft(\n",
    "        index=index,\n",
    "        title=section.title,\n",
    "        content=final_draft,\n",
    "        search_used=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"drafts\": [indexed_draft],\n",
    "        \"search_results\": [search_result]\n",
    "    }\n",
    "\n",
    "# ---------- 9. 分发节点 ----------\n",
    "def dispatch(state: State):\n",
    "    print(f\"📋 开始并行处理 {len(state['plan'])} 个章节\")\n",
    "    \n",
    "    # 更新TODO\n",
    "    completed = state['completed_tasks'] + [\"制定执行计划\"]\n",
    "    remaining = [task for task in state['todo_list'] if task not in completed]\n",
    "    update_todo_list(remaining, completed)\n",
    "    \n",
    "    return [Send(\"worker\", {\"section\": s, \"index\": i, \"topic\": state['topic']}) \n",
    "            for i, s in enumerate(state[\"plan\"])]\n",
    "\n",
    "# ---------- 10. 合并和格式化 ----------\n",
    "def merge_and_format(state: State):\n",
    "    print(f\"📝 合并 {len(state['drafts'])} 个章节\")\n",
    "    \n",
    "    # 按索引排序\n",
    "    sorted_drafts = sorted(state[\"drafts\"], key=lambda x: x.index)\n",
    "    \n",
    "    # 生成过渡内容\n",
    "    transition_prompt = f\"\"\"\n",
    "    主题: {state['topic']}\n",
    "    章节列表: {[draft.title for draft in sorted_drafts]}\n",
    "    \n",
    "    为这些章节生成自然的过渡句和连接词，确保整体文章的连贯性。\n",
    "    请为每个章节之间提供1-2句过渡语。\n",
    "    \n",
    "    返回格式：\n",
    "    章节1 -> 章节2: [过渡语]\n",
    "    章节2 -> 章节3: [过渡语]\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    transitions = llm.invoke([\n",
    "        SystemMessage(content=\"你是专业的文章编辑，擅长创建流畅的章节过渡。\"),\n",
    "        HumanMessage(content=transition_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    # 解析过渡语\n",
    "    transition_dict = {}\n",
    "    for line in transitions.split('\\n'):\n",
    "        if '->' in line and ':' in line:\n",
    "            key = line.split(':')[0].strip()\n",
    "            value = line.split(':')[1].strip()\n",
    "            transition_dict[key] = value\n",
    "    \n",
    "    # 组装最终报告\n",
    "    output_format = state.get('output_format', 'markdown')\n",
    "    \n",
    "    if output_format == 'markdown':\n",
    "        full_report = f\"# {state['topic']}\\n\\n\"\n",
    "        full_report += f\"*生成时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\\n\"\n",
    "        full_report += \"## 目录\\n\\n\"\n",
    "        \n",
    "        # 生成目录\n",
    "        for i, draft in enumerate(sorted_drafts):\n",
    "            full_report += f\"{i+1}. [{draft.title}](#{draft.title.replace('','-').lower()})\\n\"\n",
    "        \n",
    "        full_report += \"\\n---\\n\\n\"\n",
    "        \n",
    "        # 组装章节内容\n",
    "        for i, draft in enumerate(sorted_drafts):\n",
    "            full_report += f\"## {draft.title}\\n\\n\"\n",
    "            full_report += draft.content\n",
    "            \n",
    "            # 添加过渡语\n",
    "            if i < len(sorted_drafts) - 1:\n",
    "                next_title = sorted_drafts[i+1].title\n",
    "                transition_key = f\"{draft.title} -> {next_title}\"\n",
    "                if transition_key in transition_dict:\n",
    "                    full_report += f\"\\n\\n*{transition_dict[transition_key]}*\\n\\n\"\n",
    "                else:\n",
    "                    full_report += \"\\n\\n\"\n",
    "            \n",
    "            if i < len(sorted_drafts) - 1:\n",
    "                full_report += \"---\\n\\n\"\n",
    "    \n",
    "    # 保存报告\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    report_filename = f\"reports/report_{timestamp}.md\"\n",
    "    with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_report)\n",
    "    \n",
    "    # 更新TODO\n",
    "    completed = state['completed_tasks'] + [f\"生成章节: {draft.title}\" for draft in sorted_drafts] + [\"合并所有章节\"]\n",
    "    remaining = [task for task in state['todo_list'] if task not in completed]\n",
    "    update_todo_list(remaining, completed)\n",
    "    \n",
    "    return {\"final_report\": full_report}\n",
    "\n",
    "# ---------- 11. 验证节点 ----------\n",
    "validator = llm.with_structured_output(ValidationResult)\n",
    "\n",
    "def validation_node(state: State):\n",
    "    print(\"🔍 开始验证最终报告...\")\n",
    "    \n",
    "    validation_prompt = f\"\"\"\n",
    "    请对以下报告进行全面验证：\n",
    "    \n",
    "    主题: {state['topic']}\n",
    "    \n",
    "    报告内容:\n",
    "    {state['final_report'][:2000]}...  # 截取前2000字进行验证\n",
    "    \n",
    "    请验证以下方面并以JSON格式返回：\n",
    "    1. 内容完整性和逻辑性\n",
    "    2. 章节间的连贯性\n",
    "    3. 事实准确性\n",
    "    4. 语言质量\n",
    "    5. 结构合理性\n",
    "    \n",
    "    返回格式：\n",
    "    {{\n",
    "        \"is_valid\": true/false,\n",
    "        \"issues\": [\"问题1\", \"问题2\"],\n",
    "        \"suggestions\": [\"建议1\", \"建议2\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    validation = validator.invoke([\n",
    "        SystemMessage(content=\"你是专业的内容质量验证专家，请按JSON格式返回验证结果。\"),\n",
    "        HumanMessage(content=validation_prompt)\n",
    "    ])\n",
    "    \n",
    "    print(f\"📊 验证结果: {'通过' if validation.is_valid else '需要改进'}\")\n",
    "    if not validation.is_valid:\n",
    "        print(\"❌ 发现问题:\")\n",
    "        for issue in validation.issues:\n",
    "            print(f\"  - {issue}\")\n",
    "        print(\"💡 改进建议:\")\n",
    "        for suggestion in validation.suggestions:\n",
    "            print(f\"  - {suggestion}\")\n",
    "    \n",
    "    # 更新TODO\n",
    "    completed = state['completed_tasks'] + [\"验证最终报告\"]\n",
    "    update_todo_list([], completed)\n",
    "    \n",
    "    return {\"validation_result\": validation}\n",
    "\n",
    "# ---------- 12. 路由函数 ----------\n",
    "def should_regenerate(state: State):\n",
    "    \"\"\"决定是否需要重新生成\"\"\"\n",
    "    if state.get('validation_result') and not state['validation_result'].is_valid:\n",
    "        return \"regenerate\"\n",
    "    return \"complete\"\n",
    "\n",
    "# ---------- 13. 构建工作流 ----------\n",
    "def build_workflow():\n",
    "    setup_directories()\n",
    "    \n",
    "    workflow = StateGraph(State)\n",
    "    \n",
    "    # 添加节点\n",
    "    workflow.add_node(\"plan\", plan_node)\n",
    "    workflow.add_node(\"worker\", worker_node)\n",
    "    workflow.add_node(\"merge\", merge_and_format)\n",
    "    workflow.add_node(\"validate\", validation_node)\n",
    "    workflow.add_node(\"complete\", lambda state: {\"final_report\": state[\"final_report\"]})\n",
    "    \n",
    "    # 添加边\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_conditional_edges(\"plan\", dispatch, [\"worker\"])\n",
    "    workflow.add_edge(\"worker\", \"merge\")\n",
    "    workflow.add_edge(\"merge\", \"validate\")\n",
    "    workflow.add_conditional_edges(\"validate\", should_regenerate, {\n",
    "        \"complete\": \"complete\",\n",
    "        \"regenerate\": \"plan\"  # 如果验证失败，重新开始\n",
    "    })\n",
    "    workflow.add_edge(\"complete\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# ---------- 14. 主程序 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 启动增强版报告生成系统...\")\n",
    "    \n",
    "    app = build_workflow()\n",
    "    \n",
    "    # 配置参数\n",
    "    config = {\n",
    "        \"topic\": \"生成式 AI 如何重塑教育\",\n",
    "        \"output_format\": \"markdown\",\n",
    "        \"todo_list\": [],\n",
    "        \"completed_tasks\": [],\n",
    "        \"search_results\": [],\n",
    "        \"drafts\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        result = app.invoke(config)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📊 最终报告生成完成!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 显示文件位置\n",
    "        print(f\"📁 报告文件: reports/\")\n",
    "        print(f\"📁 搜索结果: search_results/\")\n",
    "        print(f\"📁 章节草稿: drafts/\")\n",
    "        print(f\"📁 任务列表: todo.txt\")\n",
    "        \n",
    "        if result.get('validation_result'):\n",
    "            validation = result['validation_result']\n",
    "            print(f\"\\n✅ 验证状态: {'通过' if validation.is_valid else '需要改进'}\")\n",
    "            \n",
    "        print(f\"\\n📝 报告预览 (前500字):\")\n",
    "        print(\"-\" * 30)\n",
    "        print(result[\"final_report\"][:500] + \"...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 生成过程出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db5e7a",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from typing import List, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ImageInfo(BaseModel):\n",
    "    url: str\n",
    "    description: str\n",
    "    source: str\n",
    "    relevance_score: float = 0.0\n",
    "    query_used: str = \"\"\n",
    "\n",
    "def extract_keywords_from_content(search_results: List[Dict], topic: str) -> List[str]:\n",
    "    \"\"\"从搜索结果中提取关键词用于图片搜索\"\"\"\n",
    "    \n",
    "    # 合并所有搜索结果内容\n",
    "    all_content = \"\"\n",
    "    for result in search_results:\n",
    "        content = result.get(\"content\", \"\")\n",
    "        all_content += content + \" \"\n",
    "    \n",
    "    # 使用LLM提取关键词\n",
    "    keyword_prompt = f\"\"\"\n",
    "    主题: {topic}\n",
    "    搜索结果内容: {all_content[:1000]}...\n",
    "    \n",
    "    请从这些内容中提取3-5个最适合用于图片搜索的关键词或短语。\n",
    "    \n",
    "    要求：\n",
    "    1. 选择具有强烈视觉化特征的词汇\n",
    "    2. 避免过于抽象的概念\n",
    "    3. 每个关键词不超过3个单词\n",
    "    4. 按照相关性排序\n",
    "    5. 用英文返回（便于图片搜索）\n",
    "    \n",
    "    返回格式：\n",
    "    keyword1, keyword2, keyword3, keyword4, keyword5\n",
    "    \n",
    "    只返回关键词，用逗号分隔。\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 这里使用您的LLM实例\n",
    "        keywords_text = llm.invoke([\n",
    "            SystemMessage(content=\"你是关键词提取专家，专门为图片搜索提取最佳关键词。\"),\n",
    "            HumanMessage(content=keyword_prompt)\n",
    "        ]).content.strip()\n",
    "        \n",
    "        # 解析关键词\n",
    "        keywords = [kw.strip() for kw in keywords_text.split(',') if kw.strip()]\n",
    "        return keywords[:5]  # 最多5个关键词\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"提取关键词时出错: {e}\")\n",
    "        # 回退到简单的关键词提取\n",
    "        return [topic.split()[:2]]  # 使用主题的前两个词作为关键词\n",
    "\n",
    "def search_pexels_images(keywords: List[str], max_images: int = 3) -> List[ImageInfo]:\n",
    "    \"\"\"使用Pexels API搜索图片\"\"\"\n",
    "    \n",
    "    # Pexels API密钥 - 需要在 https://www.pexels.com/api/ 申请\n",
    "    PEXELS_API_KEY = \"You API Key\"  # 替换为您的API密钥\n",
    "    \n",
    "    if not PEXELS_API_KEY or PEXELS_API_KEY == \"YOUR_PEXELS_API_KEY\":\n",
    "        print(\"⚠️ 未设置Pexels API密钥，跳过Pexels搜索\")\n",
    "        return []\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        if len(images) >= max_images:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            # Pexels API请求\n",
    "            url = f\"https://api.pexels.com/v1/search\"\n",
    "            headers = {\n",
    "                \"Authorization\": PEXELS_API_KEY\n",
    "            }\n",
    "            params = {\n",
    "                \"query\": keyword,\n",
    "                \"per_page\": 2,  # 每个关键词最多2张图片\n",
    "                \"size\": \"medium\"\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, headers=headers, params=params, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                photos = data.get(\"photos\", [])\n",
    "                \n",
    "                for photo in photos:\n",
    "                    if len(images) >= max_images:\n",
    "                        break\n",
    "                    \n",
    "                    images.append(ImageInfo(\n",
    "                        url=photo[\"src\"][\"medium\"],\n",
    "                        description=f\"关于 '{keyword}' 的图片\",\n",
    "                        source=\"Pexels\",\n",
    "                        relevance_score=0.7,\n",
    "                        query_used=keyword\n",
    "                    ))\n",
    "                    \n",
    "                print(f\"✅ 从Pexels找到 {len(photos)} 张关于 '{keyword}' 的图片\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"❌ Pexels API请求失败: {response.status_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Pexels搜索出错 '{keyword}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    return images\n",
    "\n",
    "def search_images_with_browser_use(keywords: List[str], max_images: int = 3) -> List[ImageInfo]:\n",
    "    \"\"\"使用Browser Use搜索图片（需要browser_use库）\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 这里假设您有browser_use的实现\n",
    "        # 如果没有，可以跳过这个函数或使用其他方式\n",
    "        \n",
    "        # 示例实现（需要根据实际的browser_use库调整）\n",
    "        # from browser_use import BrowserUse\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if len(images) >= max_images:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                # 使用browser搜索图片\n",
    "                search_query = f\"{keyword} high quality images\"\n",
    "                \n",
    "                # 这里需要实际的browser_use实现\n",
    "                # browser = BrowserUse()\n",
    "                # results = browser.search_images(search_query, limit=2)\n",
    "                \n",
    "                # 暂时返回占位符结果\n",
    "                # 实际实现时需要解析browser返回的结果\n",
    "                placeholder_results = [\n",
    "                    {\n",
    "                        \"url\": f\"https://via.placeholder.com/800x600?text={keyword.replace(' ', '+')}\",\n",
    "                        \"title\": f\"Image about {keyword}\",\n",
    "                        \"source\": \"Browser Search\"\n",
    "                    }\n",
    "                ]\n",
    "                \n",
    "                for result in placeholder_results:\n",
    "                    if len(images) >= max_images:\n",
    "                        break\n",
    "                    \n",
    "                    images.append(ImageInfo(\n",
    "                        url=result[\"url\"],\n",
    "                        description=f\"Browser搜索: {keyword}\",\n",
    "                        source=\"Browser Use\",\n",
    "                        relevance_score=0.6,\n",
    "                        query_used=keyword\n",
    "                    ))\n",
    "                \n",
    "                print(f\"✅ 通过Browser Use找到 {len(placeholder_results)} 张关于 '{keyword}' 的图片\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Browser Use搜索出错 '{keyword}': {e}\")\n",
    "                continue\n",
    "                \n",
    "    except ImportError:\n",
    "        print(\"⚠️ Browser Use库未安装，跳过Browser Use搜索\")\n",
    "        return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Browser Use搜索出错: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_images_from_search(search_results: List[Dict], topic: str = \"\", max_images: int = 3) -> List[ImageInfo]:\n",
    "    \"\"\"从搜索结果中提取图片信息，如果没有找到则通过关键词搜索\"\"\"\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    # 第一步：从搜索结果中直接提取图片URL\n",
    "    for result in search_results:\n",
    "        content = result.get(\"content\", \"\")\n",
    "        url = result.get(\"url\", \"\")\n",
    "        \n",
    "        # 使用正则表达式查找图片URL\n",
    "        image_patterns = [\n",
    "            r'https?://[^\\s]+\\.(?:jpg|jpeg|png|gif|webp|svg)',\n",
    "            r'!\\[.*?\\]\\((https?://[^\\s]+\\.(?:jpg|jpeg|png|gif|webp|svg))\\)',\n",
    "            r'<img[^>]+src=\"([^\"]+)\"'\n",
    "        ]\n",
    "        \n",
    "        for pattern in image_patterns:\n",
    "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple):\n",
    "                    img_url = match[0]\n",
    "                else:\n",
    "                    img_url = match\n",
    "                \n",
    "                images.append(ImageInfo(\n",
    "                    url=img_url,\n",
    "                    description=f\"来自 {url}\",\n",
    "                    source=url,\n",
    "                    relevance_score=0.8,\n",
    "                    query_used=\"直接提取\"\n",
    "                ))\n",
    "    \n",
    "    # 去重\n",
    "    unique_images = {}\n",
    "    for img in images:\n",
    "        if img.url not in unique_images:\n",
    "            unique_images[img.url] = img\n",
    "    \n",
    "    found_images = list(unique_images.values())[:max_images]\n",
    "    \n",
    "    print(f\"📸 直接找到 {len(found_images)} 张图片\")\n",
    "    \n",
    "    # 第二步：如果图片数量不足，通过关键词搜索\n",
    "    if len(found_images) < max_images and search_results:\n",
    "        remaining_slots = max_images - len(found_images)\n",
    "        \n",
    "        print(f\"🔍 图片数量不足，开始关键词搜索 (需要 {remaining_slots} 张)\")\n",
    "        \n",
    "        # 提取关键词\n",
    "        keywords = extract_keywords_from_content(search_results, topic)\n",
    "        \n",
    "        if keywords:\n",
    "            print(f\"🔑 提取的关键词: {', '.join(keywords)}\")\n",
    "            \n",
    "            # 尝试多个图片源\n",
    "            additional_images = []\n",
    "            \n",
    "            # 1. 尝试Pexels\n",
    "            try:\n",
    "                pexels_images = search_pexels_images(keywords, remaining_slots)\n",
    "                additional_images.extend(pexels_images)\n",
    "                print(f\"📸 Pexels找到 {len(pexels_images)} 张图片\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Pexels搜索失败: {e}\")\n",
    "            \n",
    "            \n",
    "            # 3. 如果还不够，尝试Browser Use\n",
    "            if len(additional_images) < remaining_slots:\n",
    "                try:\n",
    "                    browser_images = search_images_with_browser_use(keywords, remaining_slots - len(additional_images))\n",
    "                    additional_images.extend(browser_images)\n",
    "                    print(f\"📸 Browser Use找到 {len(browser_images)} 张图片\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Browser Use搜索失败: {e}\")\n",
    "            \n",
    "            # 合并结果\n",
    "            found_images.extend(additional_images[:remaining_slots])\n",
    "    \n",
    "    final_images = found_images[:max_images]\n",
    "    \n",
    "    print(f\"✅ 总共找到 {len(final_images)} 张图片\")\n",
    "    \n",
    "    # 按相关性排序\n",
    "    final_images.sort(key=lambda x: x.relevance_score, reverse=True)\n",
    "    \n",
    "    return final_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e9bc3-130c-4d65-b296-dfedcc284534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 启动版本控制报告生成系统...\n",
      "📋 初始计划制定...\n",
      "📋 分发任务到 8 个worker\n",
      "🔄 处理章节 1: 引言：生成式 AI 与教育的融合\n",
      "🔄 处理章节 2: 生成式 AI 在教学中的应用\n",
      "🔄 处理章节 3: 生成式 AI 对学生学习的影响\n",
      "🔄 处理章节 4: AI 驱动的教育工具与平台\n",
      "🔄 处理章节 5: 伦理与隐私问题\n",
      "🔄 处理章节 6: 生成式 AI 对教育公平性的影响\n",
      "🔄 处理章节 7: 未来趋势与展望\n",
      "🔄 处理章节 8: 总结与建议\n",
      "✅ 新版本: 未来趋势与展望 (v1)\n",
      "✅ 章节 7 已更新到 v1\n",
      "✅ 新版本: 引言：生成式 AI 与教育的融合 (v1)\n",
      "✅ 新版本: 生成式 AI 对教育公平性的影响 (v1)\n",
      "✅ 新版本: 生成式 AI 对学生学习的影响 (v1)\n",
      "✅ 章节 1 已更新到 v1\n",
      "✅ 新版本: 伦理与隐私问题 (v1)\n",
      "✅ 章节 6 已更新到 v1\n",
      "✅ 章节 3 已更新到 v1\n",
      "✅ 章节 5 已更新到 v1\n",
      "✅ 新版本: AI 驱动的教育工具与平台 (v1)\n",
      "✅ 章节 4 已更新到 v1\n",
      "✅ 新版本: 总结与建议 (v1)\n",
      "✅ 章节 8 已更新到 v1\n",
      "✅ 新版本: 生成式 AI 在教学中的应用 (v1)\n",
      "✅ 章节 2 已更新到 v1\n",
      "📝 合并报告 v1 (重新生成次数: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/1125648981.py:143: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  json.dump(history.dict(), f, ensure_ascii=False, indent=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 验证报告 v1...\n",
      "📊 验证结果: 得分 8.5/10 | 通过\n",
      "\n",
      "==================================================\n",
      "📊 报告生成完成!\n",
      "==================================================\n",
      "\n",
      "📋 最终版本: v1\n",
      "\n",
      "📁 生成的文件:\n",
      "  - 最终报告: reports/report_v1_*.md\n",
      "  - 章节草稿: drafts/section_*_v*_*.md\n",
      "  - 版本历史: versions/v*/\n",
      "  - 任务列表: todo_v1.txt\n",
      "\n",
      "✅ 最终得分: 8.5/10\n",
      "📊 状态: 通过\n",
      "\n",
      "📖 章节版本:\n",
      "  1. 引言：生成式 AI 与教育的融合 (v1)\n",
      "  2. 生成式 AI 在教学中的应用 (v1)\n",
      "  3. 生成式 AI 对学生学习的影响 (v1)\n",
      "  4. AI 驱动的教育工具与平台 (v1)\n",
      "  5. 伦理与隐私问题 (v1)\n",
      "  6. 生成式 AI 对教育公平性的影响 (v1)\n",
      "  7. 未来趋势与展望 (v1)\n",
      "  8. 总结与建议 (v1)\n",
      "\n",
      "📝 最终报告预览:\n",
      "------------------------------\n",
      "# 生成式 AI 如何重塑教育\n",
      "\n",
      "*版本: v1 | 生成时间: 2025-07-16 08:50:35*\n",
      "\n",
      "## 版本信息\n",
      "\n",
      "- 引言：生成式 AI 与教育的融合: v1\n",
      "- 生成式 AI 在教学中的应用: v1\n",
      "- 生成式 AI 对学生学习的影响: v1\n",
      "- AI 驱动的教育工具与平台: v1\n",
      "- 伦理与隐私问题: v1\n",
      "- 生成式 AI 对教育公平性的影响: v1\n",
      "- 未来趋势与展望: v1\n",
      "- 总结与建议: v1\n",
      "\n",
      "---\n",
      "\n",
      "## 目录\n",
      "\n",
      "1. [引言：生成式 AI 与教育的融合](#引言：生成式-ai-与教育的融合)\n",
      "2. [生成式 AI 在教学中的应用](#生成式-ai-在教学中的应用)\n",
      "3. [生成式 AI 对学生学习的影响](#生成式-ai-对学生学习的影响)\n",
      "4. [AI 驱动的教育工具与平台](#ai-驱动的教育工具与平台)\n",
      "5. [伦理与隐私问题](#伦理与隐私问题)\n",
      "6. [生成式 AI 对教育公平性的影响](#生成式-ai-对教育公平性的影响)\n",
      "7. [未来趋势与展望](#未来趋势与展望)\n",
      "8. [总结与建议](#总结与建议)\n",
      "\n",
      "---\n",
      "\n",
      "## 引言：生成式 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/s5q05z8n4537pyvqd1m5yq9h0000gp/T/ipykernel_62815/1125648981.py:579: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"validation_result\": validation.dict(),\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import hashlib\n",
    "from typing import Annotated, List, TypedDict, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ---------- 1. 全局配置 ----------\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "search = TavilySearchResults(max_results=3)\n",
    "MAX_REGEN = 3\n",
    "\n",
    "# ---------- 2. 版本控制数据结构 ----------\n",
    "class SectionVersion(BaseModel):\n",
    "    version: int\n",
    "    title: str\n",
    "    content: str\n",
    "    content_hash: str\n",
    "    timestamp: str\n",
    "    is_current: bool = False\n",
    "\n",
    "class SectionHistory(BaseModel):\n",
    "    section_index: int\n",
    "    base_title: str\n",
    "    versions: List[SectionVersion] = []\n",
    "    current_version: int = 0\n",
    "    \n",
    "    def add_version(self, title: str, content: str) -> bool:\n",
    "        \"\"\"添加新版本，检查是否重复\"\"\"\n",
    "        content_hash = hashlib.md5(content.encode()).hexdigest()\n",
    "        \n",
    "        # 检查是否与现有版本重复\n",
    "        for version in self.versions:\n",
    "            if version.content_hash == content_hash:\n",
    "                print(f\"⚠️ 跳过重复内容: {title}\")\n",
    "                return False\n",
    "        \n",
    "        # 将之前的版本标记为非当前\n",
    "        for version in self.versions:\n",
    "            version.is_current = False\n",
    "        \n",
    "        # 添加新版本\n",
    "        new_version = SectionVersion(\n",
    "            version=len(self.versions) + 1,\n",
    "            title=title,\n",
    "            content=content,\n",
    "            content_hash=content_hash,\n",
    "            timestamp=datetime.datetime.now().isoformat(),\n",
    "            is_current=True\n",
    "        )\n",
    "        \n",
    "        self.versions.append(new_version)\n",
    "        self.current_version = new_version.version\n",
    "        \n",
    "        print(f\"✅ 新版本: {title} (v{new_version.version})\")\n",
    "        return True\n",
    "    \n",
    "    def get_current(self) -> Optional[SectionVersion]:\n",
    "        \"\"\"获取当前版本\"\"\"\n",
    "        for version in self.versions:\n",
    "            if version.is_current:\n",
    "                return version\n",
    "        return None\n",
    "\n",
    "class ReportVersion(BaseModel):\n",
    "    version: int\n",
    "    timestamp: str\n",
    "    section_versions: Dict[int, int]\n",
    "    validation_passed: bool = False\n",
    "    regenerate_reason: str = \"\"\n",
    "\n",
    "# ---------- 3. 修正的合并函数 ----------\n",
    "def merge_section_histories(\n",
    "    left: List[SectionHistory], \n",
    "    right: List[SectionHistory]\n",
    ") -> List[SectionHistory]:\n",
    "    \"\"\"\n",
    "    合并两个章节历史列表\n",
    "    LangGraph 要求签名为 (a, b) -> c\n",
    "    \"\"\"\n",
    "    # 合并所有历史记录\n",
    "    all_histories = left + right\n",
    "    \n",
    "    # 按 section_index 分组，保留最新的版本\n",
    "    merged = {}\n",
    "    for history in all_histories:\n",
    "        key = history.section_index\n",
    "        if key not in merged:\n",
    "            merged[key] = history\n",
    "        else:\n",
    "            # 比较版本，保留更新的\n",
    "            if history.current_version > merged[key].current_version:\n",
    "                merged[key] = history\n",
    "    \n",
    "    # 按索引排序返回\n",
    "    return sorted(merged.values(), key=lambda h: h.section_index)\n",
    "\n",
    "# ---------- 4. 修正后的状态结构 ----------\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    plan: List[Dict]\n",
    "    # 修复：使用正确签名的合并函数\n",
    "    section_histories: Annotated[List[SectionHistory], merge_section_histories]\n",
    "    report_versions: List[ReportVersion]\n",
    "    current_report_version: int\n",
    "    regenerate_count: int\n",
    "    search_results: Annotated[List[Dict], operator.add]\n",
    "    final_report: str\n",
    "    validation_result: Optional[Dict]\n",
    "    output_format: str\n",
    "    todo_list: List[str]\n",
    "    completed_tasks: List[str]\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section_info: Dict\n",
    "    section_index: int\n",
    "    topic: str\n",
    "    regenerate_count: int\n",
    "    validation_issues: List[str]\n",
    "    existing_histories: List[SectionHistory]\n",
    "\n",
    "# ---------- 5. 工具函数 ----------\n",
    "def setup_directories():\n",
    "    \"\"\"创建工作目录\"\"\"\n",
    "    dirs = [\"versions\", \"search_results\", \"reports\", \"drafts\"]\n",
    "    for dir_name in dirs:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "def save_version_history(section_histories: List[SectionHistory], version: int):\n",
    "    \"\"\"保存版本历史到文件\"\"\"\n",
    "    version_dir = f\"versions/v{version}\"\n",
    "    os.makedirs(version_dir, exist_ok=True)\n",
    "    \n",
    "    for history in section_histories:\n",
    "        filename = f\"{version_dir}/section_{history.section_index:02d}_history.json\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(history.dict(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_version_history(version: int) -> List[SectionHistory]:\n",
    "    \"\"\"从文件加载版本历史\"\"\"\n",
    "    version_dir = f\"versions/v{version}\"\n",
    "    histories = []\n",
    "    \n",
    "    if os.path.exists(version_dir):\n",
    "        files = [f for f in os.listdir(version_dir) if f.endswith('_history.json')]\n",
    "        for filename in sorted(files):\n",
    "            filepath = os.path.join(version_dir, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                histories.append(SectionHistory(**data))\n",
    "    \n",
    "    return histories\n",
    "\n",
    "def update_todo_list(todo_list: List[str], completed_tasks: List[str], version: int):\n",
    "    \"\"\"更新TODO列表\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    with open(f\"todo_v{version}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"=== 报告生成任务列表 v{version} ({timestamp}) ===\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 已完成任务:\\n\")\n",
    "        for task in completed_tasks:\n",
    "            f.write(f\"✅ {task}\\n\")\n",
    "        \n",
    "        f.write(\"\\n## 待完成任务:\\n\")\n",
    "        for task in todo_list:\n",
    "            f.write(f\"🔘 {task}\\n\")\n",
    "        \n",
    "        f.write(f\"\\n## 进度: {len(completed_tasks)}/{len(completed_tasks) + len(todo_list)}\\n\")\n",
    "\n",
    "def optimize_search_query(section_info: Dict, topic: str, history: SectionHistory = None) -> str:\n",
    "    \"\"\"优化搜索查询\"\"\"\n",
    "    context = \"\"\n",
    "    if history and history.versions:\n",
    "        recent_titles = [v.title for v in history.versions[-2:]]\n",
    "        context = f\"之前版本标题: {', '.join(recent_titles)}\"\n",
    "    \n",
    "    optimization_prompt = f\"\"\"\n",
    "    主题: {topic}\n",
    "    章节标题: {section_info['title']}\n",
    "    章节描述: {section_info['description']}\n",
    "    {context}\n",
    "    \n",
    "    请生成一个优化的搜索查询，要求：\n",
    "    1. 包含核心关键词\n",
    "    2. 避免重复之前的内容\n",
    "    3. 寻找最新信息和案例\n",
    "    4. 限制50字以内\n",
    "    \n",
    "    直接返回搜索查询。\n",
    "    \"\"\"\n",
    "    \n",
    "    optimized_query = llm.invoke([\n",
    "        SystemMessage(content=\"你是搜索优化专家，专门基于历史版本优化搜索策略。\"),\n",
    "        HumanMessage(content=optimization_prompt)\n",
    "    ]).content.strip()\n",
    "    \n",
    "    return optimized_query\n",
    "\n",
    "def process_search_results(search_results: List[Dict], section_info: Dict) -> str:\n",
    "    \"\"\"处理搜索结果\"\"\"\n",
    "    if not search_results:\n",
    "        return \"无搜索结果\"\n",
    "    \n",
    "    content = \"\\n\".join([doc.get(\"content\", \"\")[:300] for doc in search_results])\n",
    "    \n",
    "    process_prompt = f\"\"\"\n",
    "    章节: {section_info['title']}\n",
    "    搜索结果: {content}\n",
    "    \n",
    "    请整合关键信息，去除重复内容，提取核心要点。\n",
    "    \"\"\"\n",
    "    \n",
    "    processed = llm.invoke([\n",
    "        SystemMessage(content=\"你是信息整合专家。\"),\n",
    "        HumanMessage(content=process_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# ---------- 6. 计划节点 ----------\n",
    "def plan_node(state: State):\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    \n",
    "    if regenerate_count > 0:\n",
    "        print(f\"🔄 重新生成 (第 {regenerate_count} 次)\")\n",
    "        # 重新生成时加载现有历史\n",
    "        current_version = state.get('current_report_version', 1)\n",
    "        existing_histories = load_version_history(current_version - 1) if current_version > 1 else []\n",
    "        \n",
    "        return {\n",
    "            \"regenerate_count\": regenerate_count,\n",
    "            \"current_report_version\": current_version,\n",
    "            \"section_histories\": existing_histories\n",
    "        }\n",
    "    \n",
    "    print(\"📋 初始计划制定...\")\n",
    "    \n",
    "    plan_prompt = f\"\"\"为\"{state['topic']}\"写一份详细的大纲，每节含标题和简短描述。\n",
    "    \n",
    "    请以 JSON 格式返回：\n",
    "    {{\n",
    "        \"sections\": [\n",
    "            {{\"title\": \"章节标题\", \"description\": \"章节描述\"}}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    class PlanSchema(BaseModel):\n",
    "        sections: List[Dict] = Field(description=\"章节列表\")\n",
    "    \n",
    "    planner = llm.with_structured_output(PlanSchema)\n",
    "    plan = planner.invoke([\n",
    "        SystemMessage(content=\"你是专业的报告规划师，请按照JSON格式返回报告大纲。\"),\n",
    "        HumanMessage(content=plan_prompt)\n",
    "    ])\n",
    "    \n",
    "    # 初始化章节历史\n",
    "    section_histories = []\n",
    "    for i, section in enumerate(plan.sections):\n",
    "        history = SectionHistory(\n",
    "            section_index=i,\n",
    "            base_title=section['title']\n",
    "        )\n",
    "        section_histories.append(history)\n",
    "    \n",
    "    # 创建首个报告版本记录\n",
    "    report_version = ReportVersion(\n",
    "        version=1,\n",
    "        timestamp=datetime.datetime.now().isoformat(),\n",
    "        section_versions={},\n",
    "        regenerate_reason=\"初始生成\"\n",
    "    )\n",
    "    \n",
    "    todo_list = [f\"生成章节: {section['title']}\" for section in plan.sections]\n",
    "    todo_list.extend([\"合并章节\", \"验证报告\"])\n",
    "    \n",
    "    update_todo_list(todo_list, [\"制定计划\"], 1)\n",
    "    \n",
    "    return {\n",
    "        \"plan\": plan.sections,\n",
    "        \"section_histories\": section_histories,\n",
    "        \"report_versions\": [report_version],\n",
    "        \"current_report_version\": 1,\n",
    "        \"regenerate_count\": 0,\n",
    "        \"todo_list\": todo_list,\n",
    "        \"completed_tasks\": [\"制定计划\"]\n",
    "    }\n",
    "\n",
    "# ---------- 7. Worker节点 ----------\n",
    "def worker_node(state: WorkerState):\n",
    "    section_info = state['section_info']\n",
    "    index = state['section_index']\n",
    "    topic = state['topic']\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    validation_issues = state.get('validation_issues', [])\n",
    "    existing_histories = state.get('existing_histories', [])\n",
    "    \n",
    "    print(f\"🔄 处理章节 {index + 1}: {section_info['title']}\")\n",
    "    \n",
    "    # 获取当前章节历史\n",
    "    current_history = None\n",
    "    for history in existing_histories:\n",
    "        if history.section_index == index:\n",
    "            current_history = history\n",
    "            break\n",
    "    \n",
    "    if not current_history:\n",
    "        current_history = SectionHistory(\n",
    "            section_index=index,\n",
    "            base_title=section_info['title']\n",
    "        )\n",
    "    \n",
    "    # 检查是否需要重新生成\n",
    "    current_version = current_history.get_current()\n",
    "    section_issues = [issue for issue in validation_issues if f\"章节{index + 1}\" in issue]\n",
    "    \n",
    "    # 如果是首次生成或有问题需要改进\n",
    "    if not current_version or section_issues or regenerate_count > 0:\n",
    "        \n",
    "        # 优化搜索\n",
    "        optimized_query = optimize_search_query(section_info, topic, current_history)\n",
    "        \n",
    "        # 执行搜索\n",
    "        try:\n",
    "            search_results = search.invoke(optimized_query)\n",
    "            processed_content = process_search_results(search_results, section_info)\n",
    "        except Exception as e:\n",
    "            print(f\"搜索错误: {e}\")\n",
    "            processed_content = \"无法获取相关信息\"\n",
    "            search_results = []\n",
    "        \n",
    "        # 构建写作提示\n",
    "        improvement_context = \"\"\n",
    "        if current_version:\n",
    "            improvement_context = f\"\"\"\n",
    "            当前版本 (v{current_version.version}):\n",
    "            标题: {current_version.title}\n",
    "            内容长度: {len(current_version.content)} 字\n",
    "            \n",
    "            需要改进的问题:\n",
    "            {', '.join(section_issues)}\n",
    "            \n",
    "            请在现有基础上改进，不要简单重复。\n",
    "            \"\"\"\n",
    "        \n",
    "        writer_prompt = f\"\"\"\n",
    "        你是专业的报告写作专家。\n",
    "        \n",
    "        章节信息:\n",
    "        - 标题: {section_info['title']}\n",
    "        - 描述: {section_info['description']}\n",
    "        - 版本: {current_version.version + 1 if current_version else 1}\n",
    "        \n",
    "        {improvement_context}\n",
    "        \n",
    "        搜索素材:\n",
    "        {processed_content}\n",
    "        \n",
    "        请{\"改进现有内容\" if current_version else \"创作新内容\"}，要求：\n",
    "        1. 避免与历史版本重复\n",
    "        2. 针对具体问题进行改进\n",
    "        3. 使用最新信息和案例\n",
    "        4. 保持专业性和可读性\n",
    "        5. 长度400-600字\n",
    "        \n",
    "        直接返回改进后的内容，使用Markdown格式。\n",
    "        \"\"\"\n",
    "        \n",
    "        # 生成新版本\n",
    "        new_content = llm.invoke([\n",
    "            SystemMessage(content=\"你是专业的报告写作专家，专注于基于反馈的迭代改进。\"),\n",
    "            HumanMessage(content=writer_prompt)\n",
    "        ]).content\n",
    "        \n",
    "        # 添加到历史记录\n",
    "        if current_history.add_version(section_info['title'], new_content):\n",
    "            # 保存当前版本到文件\n",
    "            version_num = current_history.current_version\n",
    "            draft_filename = f\"drafts/section_{index:02d}_v{version_num}_{section_info['title'].replace(' ', '_')}.md\"\n",
    "            with open(draft_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"# {section_info['title']} (v{version_num})\\n\\n{new_content}\")\n",
    "            \n",
    "            print(f\"✅ 章节 {index + 1} 已更新到 v{version_num}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"✅ 章节 {index + 1} 无需更新\")\n",
    "    \n",
    "    # 返回单个历史记录\n",
    "    return {\n",
    "        \"section_histories\": [current_history],\n",
    "        \"search_results\": [{\n",
    "            \"section_index\": index,\n",
    "            \"query\": optimized_query if 'optimized_query' in locals() else \"\",\n",
    "            \"results\": search_results if 'search_results' in locals() else []\n",
    "        }]\n",
    "    }\n",
    "\n",
    "# ---------- 8. 分发节点 ----------\n",
    "def dispatch(state: State):\n",
    "    print(f\"📋 分发任务到 {len(state['plan'])} 个worker\")\n",
    "    \n",
    "    # 获取验证问题\n",
    "    validation_issues = []\n",
    "    if state.get('validation_result'):\n",
    "        validation_issues = state['validation_result'].get('issues', [])\n",
    "    \n",
    "    existing_histories = state.get('section_histories', [])\n",
    "    \n",
    "    return [\n",
    "        Send(\"worker\", {\n",
    "            \"section_info\": section,\n",
    "            \"section_index\": i,\n",
    "            \"topic\": state['topic'],\n",
    "            \"regenerate_count\": state.get('regenerate_count', 0),\n",
    "            \"validation_issues\": validation_issues,\n",
    "            \"existing_histories\": existing_histories\n",
    "        })\n",
    "        for i, section in enumerate(state[\"plan\"])\n",
    "    ]\n",
    "\n",
    "# ---------- 9. 合并节点 ----------\n",
    "def merge_node(state: State):\n",
    "    current_version = state.get('current_report_version', 1)\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    \n",
    "    print(f\"📝 合并报告 v{current_version} (重新生成次数: {regenerate_count})\")\n",
    "    \n",
    "    # 获取当前版本的章节内容\n",
    "    current_sections = []\n",
    "    section_version_map = {}\n",
    "    \n",
    "    # 确保按索引排序\n",
    "    sorted_histories = sorted(state['section_histories'], key=lambda h: h.section_index)\n",
    "    \n",
    "    for history in sorted_histories:\n",
    "        current_section = history.get_current()\n",
    "        if current_section:\n",
    "            current_sections.append({\n",
    "                'index': history.section_index,\n",
    "                'title': current_section.title,\n",
    "                'content': current_section.content,\n",
    "                'version': current_section.version\n",
    "            })\n",
    "            section_version_map[history.section_index] = current_section.version\n",
    "    \n",
    "    # 生成过渡内容\n",
    "    transition_prompt = f\"\"\"\n",
    "    主题: {state['topic']}\n",
    "    章节标题: {[s['title'] for s in current_sections]}\n",
    "    \n",
    "    为相邻章节生成简洁的过渡语，每个1-2句。\n",
    "    \"\"\"\n",
    "    \n",
    "    transitions = llm.invoke([\n",
    "        SystemMessage(content=\"你是文章结构专家。\"),\n",
    "        HumanMessage(content=transition_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    # 组装最终报告\n",
    "    report = f\"# {state['topic']}\\n\\n\"\n",
    "    report += f\"*版本: v{current_version} | 生成时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\\n\"\n",
    "    \n",
    "    # 版本信息摘要\n",
    "    report += \"## 版本信息\\n\\n\"\n",
    "    for section in current_sections:\n",
    "        report += f\"- {section['title']}: v{section['version']}\\n\"\n",
    "    \n",
    "    if regenerate_count > 0:\n",
    "        report += f\"- 重新生成次数: {regenerate_count}\\n\"\n",
    "    \n",
    "    report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    # 目录\n",
    "    report += \"## 目录\\n\\n\"\n",
    "    for i, section in enumerate(current_sections):\n",
    "        report += f\"{i+1}. [{section['title']}](#{section['title'].replace(' ', '-').lower()})\\n\"\n",
    "    report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    # 章节内容\n",
    "    for i, section in enumerate(current_sections):\n",
    "        report += f\"## {section['title']}\\n\\n\"\n",
    "        report += section['content']\n",
    "        \n",
    "        if i < len(current_sections) - 1:\n",
    "            report += \"\\n\\n*[过渡到下一章节]*\\n\\n\"\n",
    "        \n",
    "        report += \"\\n\\n---\\n\\n\"\n",
    "    \n",
    "    # 保存报告\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"reports/report_v{current_version}_{timestamp}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    # 保存版本历史\n",
    "    save_version_history(state['section_histories'], current_version)\n",
    "    \n",
    "    # 更新报告版本记录\n",
    "    report_versions = state.get('report_versions', [])\n",
    "    current_report_version = ReportVersion(\n",
    "        version=current_version,\n",
    "        timestamp=datetime.datetime.now().isoformat(),\n",
    "        section_versions=section_version_map,\n",
    "        regenerate_reason=f\"第 {regenerate_count} 次重新生成\" if regenerate_count > 0 else \"正常生成\"\n",
    "    )\n",
    "    \n",
    "    # 更新或添加当前版本记录\n",
    "    updated_versions = [v for v in report_versions if v.version != current_version]\n",
    "    updated_versions.append(current_report_version)\n",
    "    \n",
    "    return {\n",
    "        \"final_report\": report,\n",
    "        \"report_versions\": updated_versions\n",
    "    }\n",
    "\n",
    "# ---------- 10. 验证节点 ----------\n",
    "def validation_node(state: State):\n",
    "    current_version = state.get('current_report_version', 1)\n",
    "    print(f\"🔍 验证报告 v{current_version}...\")\n",
    "    \n",
    "    validation_prompt = f\"\"\"\n",
    "    请验证以下报告的质量：\n",
    "    \n",
    "    主题: {state['topic']}\n",
    "    版本: v{current_version}\n",
    "    \n",
    "    报告内容 (前1500字):\n",
    "    {state['final_report'][:1500]}...\n",
    "    \n",
    "    请从以下方面评估并返回JSON格式：\n",
    "    1. 内容完整性和深度\n",
    "    2. 逻辑结构和连贯性\n",
    "    3. 语言质量和专业性\n",
    "    4. 创新性和时效性\n",
    "    \n",
    "    返回格式：\n",
    "    {{\n",
    "        \"is_valid\": true/false,\n",
    "        \"score\": 8.5,\n",
    "        \"issues\": [\"具体问题1\", \"具体问题2\"],\n",
    "        \"suggestions\": [\"改进建议1\", \"改进建议2\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    class ValidationSchema(BaseModel):\n",
    "        is_valid: bool\n",
    "        score: float\n",
    "        issues: List[str]\n",
    "        suggestions: List[str]\n",
    "    \n",
    "    validator = llm.with_structured_output(ValidationSchema)\n",
    "    validation = validator.invoke([\n",
    "        SystemMessage(content=\"你是专业的内容质量评估专家，请按JSON格式返回验证结果。\"),\n",
    "        HumanMessage(content=validation_prompt)\n",
    "    ])\n",
    "    \n",
    "    print(f\"📊 验证结果: 得分 {validation.score}/10 | {'通过' if validation.is_valid else '需要改进'}\")\n",
    "    \n",
    "    if not validation.is_valid:\n",
    "        print(\"⚠️ 发现问题:\")\n",
    "        for issue in validation.issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    \n",
    "    # 更新报告版本的验证状态\n",
    "    report_versions = state.get('report_versions', [])\n",
    "    for version in report_versions:\n",
    "        if version.version == current_version:\n",
    "            version.validation_passed = validation.is_valid\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        \"validation_result\": validation.dict(),\n",
    "        \"report_versions\": report_versions\n",
    "    }\n",
    "\n",
    "# ---------- 11. 路由函数 ----------\n",
    "def should_regenerate(state: State):\n",
    "    \"\"\"决定是否重新生成\"\"\"\n",
    "    validation = state.get('validation_result', {})\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    \n",
    "    if not validation.get('is_valid', True) and regenerate_count < MAX_REGEN:\n",
    "        return \"regenerate\"\n",
    "    return \"complete\"\n",
    "\n",
    "def regenerate_routing(state: State):\n",
    "    \"\"\"重新生成时的路由\"\"\"\n",
    "    regenerate_count = state.get('regenerate_count', 0) + 1\n",
    "    current_version = state.get('current_report_version', 1) + 1\n",
    "    \n",
    "    print(f\"🔄 开始第 {regenerate_count} 次重新生成 (v{current_version})\")\n",
    "    \n",
    "    return {\n",
    "        \"regenerate_count\": regenerate_count,\n",
    "        \"current_report_version\": current_version\n",
    "    }\n",
    "\n",
    "# ---------- 12. 构建工作流 ----------\n",
    "def build_workflow():\n",
    "    setup_directories()\n",
    "    \n",
    "    workflow = StateGraph(State)\n",
    "    \n",
    "    # 添加节点\n",
    "    workflow.add_node(\"plan\", plan_node)\n",
    "    workflow.add_node(\"worker\", worker_node)\n",
    "    workflow.add_node(\"merge\", merge_node)\n",
    "    workflow.add_node(\"validate\", validation_node)\n",
    "    workflow.add_node(\"regenerate\", regenerate_routing)\n",
    "    workflow.add_node(\"complete\", lambda state: state)\n",
    "    \n",
    "    # 添加边\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_conditional_edges(\"plan\", dispatch, [\"worker\"])\n",
    "    workflow.add_edge(\"worker\", \"merge\")\n",
    "    workflow.add_edge(\"merge\", \"validate\")\n",
    "    workflow.add_conditional_edges(\"validate\", should_regenerate, {\n",
    "        \"complete\": \"complete\",\n",
    "        \"regenerate\": \"regenerate\"\n",
    "    })\n",
    "    workflow.add_edge(\"regenerate\", \"worker\")\n",
    "    workflow.add_edge(\"complete\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# ---------- 13. 主程序 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 启动版本控制报告生成系统...\")\n",
    "    \n",
    "    app = build_workflow()\n",
    "    \n",
    "    config = {\n",
    "        \"topic\": \"生成式 AI 如何重塑教育\",\n",
    "        \"regenerate_count\": 0,\n",
    "        \"current_report_version\": 1,\n",
    "        \"output_format\": \"markdown\",\n",
    "        \"section_histories\": [],\n",
    "        \"report_versions\": [],\n",
    "        \"search_results\": [],\n",
    "        \"todo_list\": [],\n",
    "        \"completed_tasks\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 设置递归限制\n",
    "        result = app.invoke(config, config={\"recursion_limit\": 50})\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📊 报告生成完成!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 显示版本信息\n",
    "        current_version = result.get('current_report_version', 1)\n",
    "        print(f\"\\n📋 最终版本: v{current_version}\")\n",
    "        \n",
    "        print(\"\\n📁 生成的文件:\")\n",
    "        print(f\"  - 最终报告: reports/report_v{current_version}_*.md\")\n",
    "        print(f\"  - 章节草稿: drafts/section_*_v*_*.md\")\n",
    "        print(f\"  - 版本历史: versions/v*/\")\n",
    "        print(f\"  - 任务列表: todo_v{current_version}.txt\")\n",
    "        \n",
    "        validation = result.get('validation_result', {})\n",
    "        if validation:\n",
    "            print(f\"\\n✅ 最终得分: {validation.get('score', 0)}/10\")\n",
    "            print(f\"📊 状态: {'通过' if validation.get('is_valid', False) else '需要改进'}\")\n",
    "        \n",
    "        # 显示章节版本信息\n",
    "        print(f\"\\n📖 章节版本:\")\n",
    "        for history in sorted(result.get('section_histories', []), key=lambda h: h.section_index):\n",
    "            current = history.get_current()\n",
    "            if current:\n",
    "                print(f\"  {history.section_index + 1}. {current.title} (v{current.version})\")\n",
    "        \n",
    "        print(f\"\\n📝 最终报告预览:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(result[\"final_report\"][:500] + \"...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 生成失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "import operator\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import hashlib\n",
    "import re\n",
    "from typing import Annotated, List, TypedDict, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ---------- 1. 全局配置 ----------\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "search = TavilySearchResults(max_results=5)  # 增加搜索结果数量\n",
    "MAX_REGEN = 3\n",
    "\n",
    "# ---------- 2. 增强的数据结构 ----------\n",
    "class ImageInfo(BaseModel):\n",
    "    url: str\n",
    "    description: str\n",
    "    source: str\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "class SectionVersion(BaseModel):\n",
    "    version: int\n",
    "    title: str\n",
    "    content: str\n",
    "    content_hash: str\n",
    "    timestamp: str\n",
    "    is_current: bool = False\n",
    "    images: List[ImageInfo] = []  # 新增：关联的图片\n",
    "\n",
    "class SectionHistory(BaseModel):\n",
    "    section_index: int\n",
    "    base_title: str\n",
    "    versions: List[SectionVersion] = []\n",
    "    current_version: int = 0\n",
    "    \n",
    "    def add_version(self, title: str, content: str, images: List[ImageInfo] = None) -> bool:\n",
    "        \"\"\"添加新版本，检查是否重复\"\"\"\n",
    "        content_hash = hashlib.md5(content.encode()).hexdigest()\n",
    "        \n",
    "        # 检查是否与现有版本重复\n",
    "        for version in self.versions:\n",
    "            if version.content_hash == content_hash:\n",
    "                print(f\"⚠️ 跳过重复内容: {title}\")\n",
    "                return False\n",
    "        \n",
    "        # 将之前的版本标记为非当前\n",
    "        for version in self.versions:\n",
    "            version.is_current = False\n",
    "        \n",
    "        # 添加新版本\n",
    "        new_version = SectionVersion(\n",
    "            version=len(self.versions) + 1,\n",
    "            title=title,\n",
    "            content=content,\n",
    "            content_hash=content_hash,\n",
    "            timestamp=datetime.datetime.now().isoformat(),\n",
    "            is_current=True,\n",
    "            images=images or []\n",
    "        )\n",
    "        \n",
    "        self.versions.append(new_version)\n",
    "        self.current_version = new_version.version\n",
    "        \n",
    "        print(f\"✅ 新版本: {title} (v{new_version.version}) - 包含 {len(new_version.images)} 张图片\")\n",
    "        return True\n",
    "    \n",
    "    def get_current(self) -> Optional[SectionVersion]:\n",
    "        \"\"\"获取当前版本\"\"\"\n",
    "        for version in self.versions:\n",
    "            if version.is_current:\n",
    "                return version\n",
    "        return None\n",
    "\n",
    "class TransitionInfo(BaseModel):\n",
    "    from_section: int\n",
    "    to_section: int\n",
    "    transition_text: str\n",
    "    connection_type: str  # \"logical\", \"causal\", \"temporal\", \"contrast\"\n",
    "\n",
    "class ReportVersion(BaseModel):\n",
    "    version: int\n",
    "    timestamp: str\n",
    "    section_versions: Dict[int, int]\n",
    "    validation_passed: bool = False\n",
    "    regenerate_reason: str = \"\"\n",
    "    transitions: List[TransitionInfo] = []  # 新增：过渡信息\n",
    "\n",
    "# ---------- 3. 合并函数 ----------\n",
    "def merge_section_histories(\n",
    "    left: List[SectionHistory], \n",
    "    right: List[SectionHistory]\n",
    ") -> List[SectionHistory]:\n",
    "    \"\"\"合并两个章节历史列表\"\"\"\n",
    "    all_histories = left + right\n",
    "    merged = {}\n",
    "    for history in all_histories:\n",
    "        key = history.section_index\n",
    "        if key not in merged:\n",
    "            merged[key] = history\n",
    "        else:\n",
    "            if history.current_version > merged[key].current_version:\n",
    "                merged[key] = history\n",
    "    return sorted(merged.values(), key=lambda h: h.section_index)\n",
    "\n",
    "# ---------- 4. 状态结构 ----------\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    plan: List[Dict]\n",
    "    section_histories: Annotated[List[SectionHistory], merge_section_histories]\n",
    "    report_versions: List[ReportVersion]\n",
    "    current_report_version: int\n",
    "    regenerate_count: int\n",
    "    search_results: Annotated[List[Dict], operator.add]\n",
    "    final_report: str\n",
    "    validation_result: Optional[Dict]\n",
    "    output_format: str\n",
    "    todo_list: List[str]\n",
    "    completed_tasks: List[str]\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section_info: Dict\n",
    "    section_index: int\n",
    "    topic: str\n",
    "    regenerate_count: int\n",
    "    validation_issues: List[str]\n",
    "    existing_histories: List[SectionHistory]\n",
    "\n",
    "# ---------- 5. 工具函数 ----------\n",
    "def setup_directories():\n",
    "    \"\"\"创建工作目录\"\"\"\n",
    "    dirs = [\"versions\", \"search_results\", \"reports\", \"drafts\", \"images\"]\n",
    "    for dir_name in dirs:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "def save_version_history(section_histories: List[SectionHistory], version: int):\n",
    "    \"\"\"保存版本历史到文件\"\"\"\n",
    "    version_dir = f\"versions/v{version}\"\n",
    "    os.makedirs(version_dir, exist_ok=True)\n",
    "    \n",
    "    for history in section_histories:\n",
    "        filename = f\"{version_dir}/section_{history.section_index:02d}_history.json\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(history.dict(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_version_history(version: int) -> List[SectionHistory]:\n",
    "    \"\"\"从文件加载版本历史\"\"\"\n",
    "    version_dir = f\"versions/v{version}\"\n",
    "    histories = []\n",
    "    \n",
    "    if os.path.exists(version_dir):\n",
    "        files = [f for f in os.listdir(version_dir) if f.endswith('_history.json')]\n",
    "        for filename in sorted(files):\n",
    "            filepath = os.path.join(version_dir, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                histories.append(SectionHistory(**data))\n",
    "    \n",
    "    return histories\n",
    "\n",
    "def update_todo_list(todo_list: List[str], completed_tasks: List[str], version: int):\n",
    "    \"\"\"更新TODO列表\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    with open(f\"todo_v{version}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"=== 报告生成任务列表 v{version} ({timestamp}) ===\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 已完成任务:\\n\")\n",
    "        for task in completed_tasks:\n",
    "            f.write(f\"✅ {task}\\n\")\n",
    "        \n",
    "        f.write(\"\\n## 待完成任务:\\n\")\n",
    "        for task in todo_list:\n",
    "            f.write(f\"🔘 {task}\\n\")\n",
    "        \n",
    "        f.write(f\"\\n## 进度: {len(completed_tasks)}/{len(completed_tasks) + len(todo_list)}\\n\")\n",
    "'''\n",
    "def extract_images_from_search(search_results: List[Dict]) -> List[ImageInfo]:\n",
    "    \"\"\"从搜索结果中提取图片信息\"\"\"\n",
    "    images = []\n",
    "    for result in search_results:\n",
    "        # 检查是否包含图片URL\n",
    "        content = result.get(\"content\", \"\")\n",
    "        url = result.get(\"url\", \"\")\n",
    "        \n",
    "        # 使用正则表达式查找图片URL\n",
    "        image_patterns = [\n",
    "            r'https?://[^\\s]+\\.(?:jpg|jpeg|png|gif|webp|svg)',\n",
    "            r'!\\[.*?\\]\\((https?://[^\\s]+\\.(?:jpg|jpeg|png|gif|webp|svg))\\)',\n",
    "            r'<img[^>]+src=\"([^\"]+)\"'\n",
    "        ]\n",
    "        \n",
    "        for pattern in image_patterns:\n",
    "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple):\n",
    "                    img_url = match[0]\n",
    "                else:\n",
    "                    img_url = match\n",
    "                \n",
    "                images.append(ImageInfo(\n",
    "                    url=img_url,\n",
    "                    description=f\"来自 {url}\",\n",
    "                    source=url,\n",
    "                    relevance_score=0.8\n",
    "                ))\n",
    "    \n",
    "    # 去重并限制数量\n",
    "    unique_images = {}\n",
    "    for img in images:\n",
    "        if img.url not in unique_images:\n",
    "            unique_images[img.url] = img\n",
    "    \n",
    "    return list(unique_images.values())[:3]  # 最多3张图片\n",
    "'''\n",
    "\n",
    "def optimize_search_query(section_info: Dict, topic: str, history: SectionHistory = None) -> str:\n",
    "    \"\"\"优化搜索查询\"\"\"\n",
    "    context = \"\"\n",
    "    if history and history.versions:\n",
    "        recent_titles = [v.title for v in history.versions[-2:]]\n",
    "        context = f\"之前版本标题: {', '.join(recent_titles)}\"\n",
    "    \n",
    "    optimization_prompt = f\"\"\"\n",
    "    主题: {topic}\n",
    "    章节标题: {section_info['title']}\n",
    "    章节描述: {section_info['description']}\n",
    "    {context}\n",
    "    \n",
    "    请生成一个优化的搜索查询，要求：\n",
    "    1. 包含核心关键词和相关术语\n",
    "    2. 避免重复之前的内容\n",
    "    3. 寻找最新信息、案例和数据\n",
    "    4. 包含可能的图表和可视化内容\n",
    "    5. 限制在50字以内\n",
    "    \n",
    "    直接返回搜索查询。\n",
    "    \"\"\"\n",
    "    \n",
    "    optimized_query = llm.invoke([\n",
    "        SystemMessage(content=\"你是搜索优化专家，专门基于历史版本优化搜索策略。\"),\n",
    "        HumanMessage(content=optimization_prompt)\n",
    "    ]).content.strip()\n",
    "    \n",
    "    return optimized_query\n",
    "\n",
    "def process_search_results(search_results: List[Dict], section_info: Dict) -> tuple[str, List[ImageInfo]]:\n",
    "    \"\"\"处理搜索结果，返回文本内容和图片信息\"\"\"\n",
    "    if not search_results:\n",
    "        return \"无搜索结果\", []\n",
    "    \n",
    "    # 提取图片\n",
    "    images = extract_images_from_search(search_results)\n",
    "    \n",
    "    # 处理文本内容\n",
    "    content = \"\\n\".join([doc.get(\"content\", \"\")[:400] for doc in search_results])\n",
    "    \n",
    "    process_prompt = f\"\"\"\n",
    "    章节: {section_info['title']}\n",
    "    搜索结果: {content}\n",
    "    \n",
    "    请整合关键信息，要求：\n",
    "    1. 提取核心要点和数据\n",
    "    2. 去除重复内容\n",
    "    3. 按逻辑重要性排序\n",
    "    4. 保持事实准确性\n",
    "    5. 标注适合插入图片的位置（用[图片插入点]标记）\n",
    "    \n",
    "    返回整合后的素材。\n",
    "    \"\"\"\n",
    "    \n",
    "    processed = llm.invoke([\n",
    "        SystemMessage(content=\"你是信息整合专家，擅长从多个来源提取和整合关键信息。\"),\n",
    "        HumanMessage(content=process_prompt)\n",
    "    ]).content\n",
    "    \n",
    "    return processed, images\n",
    "\n",
    "def insert_images_into_content(content: str, images: List[ImageInfo]) -> str:\n",
    "    \"\"\"将图片插入到内容中的合适位置\"\"\"\n",
    "    if not images:\n",
    "        return content\n",
    "    \n",
    "    # 找到合适的插入点\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "    result_paragraphs = []\n",
    "    \n",
    "    image_index = 0\n",
    "    for i, paragraph in enumerate(paragraphs):\n",
    "        result_paragraphs.append(paragraph)\n",
    "        \n",
    "        # 在每隔2-3段插入一张图片\n",
    "        if image_index < len(images) and i > 0 and (i + 1) % 3 == 0:\n",
    "            img = images[image_index]\n",
    "            image_md = f\"\\n\\n![{img.description}]({img.url})\\n*图片来源: {img.source}*\\n\"\n",
    "            result_paragraphs.append(image_md)\n",
    "            image_index += 1\n",
    "    \n",
    "    return '\\n\\n'.join(result_paragraphs)\n",
    "\n",
    "# ---------- 6. 计划节点 ----------\n",
    "def plan_node(state: State):\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    \n",
    "    if regenerate_count > 0:\n",
    "        print(f\"🔄 重新生成 (第 {regenerate_count} 次)\")\n",
    "        current_version = state.get('current_report_version', 1)\n",
    "        existing_histories = load_version_history(current_version - 1) if current_version > 1 else []\n",
    "        \n",
    "        return {\n",
    "            \"regenerate_count\": regenerate_count,\n",
    "            \"current_report_version\": current_version,\n",
    "            \"section_histories\": existing_histories\n",
    "        }\n",
    "    \n",
    "    print(\"📋 初始计划制定...\")\n",
    "    \n",
    "    plan_prompt = f\"\"\"为\"{state['topic']}\"写一份详细的报告大纲，每节含标题和简短描述。\n",
    "    \n",
    "    要求：\n",
    "    1. 逻辑结构清晰，章节间有自然的递进关系\n",
    "    2. 每个章节都有明确的主题和目标\n",
    "    3. 适合插入相关图表和案例\n",
    "    4. 总共4-6个章节\n",
    "    \n",
    "    请以 JSON 格式返回：\n",
    "    {{\n",
    "        \"sections\": [\n",
    "            {{\"title\": \"章节标题\", \"description\": \"章节描述\", \"connection_type\": \"logical\"}}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    connection_type 可以是: \"logical\"(逻辑递进), \"causal\"(因果关系), \"temporal\"(时间顺序), \"contrast\"(对比关系)\n",
    "    \"\"\"\n",
    "    \n",
    "    class PlanSchema(BaseModel):\n",
    "        sections: List[Dict] = Field(description=\"章节列表\")\n",
    "    \n",
    "    planner = llm.with_structured_output(PlanSchema)\n",
    "    plan = planner.invoke([\n",
    "        SystemMessage(content=\"你是专业的报告规划师，请按照JSON格式返回逻辑清晰的报告大纲。\"),\n",
    "        HumanMessage(content=plan_prompt)\n",
    "    ])\n",
    "    \n",
    "    # 初始化章节历史\n",
    "    section_histories = []\n",
    "    for i, section in enumerate(plan.sections):\n",
    "        history = SectionHistory(\n",
    "            section_index=i,\n",
    "            base_title=section['title']\n",
    "        )\n",
    "        section_histories.append(history)\n",
    "    \n",
    "    report_version = ReportVersion(\n",
    "        version=1,\n",
    "        timestamp=datetime.datetime.now().isoformat(),\n",
    "        section_versions={},\n",
    "        regenerate_reason=\"初始生成\"\n",
    "    )\n",
    "    \n",
    "    todo_list = [f\"生成章节: {section['title']}\" for section in plan.sections]\n",
    "    todo_list.extend([\"生成章节过渡\", \"合并章节\", \"验证报告\"])\n",
    "    \n",
    "    update_todo_list(todo_list, [\"制定计划\"], 1)\n",
    "    \n",
    "    return {\n",
    "        \"plan\": plan.sections,\n",
    "        \"section_histories\": section_histories,\n",
    "        \"report_versions\": [report_version],\n",
    "        \"current_report_version\": 1,\n",
    "        \"regenerate_count\": 0,\n",
    "        \"todo_list\": todo_list,\n",
    "        \"completed_tasks\": [\"制定计划\"]\n",
    "    }\n",
    "\n",
    "# ---------- 7. Worker节点 ----------\n",
    "def worker_node(state: WorkerState):\n",
    "    section_info = state['section_info']\n",
    "    index = state['section_index']\n",
    "    topic = state['topic']\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    validation_issues = state.get('validation_issues', [])\n",
    "    existing_histories = state.get('existing_histories', [])\n",
    "    \n",
    "    print(f\"🔄 处理章节 {index + 1}: {section_info['title']}\")\n",
    "    \n",
    "    # 获取当前章节历史\n",
    "    current_history = None\n",
    "    for history in existing_histories:\n",
    "        if history.section_index == index:\n",
    "            current_history = history\n",
    "            break\n",
    "    \n",
    "    if not current_history:\n",
    "        current_history = SectionHistory(\n",
    "            section_index=index,\n",
    "            base_title=section_info['title']\n",
    "        )\n",
    "    \n",
    "    # 检查是否需要重新生成\n",
    "    current_version = current_history.get_current()\n",
    "    section_issues = [issue for issue in validation_issues if f\"章节{index + 1}\" in issue]\n",
    "    \n",
    "    # 如果是首次生成或有问题需要改进\n",
    "    if not current_version or section_issues or regenerate_count > 0:\n",
    "        \n",
    "        # 优化搜索\n",
    "        optimized_query = optimize_search_query(section_info, topic, current_history)\n",
    "        \n",
    "        # 执行搜索\n",
    "        try:\n",
    "            search_results = search.invoke(optimized_query)\n",
    "            processed_content, images = process_search_results(search_results, section_info)\n",
    "        except Exception as e:\n",
    "            print(f\"搜索错误: {e}\")\n",
    "            processed_content = \"无法获取相关信息\"\n",
    "            images = []\n",
    "            search_results = []\n",
    "        \n",
    "        # 构建写作提示\n",
    "        improvement_context = \"\"\n",
    "        if current_version:\n",
    "            improvement_context = f\"\"\"\n",
    "            当前版本 (v{current_version.version}):\n",
    "            标题: {current_version.title}\n",
    "            内容长度: {len(current_version.content)} 字\n",
    "            \n",
    "            需要改进的问题:\n",
    "            {', '.join(section_issues)}\n",
    "            \n",
    "            请在现有基础上改进，避免简单重复。\n",
    "            \"\"\"\n",
    "        \n",
    "        writer_prompt = f\"\"\"\n",
    "        你是专业的报告写作专家。\n",
    "        \n",
    "        章节信息:\n",
    "        - 标题: {section_info['title']}\n",
    "        - 描述: {section_info['description']}\n",
    "        - 连接类型: {section_info.get('connection_type', 'logical')}\n",
    "        - 版本: {current_version.version + 1 if current_version else 1}\n",
    "        \n",
    "        {improvement_context}\n",
    "        \n",
    "        搜索素材:\n",
    "        {processed_content}\n",
    "        \n",
    "        可用图片: {len(images)} 张\n",
    "        \n",
    "        请{\"改进现有内容\" if current_version else \"创作新内容\"}，要求：\n",
    "        1. 避免与历史版本重复\n",
    "        2. 针对具体问题进行改进\n",
    "        3. 使用最新信息、案例和数据\n",
    "        4. 保持专业性和可读性\n",
    "        5. 长度500-700字\n",
    "        6. 为下一章节做好自然过渡准备\n",
    "        7. 如果有合适的数据，建议插入图表位置\n",
    "        \n",
    "        请直接返回改进后的内容，使用Markdown格式。\n",
    "        \"\"\"\n",
    "        \n",
    "        # 生成新版本\n",
    "        new_content = llm.invoke([\n",
    "            SystemMessage(content=\"你是专业的报告写作专家，专注于基于反馈的迭代改进。\"),\n",
    "            HumanMessage(content=writer_prompt)\n",
    "        ]).content\n",
    "        \n",
    "        # 插入图片\n",
    "        final_content = insert_images_into_content(new_content, images)\n",
    "        \n",
    "        # 添加到历史记录\n",
    "        if current_history.add_version(section_info['title'], final_content, images):\n",
    "            # 保存当前版本到文件\n",
    "            version_num = current_history.current_version\n",
    "            draft_filename = f\"drafts/section_{index:02d}_v{version_num}_{section_info['title'].replace(' ', '_')}.md\"\n",
    "            with open(draft_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"# {section_info['title']} (v{version_num})\\n\\n{final_content}\")\n",
    "            \n",
    "            # 保存图片信息\n",
    "            if images:\n",
    "                image_info_file = f\"images/section_{index:02d}_v{version_num}_images.json\"\n",
    "                with open(image_info_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump([img.dict() for img in images], f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(f\"✅ 章节 {index + 1} 已更新到 v{version_num}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"✅ 章节 {index + 1} 无需更新\")\n",
    "    \n",
    "    return {\n",
    "        \"section_histories\": [current_history],\n",
    "        \"search_results\": [{\n",
    "            \"section_index\": index,\n",
    "            \"query\": optimized_query if 'optimized_query' in locals() else \"\",\n",
    "            \"results\": search_results if 'search_results' in locals() else []\n",
    "        }]\n",
    "    }\n",
    "\n",
    "# ---------- 8. 分发节点 ----------\n",
    "def dispatch(state: State):\n",
    "    print(f\"📋 分发任务到 {len(state['plan'])} 个worker\")\n",
    "    \n",
    "    validation_issues = []\n",
    "    if state.get('validation_result'):\n",
    "        validation_issues = state['validation_result'].get('issues', [])\n",
    "    \n",
    "    existing_histories = state.get('section_histories', [])\n",
    "    \n",
    "    return [\n",
    "        Send(\"worker\", {\n",
    "            \"section_info\": section,\n",
    "            \"section_index\": i,\n",
    "            \"topic\": state['topic'],\n",
    "            \"regenerate_count\": state.get('regenerate_count', 0),\n",
    "            \"validation_issues\": validation_issues,\n",
    "            \"existing_histories\": existing_histories\n",
    "        })\n",
    "        for i, section in enumerate(state[\"plan\"])\n",
    "    ]\n",
    "\n",
    "# ---------- 9. 生成章节过渡 ----------\n",
    "def generate_transitions(sections: List[Dict], section_histories: List[SectionHistory]) -> List[TransitionInfo]:\n",
    "    \"\"\"生成章节间的自然过渡\"\"\"\n",
    "    transitions = []\n",
    "    \n",
    "    for i in range(len(sections) - 1):\n",
    "        current_section = sections[i]\n",
    "        next_section = sections[i + 1]\n",
    "        \n",
    "        # 获取章节内容\n",
    "        current_history = None\n",
    "        next_history = None\n",
    "        \n",
    "        for history in section_histories:\n",
    "            if history.section_index == i:\n",
    "                current_history = history\n",
    "            elif history.section_index == i + 1:\n",
    "                next_history = history\n",
    "        \n",
    "        current_content = \"\"\n",
    "        next_content = \"\"\n",
    "        \n",
    "        if current_history:\n",
    "            current_version = current_history.get_current()\n",
    "            if current_version:\n",
    "                current_content = current_version.content[-300:]  # 取最后300字\n",
    "        \n",
    "        if next_history:\n",
    "            next_version = next_history.get_current()\n",
    "            if next_version:\n",
    "                next_content = next_version.content[:300]  # 取前300字\n",
    "        \n",
    "        # 生成过渡文本\n",
    "        transition_prompt = f\"\"\"\n",
    "        你是专业的文章编辑专家。\n",
    "        \n",
    "        当前章节: {current_section['title']}\n",
    "        当前章节结尾: {current_content}\n",
    "        \n",
    "        下一章节: {next_section['title']}\n",
    "        下一章节开头: {next_content}\n",
    "        \n",
    "        连接类型: {next_section.get('connection_type', 'logical')}\n",
    "        \n",
    "        请生成一个自然、流畅的过渡段落，要求：\n",
    "        1. 总结当前章节的要点\n",
    "        2. 自然引出下一章节的主题\n",
    "        3. 根据连接类型使用合适的过渡词\n",
    "        4. 长度2-3句话\n",
    "        5. 语言专业且易懂\n",
    "        \n",
    "        只返回过渡文本，不要其他说明。\n",
    "        \"\"\"\n",
    "        \n",
    "        transition_text = llm.invoke([\n",
    "            SystemMessage(content=\"你是专业的文章编辑，擅长创建自然流畅的章节过渡。\"),\n",
    "            HumanMessage(content=transition_prompt)\n",
    "        ]).content.strip()\n",
    "        \n",
    "        transitions.append(TransitionInfo(\n",
    "            from_section=i,\n",
    "            to_section=i + 1,\n",
    "            transition_text=transition_text,\n",
    "            connection_type=next_section.get('connection_type', 'logical')\n",
    "        ))\n",
    "    \n",
    "    return transitions\n",
    "\n",
    "# ---------- 10. 合并节点 ----------\n",
    "def merge_node(state: State):\n",
    "    current_version = state.get('current_report_version', 1)\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    \n",
    "    print(f\"📝 合并报告 v{current_version} (重新生成次数: {regenerate_count})\")\n",
    "    \n",
    "    # 获取当前版本的章节内容\n",
    "    current_sections = []\n",
    "    section_version_map = {}\n",
    "    \n",
    "    # 确保按索引排序\n",
    "    sorted_histories = sorted(state['section_histories'], key=lambda h: h.section_index)\n",
    "    \n",
    "    for history in sorted_histories:\n",
    "        current_section = history.get_current()\n",
    "        if current_section:\n",
    "            current_sections.append({\n",
    "                'index': history.section_index,\n",
    "                'title': current_section.title,\n",
    "                'content': current_section.content,\n",
    "                'version': current_section.version,\n",
    "                'images': current_section.images\n",
    "            })\n",
    "            section_version_map[history.section_index] = current_section.version\n",
    "    \n",
    "    # 生成章节过渡\n",
    "    transitions = generate_transitions(state['plan'], state['section_histories'])\n",
    "    \n",
    "    # 组装最终报告\n",
    "    report = f\"# {state['topic']}\\n\\n\"\n",
    "    report += f\"*版本: v{current_version} | 生成时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\\n\"\n",
    "    \n",
    "    # 版本信息摘要\n",
    "    report += \"## 版本信息\\n\\n\"\n",
    "    for section in current_sections:\n",
    "        img_count = len(section['images'])\n",
    "        report += f\"- {section['title']}: v{section['version']}\"\n",
    "        if img_count > 0:\n",
    "            report += f\" (包含 {img_count} 张图片)\"\n",
    "        report += \"\\n\"\n",
    "    \n",
    "    if regenerate_count > 0:\n",
    "        report += f\"- 重新生成次数: {regenerate_count}\\n\"\n",
    "    \n",
    "    report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    # 目录\n",
    "    report += \"## 目录\\n\\n\"\n",
    "    for i, section in enumerate(current_sections):\n",
    "        report += f\"{i+1}. [{section['title']}](#{section['title'].replace(' ', '-').lower()})\\n\"\n",
    "    report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    # 章节内容，使用自然过渡\n",
    "    for i, section in enumerate(current_sections):\n",
    "        report += f\"## {section['title']}\\n\\n\"\n",
    "        report += section['content']\n",
    "        \n",
    "        # 添加自然过渡\n",
    "        if i < len(current_sections) - 1:\n",
    "            transition = None\n",
    "            for t in transitions:\n",
    "                if t.from_section == i:\n",
    "                    transition = t\n",
    "                    break\n",
    "            \n",
    "            if transition:\n",
    "                report += f\"\\n\\n{transition.transition_text}\\n\\n\"\n",
    "            else:\n",
    "                report += \"\\n\\n\"\n",
    "        \n",
    "        if i < len(current_sections) - 1:\n",
    "            report += \"---\\n\\n\"\n",
    "    \n",
    "    # 保存报告\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"reports/report_v{current_version}_{timestamp}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    # 保存版本历史\n",
    "    save_version_history(state['section_histories'], current_version)\n",
    "    \n",
    "    # 更新报告版本记录\n",
    "    report_versions = state.get('report_versions', [])\n",
    "    current_report_version = ReportVersion(\n",
    "        version=current_version,\n",
    "        timestamp=datetime.datetime.now().isoformat(),\n",
    "        section_versions=section_version_map,\n",
    "        regenerate_reason=f\"第 {regenerate_count} 次重新生成\" if regenerate_count > 0 else \"正常生成\",\n",
    "        transitions=transitions\n",
    "    )\n",
    "    \n",
    "    # 更新或添加当前版本记录\n",
    "    updated_versions = [v for v in report_versions if v.version != current_version]\n",
    "    updated_versions.append(current_report_version)\n",
    "    \n",
    "    return {\n",
    "        \"final_report\": report,\n",
    "        \"report_versions\": updated_versions\n",
    "    }\n",
    "\n",
    "# ---------- 11. 验证节点 ----------\n",
    "def validation_node(state: State):\n",
    "    current_version = state.get('current_report_version', 1)\n",
    "    print(f\"🔍 验证报告 v{current_version}...\")\n",
    "    \n",
    "    validation_prompt = f\"\"\"\n",
    "    请验证以下报告的质量：\n",
    "    \n",
    "    主题: {state['topic']}\n",
    "    版本: v{current_version}\n",
    "    \n",
    "    报告内容 (前2000字):\n",
    "    {state['final_report'][:2000]}...\n",
    "    \n",
    "    请从以下方面评估并返回JSON格式：\n",
    "    1. 内容完整性和深度 (0-10分)\n",
    "    2. 逻辑结构和连贯性 (0-10分)\n",
    "    3. 语言质量和专业性 (0-10分)\n",
    "    4. 创新性和时效性 (0-10分)\n",
    "    5. 图表和视觉元素 (0-10分)\n",
    "    6. 章节过渡的自然性 (0-10分)\n",
    "    \n",
    "    验证通过条件：总分 >= 8.0，且没有严重问题\n",
    "    \n",
    "    返回格式：\n",
    "    {{\n",
    "        \"is_valid\": true/false,\n",
    "        \"score\": 8.5,\n",
    "        \"detailed_scores\": {{\n",
    "            \"content\": 8.0,\n",
    "            \"logic\": 9.0,\n",
    "            \"language\": 8.5,\n",
    "            \"innovation\": 8.0,\n",
    "            \"visuals\": 7.5,\n",
    "            \"transitions\": 9.0\n",
    "        }},\n",
    "        \"issues\": [\"具体问题1\", \"具体问题2\"],\n",
    "        \"suggestions\": [\"改进建议1\", \"改进建议2\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    class ValidationSchema(BaseModel):\n",
    "        is_valid: bool\n",
    "        score: float\n",
    "        detailed_scores: Dict[str, float]\n",
    "        issues: List[str]\n",
    "        suggestions: List[str]\n",
    "    \n",
    "    validator = llm.with_structured_output(ValidationSchema)\n",
    "    validation = validator.invoke([\n",
    "        SystemMessage(content=\"你是专业的内容质量评估专家，请按JSON格式返回详细的验证结果。\"),\n",
    "        HumanMessage(content=validation_prompt)\n",
    "    ])\n",
    "    \n",
    "    print(f\"📊 验证结果: 总分 {validation.score}/10\")\n",
    "    print(f\"📋 详细得分:\")\n",
    "    for aspect, score in validation.detailed_scores.items():\n",
    "        print(f\"  - {aspect}: {score}/10\")\n",
    "    \n",
    "    print(f\"✅ 状态: {'通过' if validation.is_valid else '需要改进'}\")\n",
    "    \n",
    "    if not validation.is_valid:\n",
    "        print(\"⚠️ 发现问题:\")\n",
    "        for issue in validation.issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    \n",
    "    # 更新报告版本的验证状态\n",
    "    report_versions = state.get('report_versions', [])\n",
    "    for version in report_versions:\n",
    "        if version.version == current_version:\n",
    "            version.validation_passed = validation.is_valid\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        \"validation_result\": validation.dict(),\n",
    "        \"report_versions\": report_versions\n",
    "    }\n",
    "\n",
    "# ---------- 12. 路由函数 ----------\n",
    "def should_regenerate(state: State):\n",
    "    \"\"\"决定是否重新生成 - 验证通过就直接结束\"\"\"\n",
    "    validation = state.get('validation_result', {})\n",
    "    regenerate_count = state.get('regenerate_count', 0)\n",
    "    \n",
    "    # 如果验证通过，直接完成\n",
    "    if validation.get('is_valid', False):\n",
    "        print(\"✅ 验证通过，报告生成完成！\")\n",
    "        return \"complete\"\n",
    "    \n",
    "    # 如果验证未通过且未达到最大重试次数，重新生成\n",
    "    if regenerate_count < MAX_REGEN:\n",
    "        print(f\"⚠️ 验证未通过，准备第 {regenerate_count + 1} 次重新生成...\")\n",
    "        return \"regenerate\"\n",
    "    \n",
    "    # 达到最大重试次数，强制完成\n",
    "    print(f\"🚫 已达最大重试次数 ({MAX_REGEN})，强制完成生成。\")\n",
    "    return \"complete\"\n",
    "\n",
    "def regenerate_routing(state: State):\n",
    "    \"\"\"重新生成时的路由\"\"\"\n",
    "    regenerate_count = state.get('regenerate_count', 0) + 1\n",
    "    current_version = state.get('current_report_version', 1) + 1\n",
    "    \n",
    "    validation = state.get('validation_result', {})\n",
    "    \n",
    "    print(f\"🔄 开始第 {regenerate_count} 次重新生成 (v{current_version})\")\n",
    "    print(f\"🎯 主要问题: {', '.join(validation.get('issues', []))}\")\n",
    "    \n",
    "    return {\n",
    "        \"regenerate_count\": regenerate_count,\n",
    "        \"current_report_version\": current_version\n",
    "    }\n",
    "\n",
    "# ---------- 13. 构建工作流 ----------\n",
    "def build_workflow():\n",
    "    setup_directories()\n",
    "    \n",
    "    workflow = StateGraph(State)\n",
    "    \n",
    "    # 添加节点\n",
    "    workflow.add_node(\"plan\", plan_node)\n",
    "    workflow.add_node(\"worker\", worker_node)\n",
    "    workflow.add_node(\"merge\", merge_node)\n",
    "    workflow.add_node(\"validate\", validation_node)\n",
    "    workflow.add_node(\"regenerate\", regenerate_routing)\n",
    "    workflow.add_node(\"complete\", lambda state: state)\n",
    "    \n",
    "    # 添加边\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_conditional_edges(\"plan\", dispatch, [\"worker\"])\n",
    "    workflow.add_edge(\"worker\", \"merge\")\n",
    "    workflow.add_edge(\"merge\", \"validate\")\n",
    "    workflow.add_conditional_edges(\"validate\", should_regenerate, {\n",
    "        \"complete\": \"complete\",\n",
    "        \"regenerate\": \"regenerate\"\n",
    "    })\n",
    "    workflow.add_edge(\"regenerate\", \"worker\")\n",
    "    workflow.add_edge(\"complete\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# ---------- 14. 主程序 ----------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 启动增强版报告生成系统...\")\n",
    "    print(\"✨ 新功能: 验证通过自动结束 | 自然章节过渡 | 智能图片插入\")\n",
    "    \n",
    "    app = build_workflow()\n",
    "    \n",
    "    config = {\n",
    "        \"topic\": \"生成式 AI 如何重塑教育\",\n",
    "        \"regenerate_count\": 0,\n",
    "        \"current_report_version\": 1,\n",
    "        \"output_format\": \"markdown\",\n",
    "        \"section_histories\": [],\n",
    "        \"report_versions\": [],\n",
    "        \"search_results\": [],\n",
    "        \"todo_list\": [],\n",
    "        \"completed_tasks\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 设置递归限制\n",
    "        result = app.invoke(config, config={\"recursion_limit\": 50})\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📊 报告生成完成!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 显示版本信息\n",
    "        current_version = result.get('current_report_version', 1)\n",
    "        print(f\"\\n📋 最终版本: v{current_version}\")\n",
    "        \n",
    "        print(\"\\n📁 生成的文件:\")\n",
    "        print(f\"  - 最终报告: reports/report_v{current_version}_*.md\")\n",
    "        print(f\"  - 章节草稿: drafts/section_*_v*_*.md\")\n",
    "        print(f\"  - 版本历史: versions/v*/\")\n",
    "        print(f\"  - 图片信息: images/section_*_v*_images.json\")\n",
    "        print(f\"  - 任务列表: todo_v{current_version}.txt\")\n",
    "        \n",
    "        validation = result.get('validation_result', {})\n",
    "        if validation:\n",
    "            print(f\"\\n✅ 最终得分: {validation.get('score', 0)}/10\")\n",
    "            print(f\"📊 状态: {'通过' if validation.get('is_valid', False) else '需要改进'}\")\n",
    "            \n",
    "            # 显示详细得分\n",
    "            detailed_scores = validation.get('detailed_scores', {})\n",
    "            if detailed_scores:\n",
    "                print(f\"📋 详细评分:\")\n",
    "                for aspect, score in detailed_scores.items():\n",
    "                    print(f\"  - {aspect}: {score}/10\")\n",
    "        \n",
    "        # 显示章节版本信息\n",
    "        print(f\"\\n📖 章节版本:\")\n",
    "        for history in sorted(result.get('section_histories', []), key=lambda h: h.section_index):\n",
    "            current = history.get_current()\n",
    "            if current:\n",
    "                img_count = len(current.images)\n",
    "                img_text = f\" (含 {img_count} 图)\" if img_count > 0 else \"\"\n",
    "                print(f\"  {history.section_index + 1}. {current.title} (v{current.version}){img_text}\")\n",
    "        \n",
    "        # 显示过渡信息\n",
    "        report_versions = result.get('report_versions', [])\n",
    "        if report_versions:\n",
    "            latest_version = report_versions[-1]\n",
    "            if latest_version.transitions:\n",
    "                print(f\"\\n🔗 章节过渡:\")\n",
    "                for transition in latest_version.transitions:\n",
    "                    print(f\"  {transition.from_section + 1} → {transition.to_section + 1}: {transition.connection_type}\")\n",
    "        \n",
    "        print(f\"\\n📝 最终报告预览:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(result[\"final_report\"][:500] + \"...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 生成失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191243c5-726d-45c2-850b-a8533351e5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
